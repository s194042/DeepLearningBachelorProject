{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#from torch import nn\n",
    "#import numpy as np\n",
    "#from torchsummary import summary\n",
    "#import Lossv2\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#summary(Lossv2.Loss().to(device), (6, 768, 512))  ###  IDK why, but I have to switch the dims in AvgPool on Loss() to get this to work :/ But that breaks the stuff bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.manual_seed(100)\n",
    "np.random.seed(100)\n",
    "import Lossv2\n",
    "import generateLossImages\n",
    "import time\n",
    "\n",
    "global counter \n",
    "counter = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def save_ckp(state, is_best, checkpoint_dir=\"./models/rest/\", best_model_dir=\"./models/best/\"):\n",
    "    global counter \n",
    "    f_path = checkpoint_dir + str(counter) + '_checkpoint.pt'\n",
    "    counter = counter + 1\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_dir + 'best_model.pt'\n",
    "        shutil.copyfile(f_path, best_fpath)\n",
    "\n",
    "def load_ckp(model, optimizer, checkpoint_fpath=\"./models/best/best_model.pt\"):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch'], checkpoint['index'], checkpoint['min_lr'], checkpoint['max_lr'], checkpoint['steps'], checkpoint['step_size'], checkpoint['falling'], checkpoint['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in PyTorch 1.12 and later.\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "min_lr = 0.001\n",
    "max_lr = 0.003\n",
    "decay = 0.8\n",
    "steps = 300\n",
    "falling = True\n",
    "start_epoch = 0\n",
    "start_index = 0\n",
    "momentum = 0.94\n",
    "threshold = [0.16, 0.12, 0.09, 0.06, 0.04, 0.03, 0.02, 0.015, 0.01 -1]\n",
    "step_size = (max_lr-min_lr)/steps\n",
    "model = Lossv2.Loss().to(device).to(memory_format=torch.channels_last)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=max_lr, momentum=momentum)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "#\n",
    "#torch.autograd.set_detect_anomaly(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = nn.L1Loss()\n",
    "#model = Lossv2.Loss().to(device)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.96)\n",
    "#model, optimizer, start_epoch, start_index, min_lr, max_lr, steps, step_size, falling, threshold = load_ckp(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#li = [31.007527351379395, 0.01501011848449707, 0.0010006427764892578, 28.98952603340149, 0.48702239990234375, 47.146605014801025, 12.32689380645752, 0.5665144920349121]\n",
    "#su = sum(li)\n",
    "#print([100*l/su for l in li])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rani\\AppData\\Local\\Temp\\ipykernel_12824\\2920645436.py:17: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  torch.autograd.detect_anomaly(check_nan=False)\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "printing = False\n",
    "running_loss = 0.\n",
    "last_loss = 0.\n",
    "lis = []\n",
    " # might have to delete when loading model\n",
    "threshold_decay = 0.2\n",
    "flags = [True for _ in threshold]\n",
    "record = 1\n",
    "epochs = 100\n",
    "times = [0]*8\n",
    "batch_size= 22\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.detect_anomaly(check_nan=False)\n",
    "torch.autograd.set_detect_anomaly(False, check_nan=False)\n",
    "torch.autograd.profiler.profile(enabled=False)\n",
    "torch.autograd.profiler.emit_nvtx(enabled=False)\n",
    "#torch.autograd.gradgradcheck(check_undefined_grad= False)\n",
    "#torch.autograd.gradcheck(check_undefined_grad= False)\n",
    "#torch.no_grad()\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    training = generateLossImages.MakeIter(start_index=start_index if epoch == start_epoch else 0) # start=2*71*50*4))#start_index if epoch == start_epoch else 0)) \n",
    "    #val = generateLossImages.get_image_pairs_transforms_with_loss(\"C:/Users/Rani/Desktop/ai_val/16\")\n",
    "    training_loader = torch.utils.data.DataLoader(training, batch_size=batch_size, num_workers=2)#), worker_init_fn=worker_init_fn) # num_workers\n",
    "    end = 0\n",
    "    before_start = 0\n",
    "    in_upstart = True\n",
    "    for index, data in enumerate(training_loader):#[90.06174230575562, 0.03202486038208008, 0.016014575958251953, 84.36967897415161, 1.3647308349609375, 137.4005196094513, 34.81299662590027, 1.9427943229675293, 0, 0]\n",
    "        #print(len(inputs))\n",
    "        before_start += 1\n",
    "        if before_start > 5*106/batch_size and in_upstart:\n",
    "            in_upstart = False\n",
    "            times = [0]*8\n",
    "        start = time.time()\n",
    "        if end != 0:\n",
    "            times[0] += (start-end)\n",
    "        inputs, labels = data\n",
    "        labels = torch.unsqueeze(labels, dim=-1)\n",
    "        inputs.to(memory_format=torch.channels_last)\n",
    "        load = time.time()\n",
    "        times[1] += load-start\n",
    "\n",
    "        lab = time.time()\n",
    "        times[2] += (lab-load)\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            out = time.time()\n",
    "            times[3] += (out-lab)\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            los = time.time()\n",
    "            times[4] += (los-out)\n",
    "\n",
    "        loss.backward()#scaler.scale(loss).backward()#loss.backward()\n",
    "\n",
    "        back = time.time()\n",
    "        times[5] += (back-los)\n",
    "        # Gather data and report\n",
    "        #running_loss += loss.item()\n",
    "        \n",
    "        runn = time.time()\n",
    "        times[6] += (runn-back)\n",
    "        optimizer.step()#scaler.step(optimizer)#optimizer.step()\n",
    "        #scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        if printing:\n",
    "            lis.append((f'{outputs.item():.3}',f'{labels.item():.3}'))\n",
    "        if index % 106//batch_size == 106//batch_size-1:\n",
    "            # Zero your gradients for every batch!\n",
    "            # Adjust learning weights\n",
    "            #last_loss = running_loss / 106 # loss per batch\n",
    "            #if last_loss < threshold[0] and flags[0]:\n",
    "            #    threshold = threshold[1:]\n",
    "            #    flags = flags[1:]\n",
    "            #    flag1 = False\n",
    "            #    min_lr *= threshold_decay\n",
    "            #    max_lr *= threshold_decay\n",
    "            #    step_size = (max_lr-min_lr)/steps\n",
    "            #    falling = True\n",
    "            #    optimizer.param_groups[-1]['lr'] = max_lr\n",
    "            #    if printing:\n",
    "            #        print(min_lr)\n",
    "            #        print(max_lr)\n",
    "            #        print(steps)\n",
    "            #        print(step_size)\n",
    "            #    checkpoint = {\n",
    "            #        'epoch': epoch,\n",
    "            #        'index': index,\n",
    "            #        'min_lr': min_lr,\n",
    "            #        'max_lr': max_lr,\n",
    "            #        'steps': steps,\n",
    "            #        'step_size': step_size,\n",
    "            #        'falling': falling,\n",
    "            #        'state_dict': model.state_dict(),\n",
    "            #        'optimizer': optimizer.state_dict(),\n",
    "            #        'threshold': threshold\n",
    "            #    }\n",
    "            #    save_ckp(checkpoint, True)\n",
    "            #elif falling:\n",
    "            if falling:\n",
    "                optimizer.param_groups[-1]['lr'] = optimizer.param_groups[-1]['lr'] - step_size\n",
    "                if optimizer.param_groups[-1]['lr'] < min_lr:\n",
    "                    falling = False\n",
    "                    max_lr *= decay\n",
    "                    min_lr *= decay\n",
    "                    steps /= decay\n",
    "                    step_size = (max_lr-min_lr)/steps\n",
    "\n",
    "                    if printing:\n",
    "                        print(min_lr)\n",
    "                        print(max_lr)\n",
    "                        print(steps)\n",
    "                        print(step_size)\n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch,\n",
    "                        'index': index,\n",
    "                        'min_lr': min_lr,\n",
    "                        'max_lr': max_lr,\n",
    "                        'steps': steps,\n",
    "                        'step_size': step_size,\n",
    "                        'falling': falling,\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'threshold': threshold\n",
    "                    }\n",
    "                    save_ckp(checkpoint, True)\n",
    "\n",
    "            else: \n",
    "                optimizer.param_groups[-1]['lr'] += step_size\n",
    "                if optimizer.param_groups[-1]['lr'] > max_lr:\n",
    "                    falling = True\n",
    "\n",
    "        #    if printing:\n",
    "        #        print(optimizer.param_groups[-1]['lr'])\n",
    "        #        print('  batch {} loss: {}'.format(index + 1, last_loss))\n",
    "        #        print(lis)\n",
    "        #        lis = []\n",
    "        #    running_loss = 0\n",
    "\n",
    "        #    if last_loss < record:\n",
    "        #        record = last_loss\n",
    "        #        if last_loss < 0.08:\n",
    "        #            checkpoint = {\n",
    "        #            'epoch': epoch,\n",
    "        #            'index': index,\n",
    "        #            'min_lr': min_lr,\n",
    "        #            'max_lr': max_lr,\n",
    "        #            'steps': steps,\n",
    "        #            'step_size': step_size,\n",
    "        #            'falling': falling,\n",
    "        #            'state_dict': model.state_dict(),\n",
    "        #            'optimizer': optimizer.state_dict(),\n",
    "        #            'threshold': threshold\n",
    "        #        }\n",
    "        #            save_ckp(checkpoint, True)\n",
    "        #   print(times)\n",
    "        end = time.time()\n",
    "        times[7] += (end-runn)\n",
    "        if before_start > 106/batch_size*20:\n",
    "            break\n",
    "    \n",
    "    break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03902459144592285, 5.828261613845825, 0.0, 1.4729628562927246, 0.027028560638427734, 2.4854860305786133, 0.0, 0.2182321548461914]\n",
      "[0.38749486338072336, 57.87175096845899, 0.0, 14.625791574396121, 0.2683802193413963, 24.679645171644168, 0.0, 2.1669372027786014]\n"
     ]
    }
   ],
   "source": [
    "print(times)\n",
    "su = sum(times)\n",
    "print([100*l/su for l in times])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.327433200897994\n"
     ]
    }
   ],
   "source": [
    "print(su/15*6645*50*4/86400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
