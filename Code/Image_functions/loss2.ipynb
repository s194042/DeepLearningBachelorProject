{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 768, 512]             224\n",
      "            Conv2d-2         [-1, 32, 384, 512]             128\n",
      "            Conv2d-3         [-1, 32, 384, 256]             128\n",
      "               ELU-4         [-1, 32, 384, 256]               0\n",
      "            Conv2d-5         [-1, 32, 384, 256]           1,056\n",
      "            Conv2d-6         [-1, 32, 384, 256]             128\n",
      "            Conv2d-7         [-1, 32, 384, 256]             128\n",
      "               ELU-8         [-1, 32, 384, 256]               0\n",
      "            Conv2d-9         [-1, 32, 384, 256]           1,056\n",
      "           Conv2d-10         [-1, 32, 192, 256]             128\n",
      "           Conv2d-11         [-1, 32, 192, 128]             128\n",
      "              ELU-12         [-1, 32, 192, 128]               0\n",
      "           Conv2d-13         [-1, 32, 384, 256]           1,056\n",
      "        MaxPool2d-14         [-1, 32, 192, 128]               0\n",
      "              ELU-15         [-1, 32, 192, 128]               0\n",
      "           Conv2d-16         [-1, 64, 768, 512]             448\n",
      "           Conv2d-17         [-1, 64, 192, 512]             512\n",
      "           Conv2d-18         [-1, 64, 192, 128]             512\n",
      "           Conv2d-19         [-1, 64, 192, 128]           4,160\n",
      "           Conv2d-20         [-1, 64, 192, 128]             256\n",
      "           Conv2d-21         [-1, 64, 192, 128]             256\n",
      "              ELU-22         [-1, 64, 192, 128]               0\n",
      "           Conv2d-23         [-1, 64, 192, 128]           4,160\n",
      "           Conv2d-24          [-1, 64, 96, 128]             256\n",
      "           Conv2d-25           [-1, 64, 96, 64]             256\n",
      "              ELU-26           [-1, 64, 96, 64]               0\n",
      "           Conv2d-27         [-1, 64, 192, 128]           4,160\n",
      "        MaxPool2d-28           [-1, 64, 96, 64]               0\n",
      "              ELU-29           [-1, 64, 96, 64]               0\n",
      "           Conv2d-30        [-1, 128, 192, 128]           8,320\n",
      "           Conv2d-31         [-1, 128, 96, 128]             512\n",
      "           Conv2d-32          [-1, 128, 96, 64]             512\n",
      "             Stem-33          [-1, 128, 96, 64]               0\n",
      "           Conv2d-34           [-1, 32, 96, 64]           4,128\n",
      "        MaxPool2d-35           [-1, 32, 96, 64]               0\n",
      "              ELU-36           [-1, 32, 96, 64]               0\n",
      "           Conv2d-37           [-1, 32, 96, 64]           4,128\n",
      "              ELU-38           [-1, 32, 96, 64]               0\n",
      "           Conv2d-39           [-1, 32, 96, 64]           4,128\n",
      "              ELU-40           [-1, 32, 96, 64]               0\n",
      "           Conv2d-41           [-1, 32, 96, 64]             128\n",
      "           Conv2d-42           [-1, 32, 96, 64]             128\n",
      "           Conv2d-43           [-1, 32, 96, 64]           1,056\n",
      "              ELU-44           [-1, 32, 96, 64]               0\n",
      "           Conv2d-45           [-1, 32, 96, 64]           4,128\n",
      "              ELU-46           [-1, 32, 96, 64]               0\n",
      "           Conv2d-47           [-1, 32, 96, 64]             192\n",
      "           Conv2d-48           [-1, 32, 96, 64]             192\n",
      "           Conv2d-49           [-1, 32, 96, 64]           1,056\n",
      "              ELU-50           [-1, 32, 96, 64]               0\n",
      "       InceptionA-51          [-1, 128, 96, 64]               0\n",
      "           Conv2d-52           [-1, 32, 96, 64]           4,128\n",
      "        MaxPool2d-53           [-1, 32, 96, 64]               0\n",
      "              ELU-54           [-1, 32, 96, 64]               0\n",
      "           Conv2d-55           [-1, 32, 96, 64]           4,128\n",
      "              ELU-56           [-1, 32, 96, 64]               0\n",
      "           Conv2d-57           [-1, 32, 96, 64]           4,128\n",
      "              ELU-58           [-1, 32, 96, 64]               0\n",
      "           Conv2d-59           [-1, 32, 96, 64]             128\n",
      "           Conv2d-60           [-1, 32, 96, 64]             128\n",
      "           Conv2d-61           [-1, 32, 96, 64]           1,056\n",
      "              ELU-62           [-1, 32, 96, 64]               0\n",
      "           Conv2d-63           [-1, 32, 96, 64]           4,128\n",
      "              ELU-64           [-1, 32, 96, 64]               0\n",
      "           Conv2d-65           [-1, 32, 96, 64]             192\n",
      "           Conv2d-66           [-1, 32, 96, 64]             192\n",
      "           Conv2d-67           [-1, 32, 96, 64]           1,056\n",
      "              ELU-68           [-1, 32, 96, 64]               0\n",
      "       InceptionA-69          [-1, 128, 96, 64]               0\n",
      "           Conv2d-70           [-1, 32, 96, 64]           4,128\n",
      "        MaxPool2d-71           [-1, 32, 96, 64]               0\n",
      "              ELU-72           [-1, 32, 96, 64]               0\n",
      "           Conv2d-73           [-1, 32, 96, 64]           4,128\n",
      "              ELU-74           [-1, 32, 96, 64]               0\n",
      "           Conv2d-75           [-1, 32, 96, 64]           4,128\n",
      "              ELU-76           [-1, 32, 96, 64]               0\n",
      "           Conv2d-77           [-1, 32, 96, 64]             128\n",
      "           Conv2d-78           [-1, 32, 96, 64]             128\n",
      "           Conv2d-79           [-1, 32, 96, 64]           1,056\n",
      "              ELU-80           [-1, 32, 96, 64]               0\n",
      "           Conv2d-81           [-1, 32, 96, 64]           4,128\n",
      "              ELU-82           [-1, 32, 96, 64]               0\n",
      "           Conv2d-83           [-1, 32, 96, 64]             192\n",
      "           Conv2d-84           [-1, 32, 96, 64]             192\n",
      "           Conv2d-85           [-1, 32, 96, 64]           1,056\n",
      "              ELU-86           [-1, 32, 96, 64]               0\n",
      "       InceptionA-87          [-1, 128, 96, 64]               0\n",
      "           Conv2d-88           [-1, 32, 96, 64]           4,128\n",
      "        MaxPool2d-89           [-1, 32, 96, 64]               0\n",
      "              ELU-90           [-1, 32, 96, 64]               0\n",
      "           Conv2d-91           [-1, 32, 96, 64]           4,128\n",
      "              ELU-92           [-1, 32, 96, 64]               0\n",
      "           Conv2d-93           [-1, 32, 96, 64]           4,128\n",
      "              ELU-94           [-1, 32, 96, 64]               0\n",
      "           Conv2d-95           [-1, 32, 96, 64]             128\n",
      "           Conv2d-96           [-1, 32, 96, 64]             128\n",
      "           Conv2d-97           [-1, 32, 96, 64]           1,056\n",
      "              ELU-98           [-1, 32, 96, 64]               0\n",
      "           Conv2d-99           [-1, 32, 96, 64]           4,128\n",
      "             ELU-100           [-1, 32, 96, 64]               0\n",
      "          Conv2d-101           [-1, 32, 96, 64]             192\n",
      "          Conv2d-102           [-1, 32, 96, 64]             192\n",
      "          Conv2d-103           [-1, 32, 96, 64]           1,056\n",
      "             ELU-104           [-1, 32, 96, 64]               0\n",
      "      InceptionA-105          [-1, 128, 96, 64]               0\n",
      "          Conv2d-106           [-1, 32, 96, 64]           4,128\n",
      "       MaxPool2d-107           [-1, 32, 96, 64]               0\n",
      "             ELU-108           [-1, 32, 96, 64]               0\n",
      "          Conv2d-109           [-1, 32, 96, 64]           4,128\n",
      "             ELU-110           [-1, 32, 96, 64]               0\n",
      "          Conv2d-111           [-1, 32, 96, 64]           4,128\n",
      "             ELU-112           [-1, 32, 96, 64]               0\n",
      "          Conv2d-113           [-1, 32, 96, 64]             128\n",
      "          Conv2d-114           [-1, 32, 96, 64]             128\n",
      "          Conv2d-115           [-1, 32, 96, 64]           1,056\n",
      "             ELU-116           [-1, 32, 96, 64]               0\n",
      "          Conv2d-117           [-1, 32, 96, 64]           4,128\n",
      "             ELU-118           [-1, 32, 96, 64]               0\n",
      "          Conv2d-119           [-1, 32, 96, 64]             192\n",
      "          Conv2d-120           [-1, 32, 96, 64]             192\n",
      "          Conv2d-121           [-1, 32, 96, 64]           1,056\n",
      "             ELU-122           [-1, 32, 96, 64]               0\n",
      "      InceptionA-123          [-1, 128, 96, 64]               0\n",
      "          Conv2d-124           [-1, 32, 96, 64]           4,128\n",
      "       MaxPool2d-125           [-1, 32, 96, 64]               0\n",
      "             ELU-126           [-1, 32, 96, 64]               0\n",
      "          Conv2d-127           [-1, 32, 96, 64]           4,128\n",
      "             ELU-128           [-1, 32, 96, 64]               0\n",
      "          Conv2d-129           [-1, 32, 96, 64]           4,128\n",
      "             ELU-130           [-1, 32, 96, 64]               0\n",
      "          Conv2d-131           [-1, 32, 96, 64]             128\n",
      "          Conv2d-132           [-1, 32, 96, 64]             128\n",
      "          Conv2d-133           [-1, 32, 96, 64]           1,056\n",
      "             ELU-134           [-1, 32, 96, 64]               0\n",
      "          Conv2d-135           [-1, 32, 96, 64]           4,128\n",
      "             ELU-136           [-1, 32, 96, 64]               0\n",
      "          Conv2d-137           [-1, 32, 96, 64]             192\n",
      "          Conv2d-138           [-1, 32, 96, 64]             192\n",
      "          Conv2d-139           [-1, 32, 96, 64]           1,056\n",
      "             ELU-140           [-1, 32, 96, 64]               0\n",
      "      InceptionA-141          [-1, 128, 96, 64]               0\n",
      "          Conv2d-142           [-1, 64, 96, 64]           8,256\n",
      "       MaxPool2d-143           [-1, 64, 48, 32]               0\n",
      "             ELU-144           [-1, 64, 48, 32]               0\n",
      "          Conv2d-145          [-1, 128, 48, 64]             512\n",
      "          Conv2d-146          [-1, 128, 48, 32]             512\n",
      "          Conv2d-147          [-1, 128, 48, 32]          16,512\n",
      "             ELU-148          [-1, 128, 48, 32]               0\n",
      "          Conv2d-149           [-1, 64, 96, 64]           8,256\n",
      "             ELU-150           [-1, 64, 96, 64]               0\n",
      "          Conv2d-151           [-1, 64, 48, 64]             384\n",
      "          Conv2d-152           [-1, 64, 48, 32]             384\n",
      "          Conv2d-153           [-1, 64, 48, 32]           4,160\n",
      "             ELU-154           [-1, 64, 48, 32]               0\n",
      "          Conv2d-155          [-1, 256, 48, 64]           1,024\n",
      "          Conv2d-156          [-1, 256, 48, 32]           1,024\n",
      "          Conv2d-157          [-1, 256, 48, 32]          65,792\n",
      "      ReductionA-158          [-1, 256, 48, 32]               0\n",
      "          Conv2d-159           [-1, 64, 48, 32]          16,448\n",
      "       MaxPool2d-160           [-1, 64, 48, 32]               0\n",
      "             ELU-161           [-1, 64, 48, 32]               0\n",
      "          Conv2d-162           [-1, 64, 48, 32]          16,448\n",
      "             ELU-163           [-1, 64, 48, 32]               0\n",
      "          Conv2d-164           [-1, 64, 48, 32]          16,448\n",
      "             ELU-165           [-1, 64, 48, 32]               0\n",
      "          Conv2d-166           [-1, 64, 48, 32]             256\n",
      "          Conv2d-167           [-1, 64, 48, 32]             256\n",
      "          Conv2d-168           [-1, 64, 48, 32]           4,160\n",
      "             ELU-169           [-1, 64, 48, 32]               0\n",
      "          Conv2d-170           [-1, 64, 48, 32]          16,448\n",
      "             ELU-171           [-1, 64, 48, 32]               0\n",
      "          Conv2d-172           [-1, 64, 48, 32]             384\n",
      "          Conv2d-173           [-1, 64, 48, 32]             384\n",
      "          Conv2d-174           [-1, 64, 48, 32]           4,160\n",
      "             ELU-175           [-1, 64, 48, 32]               0\n",
      "      InceptionA-176          [-1, 256, 48, 32]               0\n",
      "          Conv2d-177           [-1, 64, 48, 32]          16,448\n",
      "       MaxPool2d-178           [-1, 64, 48, 32]               0\n",
      "             ELU-179           [-1, 64, 48, 32]               0\n",
      "          Conv2d-180           [-1, 64, 48, 32]          16,448\n",
      "             ELU-181           [-1, 64, 48, 32]               0\n",
      "          Conv2d-182           [-1, 64, 48, 32]          16,448\n",
      "             ELU-183           [-1, 64, 48, 32]               0\n",
      "          Conv2d-184           [-1, 64, 48, 32]             256\n",
      "          Conv2d-185           [-1, 64, 48, 32]             256\n",
      "          Conv2d-186           [-1, 64, 48, 32]           4,160\n",
      "             ELU-187           [-1, 64, 48, 32]               0\n",
      "          Conv2d-188           [-1, 64, 48, 32]          16,448\n",
      "             ELU-189           [-1, 64, 48, 32]               0\n",
      "          Conv2d-190           [-1, 64, 48, 32]             384\n",
      "          Conv2d-191           [-1, 64, 48, 32]             384\n",
      "          Conv2d-192           [-1, 64, 48, 32]           4,160\n",
      "             ELU-193           [-1, 64, 48, 32]               0\n",
      "      InceptionA-194          [-1, 256, 48, 32]               0\n",
      "          Conv2d-195          [-1, 128, 48, 32]          32,896\n",
      "       MaxPool2d-196          [-1, 128, 24, 16]               0\n",
      "             ELU-197          [-1, 128, 24, 16]               0\n",
      "          Conv2d-198          [-1, 256, 24, 32]           1,024\n",
      "          Conv2d-199          [-1, 256, 24, 16]           1,024\n",
      "          Conv2d-200          [-1, 256, 24, 16]          65,792\n",
      "             ELU-201          [-1, 256, 24, 16]               0\n",
      "          Conv2d-202          [-1, 128, 48, 32]          32,896\n",
      "             ELU-203          [-1, 128, 48, 32]               0\n",
      "          Conv2d-204          [-1, 128, 24, 32]             768\n",
      "          Conv2d-205          [-1, 128, 24, 16]             768\n",
      "          Conv2d-206          [-1, 128, 24, 16]          16,512\n",
      "             ELU-207          [-1, 128, 24, 16]               0\n",
      "          Conv2d-208          [-1, 512, 24, 32]           2,048\n",
      "          Conv2d-209          [-1, 512, 24, 16]           2,048\n",
      "          Conv2d-210          [-1, 512, 24, 16]         262,656\n",
      "      ReductionA-211          [-1, 512, 24, 16]               0\n",
      "          Conv2d-212          [-1, 128, 24, 16]          65,664\n",
      "       MaxPool2d-213          [-1, 128, 24, 16]               0\n",
      "             ELU-214          [-1, 128, 24, 16]               0\n",
      "          Conv2d-215          [-1, 128, 24, 16]          65,664\n",
      "             ELU-216          [-1, 128, 24, 16]               0\n",
      "          Conv2d-217          [-1, 128, 24, 16]          65,664\n",
      "             ELU-218          [-1, 128, 24, 16]               0\n",
      "          Conv2d-219          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-220          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-221          [-1, 128, 24, 16]          16,512\n",
      "             ELU-222          [-1, 128, 24, 16]               0\n",
      "          Conv2d-223          [-1, 128, 24, 16]          65,664\n",
      "             ELU-224          [-1, 128, 24, 16]               0\n",
      "          Conv2d-225          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-226          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-227          [-1, 128, 24, 16]          16,512\n",
      "             ELU-228          [-1, 128, 24, 16]               0\n",
      "          Conv2d-229          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-230          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-231          [-1, 128, 24, 16]          16,512\n",
      "             ELU-232          [-1, 128, 24, 16]               0\n",
      "      InceptionB-233          [-1, 512, 24, 16]               0\n",
      "          Conv2d-234          [-1, 128, 24, 16]          65,664\n",
      "       MaxPool2d-235          [-1, 128, 24, 16]               0\n",
      "             ELU-236          [-1, 128, 24, 16]               0\n",
      "          Conv2d-237          [-1, 128, 24, 16]          65,664\n",
      "             ELU-238          [-1, 128, 24, 16]               0\n",
      "          Conv2d-239          [-1, 128, 24, 16]          65,664\n",
      "             ELU-240          [-1, 128, 24, 16]               0\n",
      "          Conv2d-241          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-242          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-243          [-1, 128, 24, 16]          16,512\n",
      "             ELU-244          [-1, 128, 24, 16]               0\n",
      "          Conv2d-245          [-1, 128, 24, 16]          65,664\n",
      "             ELU-246          [-1, 128, 24, 16]               0\n",
      "          Conv2d-247          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-248          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-249          [-1, 128, 24, 16]          16,512\n",
      "             ELU-250          [-1, 128, 24, 16]               0\n",
      "          Conv2d-251          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-252          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-253          [-1, 128, 24, 16]          16,512\n",
      "             ELU-254          [-1, 128, 24, 16]               0\n",
      "      InceptionB-255          [-1, 512, 24, 16]               0\n",
      "          Conv2d-256          [-1, 128, 24, 16]          65,664\n",
      "       MaxPool2d-257          [-1, 128, 24, 16]               0\n",
      "             ELU-258          [-1, 128, 24, 16]               0\n",
      "          Conv2d-259          [-1, 128, 24, 16]          65,664\n",
      "             ELU-260          [-1, 128, 24, 16]               0\n",
      "          Conv2d-261          [-1, 128, 24, 16]          65,664\n",
      "             ELU-262          [-1, 128, 24, 16]               0\n",
      "          Conv2d-263          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-264          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-265          [-1, 128, 24, 16]          16,512\n",
      "             ELU-266          [-1, 128, 24, 16]               0\n",
      "          Conv2d-267          [-1, 128, 24, 16]          65,664\n",
      "             ELU-268          [-1, 128, 24, 16]               0\n",
      "          Conv2d-269          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-270          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-271          [-1, 128, 24, 16]          16,512\n",
      "             ELU-272          [-1, 128, 24, 16]               0\n",
      "          Conv2d-273          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-274          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-275          [-1, 128, 24, 16]          16,512\n",
      "             ELU-276          [-1, 128, 24, 16]               0\n",
      "      InceptionB-277          [-1, 512, 24, 16]               0\n",
      "          Conv2d-278          [-1, 128, 24, 16]          65,664\n",
      "       MaxPool2d-279          [-1, 128, 24, 16]               0\n",
      "             ELU-280          [-1, 128, 24, 16]               0\n",
      "          Conv2d-281          [-1, 128, 24, 16]          65,664\n",
      "             ELU-282          [-1, 128, 24, 16]               0\n",
      "          Conv2d-283          [-1, 128, 24, 16]          65,664\n",
      "             ELU-284          [-1, 128, 24, 16]               0\n",
      "          Conv2d-285          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-286          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-287          [-1, 128, 24, 16]          16,512\n",
      "             ELU-288          [-1, 128, 24, 16]               0\n",
      "          Conv2d-289          [-1, 128, 24, 16]          65,664\n",
      "             ELU-290          [-1, 128, 24, 16]               0\n",
      "          Conv2d-291          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-292          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-293          [-1, 128, 24, 16]          16,512\n",
      "             ELU-294          [-1, 128, 24, 16]               0\n",
      "          Conv2d-295          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-296          [-1, 128, 24, 16]           1,024\n",
      "          Conv2d-297          [-1, 128, 24, 16]          16,512\n",
      "             ELU-298          [-1, 128, 24, 16]               0\n",
      "      InceptionB-299          [-1, 512, 24, 16]               0\n",
      "       MaxPool2d-300           [-1, 512, 12, 8]               0\n",
      "             ELU-301           [-1, 512, 12, 8]               0\n",
      "          Conv2d-302          [-1, 256, 24, 16]         131,328\n",
      "             ELU-303          [-1, 256, 24, 16]               0\n",
      "          Conv2d-304          [-1, 256, 12, 16]           1,024\n",
      "          Conv2d-305           [-1, 256, 12, 8]           1,024\n",
      "          Conv2d-306           [-1, 256, 12, 8]          65,792\n",
      "             ELU-307           [-1, 256, 12, 8]               0\n",
      "          Conv2d-308          [-1, 256, 24, 16]         131,328\n",
      "             ELU-309          [-1, 256, 24, 16]               0\n",
      "          Conv2d-310          [-1, 256, 24, 16]           2,048\n",
      "          Conv2d-311          [-1, 256, 24, 16]           2,048\n",
      "          Conv2d-312          [-1, 256, 24, 16]          65,792\n",
      "             ELU-313          [-1, 256, 24, 16]               0\n",
      "          Conv2d-314          [-1, 256, 12, 16]           1,024\n",
      "          Conv2d-315           [-1, 256, 12, 8]           1,024\n",
      "          Conv2d-316           [-1, 256, 12, 8]          65,792\n",
      "             ELU-317           [-1, 256, 12, 8]               0\n",
      "          Conv2d-318         [-1, 1024, 12, 16]           4,096\n",
      "          Conv2d-319          [-1, 1024, 12, 8]           4,096\n",
      "          Conv2d-320          [-1, 1024, 12, 8]       1,049,600\n",
      "      ReductionB-321          [-1, 1024, 12, 8]               0\n",
      "          Conv2d-322           [-1, 256, 12, 8]         262,400\n",
      "       MaxPool2d-323           [-1, 256, 12, 8]               0\n",
      "             ELU-324           [-1, 256, 12, 8]               0\n",
      "          Conv2d-325           [-1, 256, 12, 8]         262,400\n",
      "             ELU-326           [-1, 256, 12, 8]               0\n",
      "          Conv2d-327           [-1, 256, 12, 8]         262,400\n",
      "             ELU-328           [-1, 256, 12, 8]               0\n",
      "          Conv2d-329           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-330           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-331           [-1, 256, 12, 8]          65,792\n",
      "             ELU-332           [-1, 256, 12, 8]               0\n",
      "          Conv2d-333           [-1, 256, 12, 8]         262,400\n",
      "             ELU-334           [-1, 256, 12, 8]               0\n",
      "          Conv2d-335           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-336           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-337           [-1, 256, 12, 8]          65,792\n",
      "             ELU-338           [-1, 256, 12, 8]               0\n",
      "          Conv2d-339           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-340           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-341           [-1, 256, 12, 8]          65,792\n",
      "             ELU-342           [-1, 256, 12, 8]               0\n",
      "      InceptionB-343          [-1, 1024, 12, 8]               0\n",
      "          Conv2d-344           [-1, 256, 12, 8]         262,400\n",
      "       MaxPool2d-345           [-1, 256, 12, 8]               0\n",
      "             ELU-346           [-1, 256, 12, 8]               0\n",
      "          Conv2d-347           [-1, 256, 12, 8]         262,400\n",
      "             ELU-348           [-1, 256, 12, 8]               0\n",
      "          Conv2d-349           [-1, 256, 12, 8]         262,400\n",
      "             ELU-350           [-1, 256, 12, 8]               0\n",
      "          Conv2d-351           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-352           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-353           [-1, 256, 12, 8]          65,792\n",
      "             ELU-354           [-1, 256, 12, 8]               0\n",
      "          Conv2d-355           [-1, 256, 12, 8]         262,400\n",
      "             ELU-356           [-1, 256, 12, 8]               0\n",
      "          Conv2d-357           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-358           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-359           [-1, 256, 12, 8]          65,792\n",
      "             ELU-360           [-1, 256, 12, 8]               0\n",
      "          Conv2d-361           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-362           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-363           [-1, 256, 12, 8]          65,792\n",
      "             ELU-364           [-1, 256, 12, 8]               0\n",
      "      InceptionB-365          [-1, 1024, 12, 8]               0\n",
      "          Conv2d-366           [-1, 256, 12, 8]         262,400\n",
      "       MaxPool2d-367           [-1, 256, 12, 8]               0\n",
      "             ELU-368           [-1, 256, 12, 8]               0\n",
      "          Conv2d-369           [-1, 256, 12, 8]         262,400\n",
      "             ELU-370           [-1, 256, 12, 8]               0\n",
      "          Conv2d-371           [-1, 256, 12, 8]         262,400\n",
      "             ELU-372           [-1, 256, 12, 8]               0\n",
      "          Conv2d-373           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-374           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-375           [-1, 256, 12, 8]          65,792\n",
      "             ELU-376           [-1, 256, 12, 8]               0\n",
      "          Conv2d-377           [-1, 256, 12, 8]         262,400\n",
      "             ELU-378           [-1, 256, 12, 8]               0\n",
      "          Conv2d-379           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-380           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-381           [-1, 256, 12, 8]          65,792\n",
      "             ELU-382           [-1, 256, 12, 8]               0\n",
      "          Conv2d-383           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-384           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-385           [-1, 256, 12, 8]          65,792\n",
      "             ELU-386           [-1, 256, 12, 8]               0\n",
      "      InceptionB-387          [-1, 1024, 12, 8]               0\n",
      "          Conv2d-388           [-1, 256, 12, 8]         262,400\n",
      "       MaxPool2d-389           [-1, 256, 12, 8]               0\n",
      "             ELU-390           [-1, 256, 12, 8]               0\n",
      "          Conv2d-391           [-1, 256, 12, 8]         262,400\n",
      "             ELU-392           [-1, 256, 12, 8]               0\n",
      "          Conv2d-393           [-1, 256, 12, 8]         262,400\n",
      "             ELU-394           [-1, 256, 12, 8]               0\n",
      "          Conv2d-395           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-396           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-397           [-1, 256, 12, 8]          65,792\n",
      "             ELU-398           [-1, 256, 12, 8]               0\n",
      "          Conv2d-399           [-1, 256, 12, 8]         262,400\n",
      "             ELU-400           [-1, 256, 12, 8]               0\n",
      "          Conv2d-401           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-402           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-403           [-1, 256, 12, 8]          65,792\n",
      "             ELU-404           [-1, 256, 12, 8]               0\n",
      "          Conv2d-405           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-406           [-1, 256, 12, 8]           2,048\n",
      "          Conv2d-407           [-1, 256, 12, 8]          65,792\n",
      "             ELU-408           [-1, 256, 12, 8]               0\n",
      "      InceptionB-409          [-1, 1024, 12, 8]               0\n",
      "       MaxPool2d-410           [-1, 1024, 6, 4]               0\n",
      "             ELU-411           [-1, 1024, 6, 4]               0\n",
      "          Conv2d-412           [-1, 512, 12, 8]         524,800\n",
      "             ELU-413           [-1, 512, 12, 8]               0\n",
      "          Conv2d-414            [-1, 512, 6, 8]           2,048\n",
      "          Conv2d-415            [-1, 512, 6, 4]           2,048\n",
      "          Conv2d-416            [-1, 512, 6, 4]         262,656\n",
      "             ELU-417            [-1, 512, 6, 4]               0\n",
      "          Conv2d-418           [-1, 512, 12, 8]         524,800\n",
      "             ELU-419           [-1, 512, 12, 8]               0\n",
      "          Conv2d-420           [-1, 512, 12, 8]           4,096\n",
      "          Conv2d-421           [-1, 512, 12, 8]           4,096\n",
      "          Conv2d-422           [-1, 512, 12, 8]         262,656\n",
      "             ELU-423           [-1, 512, 12, 8]               0\n",
      "          Conv2d-424            [-1, 512, 6, 8]           2,048\n",
      "          Conv2d-425            [-1, 512, 6, 4]           2,048\n",
      "          Conv2d-426            [-1, 512, 6, 4]         262,656\n",
      "             ELU-427            [-1, 512, 6, 4]               0\n",
      "          Conv2d-428           [-1, 2048, 6, 8]           8,192\n",
      "          Conv2d-429           [-1, 2048, 6, 4]           8,192\n",
      "          Conv2d-430           [-1, 2048, 6, 4]       4,196,352\n",
      "      ReductionB-431           [-1, 2048, 6, 4]               0\n",
      "          Conv2d-432            [-1, 512, 6, 4]       1,049,088\n",
      "       MaxPool2d-433            [-1, 512, 6, 4]               0\n",
      "             ELU-434            [-1, 512, 6, 4]               0\n",
      "          Conv2d-435            [-1, 512, 6, 4]       1,049,088\n",
      "             ELU-436            [-1, 512, 6, 4]               0\n",
      "          Conv2d-437            [-1, 512, 6, 4]       1,049,088\n",
      "             ELU-438            [-1, 512, 6, 4]               0\n",
      "          Conv2d-439            [-1, 512, 6, 4]           4,096\n",
      "          Conv2d-440            [-1, 512, 6, 4]           4,096\n",
      "          Conv2d-441            [-1, 512, 6, 4]         262,656\n",
      "             ELU-442            [-1, 512, 6, 4]               0\n",
      "          Conv2d-443            [-1, 512, 6, 4]       1,049,088\n",
      "             ELU-444            [-1, 512, 6, 4]               0\n",
      "          Conv2d-445            [-1, 512, 6, 4]           4,096\n",
      "          Conv2d-446            [-1, 512, 6, 4]           4,096\n",
      "          Conv2d-447            [-1, 512, 6, 4]         262,656\n",
      "             ELU-448            [-1, 512, 6, 4]               0\n",
      "          Conv2d-449            [-1, 512, 6, 4]           4,096\n",
      "          Conv2d-450            [-1, 512, 6, 4]           4,096\n",
      "          Conv2d-451            [-1, 512, 6, 4]         262,656\n",
      "             ELU-452            [-1, 512, 6, 4]               0\n",
      "      InceptionB-453           [-1, 2048, 6, 4]               0\n",
      "       AvgPool2d-454           [-1, 2048, 1, 1]               0\n",
      "          Linear-455                  [-1, 256]         524,544\n",
      "             ELU-456                  [-1, 256]               0\n",
      "          Linear-457                   [-1, 64]          16,448\n",
      "             ELU-458                   [-1, 64]               0\n",
      "          Linear-459                   [-1, 24]           1,560\n",
      "             ELU-460                   [-1, 24]               0\n",
      "          Linear-461                    [-1, 8]             520\n",
      "            Tanh-462                    [-1, 8]               0\n",
      "          Linear-463                    [-1, 1]              33\n",
      "         Sigmoid-464                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 20,275,201\n",
      "Trainable params: 20,275,201\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 9.00\n",
      "Forward/backward pass size (MB): 1114.80\n",
      "Params size (MB): 77.34\n",
      "Estimated Total Size (MB): 1201.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import Lossv2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "summary(Lossv2.Loss().to(device), (6, 768, 512))  ###  IDK why, but I have to switch the dims in AvgPool on Loss() to get this to work :/ But that breaks the stuff bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.manual_seed(100)\n",
    "np.random.seed(100)\n",
    "import Lossv2\n",
    "import generateLossImages\n",
    "import time\n",
    "\n",
    "global counter \n",
    "counter = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def save_ckp(state, is_best, checkpoint_dir=\"./models/rest/\", best_model_dir=\"./models/best/\"):\n",
    "    global counter \n",
    "    f_path = checkpoint_dir + str(counter) + '_checkpoint.pt'\n",
    "    counter = counter + 1\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_dir + 'best_model.pt'\n",
    "        shutil.copyfile(f_path, best_fpath)\n",
    "\n",
    "def load_ckp(model, optimizer, checkpoint_fpath=\"./models/best/best_model.pt\"):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch'], checkpoint['index'], checkpoint['min_lr'], checkpoint['max_lr'], checkpoint['steps'], checkpoint['step_size'], checkpoint['falling'], checkpoint['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "min_lr = 0.0003\n",
    "max_lr = 0.001\n",
    "decay = 0.8\n",
    "steps = 300\n",
    "falling = True\n",
    "start_epoch = 0\n",
    "start_index = 0\n",
    "threshold = [0.24, 0.2, 0.16, 0.12, 0.09, 0.06, 0.04, 0.03, 0.02, 0.015, 0.01 -1]\n",
    "step_size = (max_lr-min_lr)/steps\n",
    "model = Lossv2.Loss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=max_lr, momentum=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "model = Lossv2.Loss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.96)\n",
    "model, optimizer, start_epoch, start_index, min_lr, max_lr, steps, step_size, falling, threshold = load_ckp(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.72382749606882, 0.012452385971162576, 0.0008301326924880367, 24.049694721718666, 0.40403351288996003, 39.11279737602433, 10.22638426619226, 0.4699801084423085]\n"
     ]
    }
   ],
   "source": [
    "li = [31.007527351379395, 0.01501011848449707, 0.0010006427764892578, 28.98952603340149, 0.48702239990234375, 47.146605014801025, 12.32689380645752, 0.5665144920349121]\n",
    "su = sum(li)\n",
    "print([100*l/su for l in li])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rani\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009976666666666667\n",
      "  batch 117 loss: 0.2686974798512255\n",
      "[('0.506', '0.001'), ('0.506', '0.001'), ('0.506', '0.001'), ('0.506', '0.001'), ('0.506', '0.001'), ('0.506', '0.001'), ('0.506', '0.001'), ('0.507', '0.001'), ('0.506', '0.001'), ('0.511', '0.001'), ('0.508', '0.999'), ('0.51', '0.999'), ('0.515', '0.999'), ('0.512', '0.999'), ('0.511', '0.999'), ('0.519', '0.999'), ('0.518', '0.999'), ('0.511', '0.999'), ('0.502', '0.999'), ('0.505', '0.999'), ('0.511', '0.999'), ('0.498', '0.999'), ('0.506', '0.2'), ('0.506', '0.2'), ('0.506', '0.2'), ('0.506', '0.2'), ('0.506', '0.2'), ('0.506', '0.2'), ('0.508', '0.2'), ('0.506', '0.2'), ('0.511', '0.2'), ('0.508', '0.2'), ('0.508', '0.2'), ('0.513', '0.6'), ('0.511', '0.6'), ('0.512', '0.6'), ('0.509', '0.6'), ('0.509', '0.6'), ('0.515', '0.6'), ('0.517', '0.6'), ('0.508', '0.6'), ('0.514', '0.6'), ('0.515', '0.6'), ('0.513', '0.6'), ('0.513', '0.6'), ('0.508', '0.4'), ('0.507', '0.4'), ('0.507', '0.4'), ('0.507', '0.4'), ('0.507', '0.4'), ('0.509', '0.4'), ('0.514', '0.4'), ('0.507', '0.4'), ('0.51', '0.4'), ('0.511', '0.4'), ('0.51', '0.4'), ('0.51', '0.4'), ('0.515', '0.8'), ('0.516', '0.8'), ('0.514', '0.8'), ('0.511', '0.8'), ('0.51', '0.8'), ('0.518', '0.8'), ('0.518', '0.8'), ('0.509', '0.8'), ('0.514', '0.8'), ('0.514', '0.8'), ('0.514', '0.8'), ('0.514', '0.8'), ('0.512', '0.8'), ('0.502', '0.8'), ('0.506', '0.1'), ('0.506', '0.1'), ('0.506', '0.1'), ('0.506', '0.1'), ('0.506', '0.1'), ('0.506', '0.1'), ('0.507', '0.1'), ('0.506', '0.1'), ('0.511', '0.9'), ('0.513', '0.9'), ('0.515', '0.9'), ('0.511', '0.9'), ('0.511', '0.9'), ('0.519', '0.9'), ('0.518', '0.9'), ('0.51', '0.9'), ('0.511', '0.9'), ('0.498', '0.9'), ('0.515', '0.7'), ('0.515', '0.7'), ('0.513', '0.7'), ('0.51', '0.7'), ('0.509', '0.7'), ('0.516', '0.7'), ('0.518', '0.7'), ('0.509', '0.7'), ('0.514', '0.7'), ('0.509', '0.7'), ('0.507', '0.3'), ('0.506', '0.3'), ('0.506', '0.3'), ('0.507', '0.3'), ('0.506', '0.3'), ('0.507', '0.3'), ('0.511', '0.3'), ('0.506', '0.3'), ('0.51', '0.5'), ('0.509', '0.5'), ('0.51', '0.5'), ('0.508', '0.5'), ('0.508', '0.5'), ('0.512', '0.5'), ('0.516', '0.5'), ('0.508', '0.5'), ('0.511', '0.5'), ('0.512', '0.5')]\n",
      "5.9999999999999995e-05\n",
      "0.0002\n",
      "300\n",
      "4.666666666666667e-07\n",
      "0.0002\n",
      "  batch 234 loss: 0.22094676841018546\n",
      "[('0.516', '0.001'), ('0.521', '0.001'), ('0.518', '0.001'), ('0.518', '0.001'), ('0.52', '0.001'), ('0.518', '0.001'), ('0.517', '0.001'), ('0.523', '0.001'), ('0.523', '0.001'), ('0.633', '0.001'), ('0.773', '0.999'), ('0.768', '0.999'), ('0.716', '0.999'), ('0.627', '0.999'), ('0.626', '0.999'), ('0.657', '0.999'), ('0.702', '0.999'), ('0.625', '0.999'), ('0.795', '0.999'), ('0.784', '0.999'), ('0.764', '0.999'), ('0.803', '0.999'), ('0.534', '0.2'), ('0.527', '0.2'), ('0.527', '0.2'), ('0.532', '0.2'), ('0.527', '0.2'), ('0.523', '0.2'), ('0.539', '0.2'), ('0.535', '0.2'), ('0.608', '0.2'), ('0.566', '0.2'), ('0.566', '0.2'), ('0.649', '0.6'), ('0.634', '0.6'), ('0.642', '0.6'), ('0.587', '0.6'), ('0.595', '0.6'), ('0.603', '0.6'), ('0.655', '0.6'), ('0.597', '0.6'), ('0.704', '0.6'), ('0.723', '0.6'), ('0.674', '0.6'), ('0.695', '0.6'), ('0.586', '0.4'), ('0.569', '0.4'), ('0.56', '0.4'), ('0.557', '0.4'), ('0.56', '0.4'), ('0.555', '0.4'), ('0.612', '0.4'), ('0.576', '0.4'), ('0.616', '0.4'), ('0.63', '0.4'), ('0.602', '0.4'), ('0.609', '0.4'), ('0.721', '0.8'), ('0.71', '0.8'), ('0.681', '0.8'), ('0.611', '0.8'), ('0.616', '0.8'), ('0.638', '0.8'), ('0.688', '0.8'), ('0.61', '0.8'), ('0.704', '0.8'), ('0.735', '0.8'), ('0.68', '0.8'), ('0.683', '0.8'), ('0.747', '0.8'), ('0.786', '0.8'), ('0.527', '0.1'), ('0.522', '0.1'), ('0.521', '0.1'), ('0.525', '0.1'), ('0.521', '0.1'), ('0.519', '0.1'), ('0.531', '0.1'), ('0.53', '0.1'), ('0.755', '0.9'), ('0.748', '0.9'), ('0.708', '0.9'), ('0.619', '0.9'), ('0.621', '0.9'), ('0.648', '0.9'), ('0.695', '0.9'), ('0.617', '0.9'), ('0.76', '0.9'), ('0.801', '0.9'), ('0.691', '0.7'), ('0.682', '0.7'), ('0.665', '0.7'), ('0.604', '0.7'), ('0.606', '0.7'), ('0.621', '0.7'), ('0.672', '0.7'), ('0.604', '0.7'), ('0.713', '0.7'), ('0.753', '0.7'), ('0.56', '0.3'), ('0.544', '0.3'), ('0.539', '0.3'), ('0.547', '0.3'), ('0.536', '0.3'), ('0.53', '0.3'), ('0.574', '0.3'), ('0.557', '0.3'), ('0.618', '0.5'), ('0.597', '0.5'), ('0.608', '0.5'), ('0.573', '0.5'), ('0.578', '0.5'), ('0.579', '0.5'), ('0.635', '0.5'), ('0.587', '0.5'), ('0.636', '0.5'), ('0.656', '0.5')]\n",
      "0.00019953333333333335\n",
      "  batch 351 loss: 0.21620175318840223\n",
      "[('0.51', '0.001'), ('0.516', '0.001'), ('0.513', '0.001'), ('0.512', '0.001'), ('0.515', '0.001'), ('0.512', '0.001'), ('0.511', '0.001'), ('0.518', '0.001'), ('0.517', '0.001'), ('0.659', '0.001'), ('0.809', '0.999'), ('0.8', '0.999'), ('0.748', '0.999'), ('0.646', '0.999'), ('0.646', '0.999'), ('0.68', '0.999'), ('0.729', '0.999'), ('0.641', '0.999'), ('0.83', '0.999'), ('0.82', '0.999'), ('0.8', '0.999'), ('0.843', '0.999'), ('0.532', '0.2'), ('0.523', '0.2'), ('0.524', '0.2'), ('0.528', '0.2'), ('0.522', '0.2'), ('0.518', '0.2'), ('0.538', '0.2'), ('0.533', '0.2'), ('0.626', '0.2'), ('0.575', '0.2'), ('0.576', '0.2'), ('0.667', '0.6'), ('0.651', '0.6'), ('0.66', '0.6'), ('0.595', '0.6'), ('0.606', '0.6'), ('0.618', '0.6'), ('0.675', '0.6'), ('0.607', '0.6'), ('0.748', '0.6'), ('0.758', '0.6'), ('0.698', '0.6'), ('0.726', '0.6'), ('0.594', '0.4'), ('0.573', '0.4'), ('0.563', '0.4'), ('0.56', '0.4'), ('0.563', '0.4'), ('0.557', '0.4'), ('0.626', '0.4'), ('0.584', '0.4'), ('0.629', '0.4'), ('0.648', '0.4'), ('0.619', '0.4'), ('0.627', '0.4'), ('0.748', '0.8'), ('0.735', '0.8'), ('0.706', '0.8'), ('0.624', '0.8'), ('0.632', '0.8'), ('0.658', '0.8'), ('0.713', '0.8'), ('0.622', '0.8'), ('0.748', '0.8'), ('0.775', '0.8'), ('0.7', '0.8'), ('0.705', '0.8'), ('0.781', '0.8'), ('0.824', '0.8'), ('0.523', '0.1'), ('0.518', '0.1'), ('0.516', '0.1'), ('0.52', '0.1'), ('0.516', '0.1'), ('0.514', '0.1'), ('0.529', '0.1'), ('0.526', '0.1'), ('0.788', '0.9'), ('0.779', '0.9'), ('0.738', '0.9'), ('0.636', '0.9'), ('0.639', '0.9'), ('0.669', '0.9'), ('0.721', '0.9'), ('0.631', '0.9'), ('0.797', '0.9'), ('0.84', '0.9'), ('0.716', '0.7'), ('0.706', '0.7'), ('0.686', '0.7'), ('0.616', '0.7'), ('0.62', '0.7'), ('0.639', '0.7'), ('0.695', '0.7'), ('0.616', '0.7'), ('0.744', '0.7'), ('0.789', '0.7'), ('0.563', '0.3'), ('0.544', '0.3'), ('0.538', '0.3'), ('0.548', '0.3'), ('0.534', '0.3'), ('0.526', '0.3'), ('0.58', '0.3'), ('0.56', '0.3'), ('0.633', '0.5'), ('0.608', '0.5'), ('0.619', '0.5'), ('0.578', '0.5'), ('0.585', '0.5'), ('0.588', '0.5'), ('0.652', '0.5'), ('0.596', '0.5'), ('0.655', '0.5'), ('0.679', '0.5')]\n",
      "0.0001990666666666667\n",
      "  batch 468 loss: 0.20774045382809436\n",
      "[('0.493', '0.001'), ('0.5', '0.001'), ('0.496', '0.001'), ('0.496', '0.001'), ('0.499', '0.001'), ('0.496', '0.001'), ('0.494', '0.001'), ('0.503', '0.001'), ('0.503', '0.001'), ('0.663', '0.001'), ('0.846', '0.999'), ('0.837', '0.999'), ('0.777', '0.999'), ('0.66', '0.999'), ('0.659', '0.999'), ('0.696', '0.999'), ('0.754', '0.999'), ('0.655', '0.999'), ('0.871', '0.999'), ('0.861', '0.999'), ('0.836', '0.999'), ('0.881', '0.999'), ('0.518', '0.2'), ('0.508', '0.2'), ('0.509', '0.2'), ('0.516', '0.2'), ('0.508', '0.2'), ('0.502', '0.2'), ('0.525', '0.2'), ('0.521', '0.2'), ('0.625', '0.2'), ('0.563', '0.2'), ('0.564', '0.2'), ('0.682', '0.6'), ('0.661', '0.6'), ('0.674', '0.6'), ('0.597', '0.6'), ('0.61', '0.6'), ('0.623', '0.6'), ('0.69', '0.6'), ('0.609', '0.6'), ('0.759', '0.6'), ('0.792', '0.6'), ('0.721', '0.6'), ('0.751', '0.6'), ('0.593', '0.4'), ('0.566', '0.4'), ('0.556', '0.4'), ('0.554', '0.4'), ('0.558', '0.4'), ('0.549', '0.4'), ('0.631', '0.4'), ('0.58', '0.4'), ('0.634', '0.4'), ('0.658', '0.4'), ('0.616', '0.4'), ('0.625', '0.4'), ('0.778', '0.8'), ('0.762', '0.8'), ('0.729', '0.8'), ('0.632', '0.8'), ('0.641', '0.8'), ('0.67', '0.8'), ('0.735', '0.8'), ('0.628', '0.8'), ('0.759', '0.8'), ('0.81', '0.8'), ('0.73', '0.8'), ('0.734', '0.8'), ('0.813', '0.8'), ('0.863', '0.8'), ('0.508', '0.1'), ('0.502', '0.1'), ('0.5', '0.1'), ('0.506', '0.1'), ('0.501', '0.1'), ('0.497', '0.1'), ('0.514', '0.1'), ('0.513', '0.1'), ('0.821', '0.9'), ('0.812', '0.9'), ('0.764', '0.9'), ('0.647', '0.9'), ('0.651', '0.9'), ('0.684', '0.9'), ('0.745', '0.9'), ('0.64', '0.9'), ('0.833', '0.9'), ('0.881', '0.9'), ('0.739', '0.7'), ('0.727', '0.7'), ('0.706', '0.7'), ('0.622', '0.7'), ('0.627', '0.7'), ('0.648', '0.7'), ('0.714', '0.7'), ('0.62', '0.7'), ('0.772', '0.7'), ('0.822', '0.7'), ('0.555', '0.3'), ('0.532', '0.3'), ('0.525', '0.3'), ('0.538', '0.3'), ('0.522', '0.3'), ('0.512', '0.3'), ('0.576', '0.3'), ('0.552', '0.3'), ('0.64', '0.5'), ('0.609', '0.5'), ('0.624', '0.5'), ('0.577', '0.5'), ('0.585', '0.5'), ('0.586', '0.5'), ('0.663', '0.5'), ('0.595', '0.5'), ('0.665', '0.5'), ('0.694', '0.5')]\n",
      "1.2e-05\n",
      "4e-05\n",
      "300\n",
      "9.333333333333335e-08\n",
      "4e-05\n",
      "  batch 585 loss: 0.195993669776835\n",
      "[('0.463', '0.001'), ('0.471', '0.001'), ('0.467', '0.001'), ('0.466', '0.001'), ('0.469', '0.001'), ('0.464', '0.001'), ('0.465', '0.001'), ('0.47', '0.001'), ('0.466', '0.001'), ('0.62', '0.001'), ('0.872', '0.999'), ('0.859', '0.999'), ('0.796', '0.999'), ('0.621', '0.999'), ('0.612', '0.999'), ('0.67', '0.999'), ('0.725', '0.999'), ('0.609', '0.999'), ('0.895', '0.999'), ('0.877', '0.999'), ('0.863', '0.999'), ('0.868', '0.999'), ('0.49', '0.2'), ('0.479', '0.2'), ('0.479', '0.2'), ('0.483', '0.2'), ('0.468', '0.2'), ('0.473', '0.2'), ('0.486', '0.2'), ('0.476', '0.2'), ('0.569', '0.2'), ('0.517', '0.2'), ('0.517', '0.2'), ('0.685', '0.6'), ('0.661', '0.6'), ('0.673', '0.6'), ('0.558', '0.6'), ('0.558', '0.6'), ('0.594', '0.6'), ('0.65', '0.6'), ('0.56', '0.6'), ('0.738', '0.6'), ('0.733', '0.6'), ('0.731', '0.6'), ('0.716', '0.6'), ('0.575', '0.4'), ('0.545', '0.4'), ('0.532', '0.4'), ('0.514', '0.4'), ('0.502', '0.4'), ('0.525', '0.4'), ('0.584', '0.4'), ('0.525', '0.4'), ('0.637', '0.4'), ('0.618', '0.4'), ('0.563', '0.4'), ('0.574', '0.4'), ('0.794', '0.8'), ('0.78', '0.8'), ('0.74', '0.8'), ('0.595', '0.8'), ('0.595', '0.8'), ('0.642', '0.8'), ('0.703', '0.8'), ('0.583', '0.8'), ('0.738', '0.8'), ('0.774', '0.8'), ('0.668', '0.8'), ('0.672', '0.8'), ('0.841', '0.8'), ('0.845', '0.8'), ('0.479', '0.1'), ('0.472', '0.1'), ('0.471', '0.1'), ('0.475', '0.1'), ('0.465', '0.1'), ('0.468', '0.1'), ('0.478', '0.1'), ('0.471', '0.1'), ('0.845', '0.9'), ('0.833', '0.9'), ('0.783', '0.9'), ('0.61', '0.9'), ('0.605', '0.9'), ('0.656', '0.9'), ('0.714', '0.9'), ('0.596', '0.9'), ('0.86', '0.9'), ('0.867', '0.9'), ('0.751', '0.7'), ('0.737', '0.7'), ('0.713', '0.7'), ('0.583', '0.7'), ('0.579', '0.7'), ('0.618', '0.7'), ('0.678', '0.7'), ('0.572', '0.7'), ('0.793', '0.7'), ('0.8', '0.7'), ('0.531', '0.3'), ('0.504', '0.3'), ('0.497', '0.3'), ('0.501', '0.3'), ('0.475', '0.3'), ('0.484', '0.3'), ('0.529', '0.3'), ('0.499', '0.3'), ('0.632', '0.5'), ('0.595', '0.5'), ('0.615', '0.5'), ('0.535', '0.5'), ('0.529', '0.5'), ('0.562', '0.5'), ('0.618', '0.5'), ('0.544', '0.5'), ('0.673', '0.5'), ('0.653', '0.5')]\n",
      "3.990666666666667e-05\n",
      "  batch 702 loss: 0.19242250511788914\n",
      "[('0.455', '0.001'), ('0.463', '0.001'), ('0.459', '0.001'), ('0.458', '0.001'), ('0.461', '0.001'), ('0.456', '0.001'), ('0.457', '0.001'), ('0.462', '0.001'), ('0.459', '0.001'), ('0.596', '0.001'), ('0.877', '0.999'), ('0.862', '0.999'), ('0.799', '0.999'), ('0.617', '0.999'), ('0.605', '0.999'), ('0.669', '0.999'), ('0.728', '0.999'), ('0.601', '0.999'), ('0.9', '0.999'), ('0.88', '0.999'), ('0.869', '0.999'), ('0.877', '0.999'), ('0.481', '0.2'), ('0.471', '0.2'), ('0.472', '0.2'), ('0.475', '0.2'), ('0.46', '0.2'), ('0.465', '0.2'), ('0.479', '0.2'), ('0.469', '0.2'), ('0.558', '0.2'), ('0.502', '0.2'), ('0.502', '0.2'), ('0.683', '0.6'), ('0.659', '0.6'), ('0.672', '0.6'), ('0.552', '0.6'), ('0.551', '0.6'), ('0.59', '0.6'), ('0.649', '0.6'), ('0.553', '0.6'), ('0.734', '0.6'), ('0.735', '0.6'), ('0.73', '0.6'), ('0.72', '0.6'), ('0.57', '0.4'), ('0.537', '0.4'), ('0.524', '0.4'), ('0.507', '0.4'), ('0.495', '0.4'), ('0.517', '0.4'), ('0.58', '0.4'), ('0.52', '0.4'), ('0.63', '0.4'), ('0.611', '0.4'), ('0.541', '0.4'), ('0.551', '0.4'), ('0.798', '0.8'), ('0.781', '0.8'), ('0.742', '0.8'), ('0.588', '0.8'), ('0.588', '0.8'), ('0.64', '0.8'), ('0.705', '0.8'), ('0.575', '0.8'), ('0.734', '0.8'), ('0.777', '0.8'), ('0.671', '0.8'), ('0.674', '0.8'), ('0.845', '0.8'), ('0.853', '0.8'), ('0.471', '0.1'), ('0.464', '0.1'), ('0.463', '0.1'), ('0.467', '0.1'), ('0.457', '0.1'), ('0.46', '0.1'), ('0.471', '0.1'), ('0.464', '0.1'), ('0.85', '0.9'), ('0.835', '0.9'), ('0.787', '0.9'), ('0.603', '0.9'), ('0.597', '0.9'), ('0.655', '0.9'), ('0.717', '0.9'), ('0.588', '0.9'), ('0.864', '0.9'), ('0.875', '0.9'), ('0.752', '0.7'), ('0.739', '0.7'), ('0.715', '0.7'), ('0.578', '0.7'), ('0.572', '0.7'), ('0.615', '0.7'), ('0.678', '0.7'), ('0.565', '0.7'), ('0.796', '0.7'), ('0.81', '0.7'), ('0.523', '0.3'), ('0.496', '0.3'), ('0.49', '0.3'), ('0.493', '0.3'), ('0.467', '0.3'), ('0.476', '0.3'), ('0.523', '0.3'), ('0.492', '0.3'), ('0.628', '0.5'), ('0.589', '0.5'), ('0.608', '0.5'), ('0.529', '0.5'), ('0.522', '0.5'), ('0.557', '0.5'), ('0.616', '0.5'), ('0.538', '0.5'), ('0.667', '0.5'), ('0.65', '0.5')]\n",
      "3.9813333333333334e-05\n",
      "  batch 819 loss: 0.18932531608475578\n",
      "[('0.446', '0.001'), ('0.453', '0.001'), ('0.449', '0.001'), ('0.448', '0.001'), ('0.451', '0.001'), ('0.446', '0.001'), ('0.447', '0.001'), ('0.452', '0.001'), ('0.448', '0.001'), ('0.593', '0.001'), ('0.881', '0.999'), ('0.865', '0.999'), ('0.809', '0.999'), ('0.615', '0.999'), ('0.602', '0.999'), ('0.652', '0.999'), ('0.697', '0.999'), ('0.587', '0.999'), ('0.904', '0.999'), ('0.882', '0.999'), ('0.88', '0.999'), ('0.857', '0.999'), ('0.471', '0.2'), ('0.461', '0.2'), ('0.462', '0.2'), ('0.465', '0.2'), ('0.45', '0.2'), ('0.455', '0.2'), ('0.466', '0.2'), ('0.457', '0.2'), ('0.552', '0.2'), ('0.49', '0.2'), ('0.49', '0.2'), ('0.68', '0.6'), ('0.655', '0.6'), ('0.673', '0.6'), ('0.543', '0.6'), ('0.542', '0.6'), ('0.577', '0.6'), ('0.617', '0.6'), ('0.534', '0.6'), ('0.732', '0.6'), ('0.748', '0.6'), ('0.74', '0.6'), ('0.692', '0.6'), ('0.56', '0.4'), ('0.528', '0.4'), ('0.515', '0.4'), ('0.498', '0.4'), ('0.485', '0.4'), ('0.509', '0.4'), ('0.552', '0.4'), ('0.501', '0.4'), ('0.632', '0.4'), ('0.587', '0.4'), ('0.531', '0.4'), ('0.541', '0.4'), ('0.798', '0.8'), ('0.781', '0.8'), ('0.751', '0.8'), ('0.583', '0.8'), ('0.583', '0.8'), ('0.624', '0.8'), ('0.673', '0.8'), ('0.557', '0.8'), ('0.732', '0.8'), ('0.784', '0.8'), ('0.644', '0.8'), ('0.651', '0.8'), ('0.856', '0.8'), ('0.832', '0.8'), ('0.461', '0.1'), ('0.454', '0.1'), ('0.453', '0.1'), ('0.457', '0.1'), ('0.447', '0.1'), ('0.45', '0.1'), ('0.459', '0.1'), ('0.452', '0.1'), ('0.852', '0.9'), ('0.837', '0.9'), ('0.796', '0.9'), ('0.601', '0.9'), ('0.593', '0.9'), ('0.639', '0.9'), ('0.686', '0.9'), ('0.572', '0.9'), ('0.877', '0.9'), ('0.856', '0.9'), ('0.751', '0.7'), ('0.738', '0.7'), ('0.718', '0.7'), ('0.572', '0.7'), ('0.564', '0.7'), ('0.601', '0.7'), ('0.647', '0.7'), ('0.547', '0.7'), ('0.808', '0.7'), ('0.78', '0.7'), ('0.514', '0.3'), ('0.486', '0.3'), ('0.479', '0.3'), ('0.484', '0.3'), ('0.458', '0.3'), ('0.466', '0.3'), ('0.503', '0.3'), ('0.476', '0.3'), ('0.624', '0.5'), ('0.581', '0.5'), ('0.605', '0.5'), ('0.52', '0.5'), ('0.512', '0.5'), ('0.546', '0.5'), ('0.585', '0.5'), ('0.519', '0.5'), ('0.676', '0.5'), ('0.618', '0.5')]\n",
      "3.972e-05\n",
      "  batch 936 loss: 0.18550946888251182\n",
      "[('0.434', '0.001'), ('0.441', '0.001'), ('0.437', '0.001'), ('0.437', '0.001'), ('0.439', '0.001'), ('0.435', '0.001'), ('0.435', '0.001'), ('0.441', '0.001'), ('0.437', '0.001'), ('0.59', '0.001'), ('0.886', '0.999'), ('0.869', '0.999'), ('0.81', '0.999'), ('0.602', '0.999'), ('0.586', '0.999'), ('0.654', '0.999'), ('0.707', '0.999'), ('0.571', '0.999'), ('0.906', '0.999'), ('0.889', '0.999'), ('0.883', '0.999'), ('0.869', '0.999'), ('0.459', '0.2'), ('0.449', '0.2'), ('0.449', '0.2'), ('0.453', '0.2'), ('0.439', '0.2'), ('0.443', '0.2'), ('0.456', '0.2'), ('0.446', '0.2'), ('0.545', '0.2'), ('0.483', '0.2'), ('0.483', '0.2'), ('0.676', '0.6'), ('0.648', '0.6'), ('0.668', '0.6'), ('0.533', '0.6'), ('0.529', '0.6'), ('0.571', '0.6'), ('0.62', '0.6'), ('0.526', '0.6'), ('0.743', '0.6'), ('0.754', '0.6'), ('0.736', '0.6'), ('0.695', '0.6'), ('0.551', '0.4'), ('0.517', '0.4'), ('0.502', '0.4'), ('0.486', '0.4'), ('0.474', '0.4'), ('0.498', '0.4'), ('0.549', '0.4'), ('0.493', '0.4'), ('0.621', '0.4'), ('0.579', '0.4'), ('0.528', '0.4'), ('0.539', '0.4'), ('0.8', '0.8'), ('0.785', '0.8'), ('0.748', '0.8'), ('0.573', '0.8'), ('0.568', '0.8'), ('0.622', '0.8'), ('0.681', '0.8'), ('0.546', '0.8'), ('0.743', '0.8'), ('0.789', '0.8'), ('0.64', '0.8'), ('0.646', '0.8'), ('0.86', '0.8'), ('0.843', '0.8'), ('0.449', '0.1'), ('0.442', '0.1'), ('0.441', '0.1'), ('0.445', '0.1'), ('0.436', '0.1'), ('0.438', '0.1'), ('0.449', '0.1'), ('0.442', '0.1'), ('0.857', '0.9'), ('0.842', '0.9'), ('0.797', '0.9'), ('0.588', '0.9'), ('0.578', '0.9'), ('0.638', '0.9'), ('0.695', '0.9'), ('0.558', '0.9'), ('0.88', '0.9'), ('0.869', '0.9'), ('0.752', '0.7'), ('0.739', '0.7'), ('0.716', '0.7'), ('0.561', '0.7'), ('0.551', '0.7'), ('0.597', '0.7'), ('0.653', '0.7'), ('0.537', '0.7'), ('0.81', '0.7'), ('0.792', '0.7'), ('0.502', '0.3'), ('0.474', '0.3'), ('0.467', '0.3'), ('0.472', '0.3'), ('0.446', '0.3'), ('0.454', '0.3'), ('0.495', '0.3'), ('0.468', '0.3'), ('0.616', '0.5'), ('0.572', '0.5'), ('0.596', '0.5'), ('0.509', '0.5'), ('0.499', '0.5'), ('0.539', '0.5'), ('0.585', '0.5'), ('0.512', '0.5'), ('0.667', '0.5'), ('0.622', '0.5')]\n",
      "3.9626666666666664e-05\n",
      "  batch 1053 loss: 0.18011790080967113\n",
      "[('0.421', '0.001'), ('0.427', '0.001'), ('0.424', '0.001'), ('0.424', '0.001'), ('0.426', '0.001'), ('0.422', '0.001'), ('0.422', '0.001'), ('0.428', '0.001'), ('0.425', '0.001'), ('0.629', '0.001'), ('0.891', '0.999'), ('0.875', '0.999'), ('0.813', '0.999'), ('0.608', '0.999'), ('0.597', '0.999'), ('0.658', '0.999'), ('0.741', '0.999'), ('0.581', '0.999'), ('0.914', '0.999'), ('0.894', '0.999'), ('0.886', '0.999'), ('0.899', '0.999'), ('0.445', '0.2'), ('0.435', '0.2'), ('0.435', '0.2'), ('0.44', '0.2'), ('0.429', '0.2'), ('0.429', '0.2'), ('0.446', '0.2'), ('0.438', '0.2'), ('0.576', '0.2'), ('0.499', '0.2'), ('0.501', '0.2'), ('0.671', '0.6'), ('0.642', '0.6'), ('0.661', '0.6'), ('0.533', '0.6'), ('0.539', '0.6'), ('0.564', '0.6'), ('0.646', '0.6'), ('0.534', '0.6'), ('0.751', '0.6'), ('0.769', '0.6'), ('0.732', '0.6'), ('0.719', '0.6'), ('0.538', '0.4'), ('0.502', '0.4'), ('0.489', '0.4'), ('0.479', '0.4'), ('0.474', '0.4'), ('0.483', '0.4'), ('0.562', '0.4'), ('0.498', '0.4'), ('0.611', '0.4'), ('0.591', '0.4'), ('0.553', '0.4'), ('0.57', '0.4'), ('0.802', '0.8'), ('0.786', '0.8'), ('0.745', '0.8'), ('0.576', '0.8'), ('0.578', '0.8'), ('0.621', '0.8'), ('0.713', '0.8'), ('0.555', '0.8'), ('0.751', '0.8'), ('0.807', '0.8'), ('0.692', '0.8'), ('0.696', '0.8'), ('0.861', '0.8'), ('0.874', '0.8'), ('0.435', '0.1'), ('0.429', '0.1'), ('0.427', '0.1'), ('0.432', '0.1'), ('0.425', '0.1'), ('0.425', '0.1'), ('0.437', '0.1'), ('0.432', '0.1'), ('0.863', '0.9'), ('0.846', '0.9'), ('0.797', '0.9'), ('0.593', '0.9'), ('0.588', '0.9'), ('0.64', '0.9'), ('0.728', '0.9'), ('0.568', '0.9'), ('0.883', '0.9'), ('0.897', '0.9'), ('0.752', '0.7'), ('0.737', '0.7'), ('0.712', '0.7'), ('0.562', '0.7'), ('0.561', '0.7'), ('0.593', '0.7'), ('0.682', '0.7'), ('0.546', '0.7'), ('0.808', '0.7'), ('0.823', '0.7'), ('0.488', '0.3'), ('0.459', '0.3'), ('0.453', '0.3'), ('0.463', '0.3'), ('0.439', '0.3'), ('0.44', '0.3'), ('0.496', '0.3'), ('0.465', '0.3'), ('0.604', '0.5'), ('0.559', '0.5'), ('0.583', '0.5'), ('0.506', '0.5'), ('0.506', '0.5'), ('0.527', '0.5'), ('0.606', '0.5'), ('0.519', '0.5'), ('0.657', '0.5'), ('0.628', '0.5')]\n",
      "3.953333333333333e-05\n",
      "  batch 1170 loss: 0.1734808747075562\n",
      "[('0.407', '0.001'), ('0.412', '0.001'), ('0.41', '0.001'), ('0.409', '0.001'), ('0.411', '0.001'), ('0.408', '0.001'), ('0.408', '0.001'), ('0.414', '0.001'), ('0.411', '0.001'), ('0.598', '0.001'), ('0.896', '0.999'), ('0.88', '0.999'), ('0.813', '0.999'), ('0.603', '0.999'), ('0.593', '0.999'), ('0.651', '0.999'), ('0.747', '0.999'), ('0.576', '0.999'), ('0.919', '0.999'), ('0.902', '0.999'), ('0.892', '0.999'), ('0.911', '0.999'), ('0.428', '0.2'), ('0.419', '0.2'), ('0.42', '0.2'), ('0.426', '0.2'), ('0.416', '0.2'), ('0.414', '0.2'), ('0.432', '0.2'), ('0.424', '0.2'), ('0.539', '0.2'), ('0.469', '0.2'), ('0.47', '0.2'), ('0.659', '0.6'), ('0.627', '0.6'), ('0.651', '0.6'), ('0.522', '0.6'), ('0.529', '0.6'), ('0.55', '0.6'), ('0.644', '0.6'), ('0.525', '0.6'), ('0.761', '0.6'), ('0.769', '0.6'), ('0.73', '0.6'), ('0.733', '0.6'), ('0.52', '0.4'), ('0.485', '0.4'), ('0.473', '0.4'), ('0.467', '0.4'), ('0.462', '0.4'), ('0.466', '0.4'), ('0.554', '0.4'), ('0.488', '0.4'), ('0.595', '0.4'), ('0.581', '0.4'), ('0.523', '0.4'), ('0.537', '0.4'), ('0.804', '0.8'), ('0.787', '0.8'), ('0.746', '0.8'), ('0.567', '0.8'), ('0.571', '0.8'), ('0.611', '0.8'), ('0.717', '0.8'), ('0.547', '0.8'), ('0.761', '0.8'), ('0.813', '0.8'), ('0.694', '0.8'), ('0.7', '0.8'), ('0.867', '0.8'), ('0.887', '0.8'), ('0.419', '0.1'), ('0.414', '0.1'), ('0.413', '0.1'), ('0.417', '0.1'), ('0.411', '0.1'), ('0.41', '0.1'), ('0.423', '0.1'), ('0.418', '0.1'), ('0.866', '0.9'), ('0.848', '0.9'), ('0.798', '0.9'), ('0.586', '0.9'), ('0.582', '0.9'), ('0.632', '0.9'), ('0.732', '0.9'), ('0.56', '0.9'), ('0.888', '0.9'), ('0.911', '0.9'), ('0.749', '0.7'), ('0.735', '0.7'), ('0.707', '0.7'), ('0.554', '0.7'), ('0.552', '0.7'), ('0.581', '0.7'), ('0.683', '0.7'), ('0.537', '0.7'), ('0.81', '0.7'), ('0.838', '0.7'), ('0.47', '0.3'), ('0.442', '0.3'), ('0.437', '0.3'), ('0.45', '0.3'), ('0.426', '0.3'), ('0.424', '0.3'), ('0.484', '0.3'), ('0.454', '0.3'), ('0.591', '0.5'), ('0.542', '0.5'), ('0.572', '0.5'), ('0.495', '0.5'), ('0.495', '0.5'), ('0.511', '0.5'), ('0.601', '0.5'), ('0.51', '0.5'), ('0.649', '0.5'), ('0.64', '0.5')]\n",
      "3.9439999999999995e-05\n",
      "  batch 1287 loss: 0.16906524978132328\n",
      "[('0.392', '0.001'), ('0.396', '0.001'), ('0.394', '0.001'), ('0.394', '0.001'), ('0.396', '0.001'), ('0.393', '0.001'), ('0.393', '0.001'), ('0.397', '0.001'), ('0.395', '0.001'), ('0.558', '0.001'), ('0.9', '0.999'), ('0.879', '0.999'), ('0.811', '0.999'), ('0.571', '0.999'), ('0.557', '0.999'), ('0.644', '0.999'), ('0.736', '0.999'), ('0.537', '0.999'), ('0.923', '0.999'), ('0.904', '0.999'), ('0.893', '0.999'), ('0.914', '0.999'), ('0.411', '0.2'), ('0.402', '0.2'), ('0.403', '0.2'), ('0.408', '0.2'), ('0.398', '0.2'), ('0.398', '0.2'), ('0.413', '0.2'), ('0.406', '0.2'), ('0.5', '0.2'), ('0.437', '0.2'), ('0.437', '0.2'), ('0.646', '0.6'), ('0.614', '0.6'), ('0.636', '0.6'), ('0.494', '0.6'), ('0.495', '0.6'), ('0.534', '0.6'), ('0.625', '0.6'), ('0.492', '0.6'), ('0.73', '0.6'), ('0.769', '0.6'), ('0.718', '0.6'), ('0.717', '0.6'), ('0.501', '0.4'), ('0.465', '0.4'), ('0.453', '0.4'), ('0.443', '0.4'), ('0.436', '0.4'), ('0.448', '0.4'), ('0.532', '0.4'), ('0.46', '0.4'), ('0.581', '0.4'), ('0.569', '0.4'), ('0.482', '0.4'), ('0.495', '0.4'), ('0.803', '0.8'), ('0.783', '0.8'), ('0.735', '0.8'), ('0.535', '0.8'), ('0.536', '0.8'), ('0.601', '0.8'), ('0.704', '0.8'), ('0.512', '0.8'), ('0.73', '0.8'), ('0.807', '0.8'), ('0.676', '0.8'), ('0.683', '0.8'), ('0.867', '0.8'), ('0.888', '0.8'), ('0.403', '0.1'), ('0.397', '0.1'), ('0.397', '0.1'), ('0.401', '0.1'), ('0.395', '0.1'), ('0.395', '0.1'), ('0.405', '0.1'), ('0.401', '0.1'), ('0.867', '0.9'), ('0.848', '0.9'), ('0.794', '0.9'), ('0.553', '0.9'), ('0.547', '0.9'), ('0.623', '0.9'), ('0.721', '0.9'), ('0.524', '0.9'), ('0.89', '0.9'), ('0.911', '0.9'), ('0.744', '0.7'), ('0.727', '0.7'), ('0.695', '0.7'), ('0.522', '0.7'), ('0.517', '0.7'), ('0.568', '0.7'), ('0.666', '0.7'), ('0.503', '0.7'), ('0.806', '0.7'), ('0.834', '0.7'), ('0.45', '0.3'), ('0.424', '0.3'), ('0.418', '0.3'), ('0.428', '0.3'), ('0.407', '0.3'), ('0.407', '0.3'), ('0.462', '0.3'), ('0.432', '0.3'), ('0.574', '0.5'), ('0.524', '0.5'), ('0.551', '0.5'), ('0.467', '0.5'), ('0.464', '0.5'), ('0.492', '0.5'), ('0.579', '0.5'), ('0.479', '0.5'), ('0.629', '0.5'), ('0.619', '0.5')]\n",
      "3.934666666666666e-05\n",
      "  batch 1404 loss: 0.16378958714313996\n",
      "[('0.376', '0.001'), ('0.38', '0.001'), ('0.378', '0.001'), ('0.378', '0.001'), ('0.379', '0.001'), ('0.377', '0.001'), ('0.377', '0.001'), ('0.381', '0.001'), ('0.379', '0.001'), ('0.566', '0.001'), ('0.903', '0.999'), ('0.883', '0.999'), ('0.812', '0.999'), ('0.563', '0.999'), ('0.551', '0.999'), ('0.635', '0.999'), ('0.743', '0.999'), ('0.533', '0.999'), ('0.928', '0.999'), ('0.912', '0.999'), ('0.897', '0.999'), ('0.927', '0.999'), ('0.393', '0.2'), ('0.385', '0.2'), ('0.386', '0.2'), ('0.391', '0.2'), ('0.383', '0.2'), ('0.382', '0.2'), ('0.396', '0.2'), ('0.39', '0.2'), ('0.497', '0.2'), ('0.432', '0.2'), ('0.433', '0.2'), ('0.631', '0.6'), ('0.597', '0.6'), ('0.619', '0.6'), ('0.479', '0.6'), ('0.484', '0.6'), ('0.518', '0.6'), ('0.622', '0.6'), ('0.481', '0.6'), ('0.74', '0.6'), ('0.766', '0.6'), ('0.707', '0.6'), ('0.721', '0.6'), ('0.48', '0.4'), ('0.444', '0.4'), ('0.431', '0.4'), ('0.426', '0.4'), ('0.421', '0.4'), ('0.428', '0.4'), ('0.521', '0.4'), ('0.447', '0.4'), ('0.56', '0.4'), ('0.556', '0.4'), ('0.481', '0.4'), ('0.496', '0.4'), ('0.8', '0.8'), ('0.779', '0.8'), ('0.727', '0.8'), ('0.525', '0.8'), ('0.529', '0.8'), ('0.589', '0.8'), ('0.707', '0.8'), ('0.504', '0.8'), ('0.74', '0.8'), ('0.812', '0.8'), ('0.674', '0.8'), ('0.68', '0.8'), ('0.87', '0.8'), ('0.901', '0.8'), ('0.385', '0.1'), ('0.381', '0.1'), ('0.38', '0.1'), ('0.384', '0.1'), ('0.379', '0.1'), ('0.378', '0.1'), ('0.389', '0.1'), ('0.385', '0.1'), ('0.87', '0.9'), ('0.849', '0.9'), ('0.794', '0.9'), ('0.546', '0.9'), ('0.541', '0.9'), ('0.612', '0.9'), ('0.726', '0.9'), ('0.519', '0.9'), ('0.894', '0.9'), ('0.926', '0.9'), ('0.735', '0.7'), ('0.718', '0.7'), ('0.683', '0.7'), ('0.511', '0.7'), ('0.509', '0.7'), ('0.554', '0.7'), ('0.667', '0.7'), ('0.494', '0.7'), ('0.807', '0.7'), ('0.849', '0.7'), ('0.43', '0.3'), ('0.404', '0.3'), ('0.4', '0.3'), ('0.411', '0.3'), ('0.391', '0.3'), ('0.39', '0.3'), ('0.447', '0.3'), ('0.416', '0.3'), ('0.554', '0.5'), ('0.503', '0.5'), ('0.532', '0.5'), ('0.451', '0.5'), ('0.451', '0.5'), ('0.474', '0.5'), ('0.573', '0.5'), ('0.467', '0.5'), ('0.614', '0.5'), ('0.62', '0.5')]\n"
     ]
    }
   ],
   "source": [
    "printing = True\n",
    "\n",
    "\n",
    "running_loss = 0.\n",
    "last_loss = 0.\n",
    "lis = []\n",
    " # might have to delete when loading model\n",
    "threshold_decay = 0.2\n",
    "flags = [True for _ in threshold]\n",
    "record = 1\n",
    "epochs = 100\n",
    "\n",
    "times = [0]*10\n",
    "transforms = 117\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    training = generateLossImages.MakeIter(generateLossImages.get_image_pairs_transforms_with_loss(cupy=True, start=start_index if epoch == start_epoch else 0)) # start=2*71*50*4))#start_index if epoch == start_epoch else 0)) \n",
    "    val = generateLossImages.get_image_pairs_transforms_with_loss(\"C:/Users/Rani/Desktop/ai_val/16\")\n",
    "    training_loader = torch.utils.data.DataLoader(training)\n",
    "    for index, data in enumerate(training_loader): # loading data takes 25.72% of the time\n",
    "\n",
    "        inputs, labels = data  #0.01%\n",
    "\n",
    "        labels = labels.to(\"cuda\") # 0.00%\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs) # 24.05%\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels) # 0.40%\n",
    "\n",
    "        loss.backward() # 39.11%\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item() # 10.23%\n",
    "\n",
    "        if printing: # From here down only takes 0.47% of the time\n",
    "            lis.append((f'{outputs.item():.3}',f'{labels.item():.3}'))\n",
    "        if index % transforms == transforms-1:\n",
    "            # Zero your gradients for every batch!\n",
    "            # Adjust learning weights\n",
    "            last_loss = running_loss / transforms # loss per batch\n",
    "            if last_loss < threshold[0] and flags[0]:\n",
    "                threshold = threshold[1:]\n",
    "                flags = flags[1:]\n",
    "                flag1 = False\n",
    "                min_lr *= threshold_decay\n",
    "                max_lr *= threshold_decay\n",
    "                step_size = (max_lr-min_lr)/steps\n",
    "                falling = True\n",
    "                optimizer.param_groups[-1]['lr'] = max_lr\n",
    "                if printing:\n",
    "                    print(min_lr)\n",
    "                    print(max_lr)\n",
    "                    print(steps)\n",
    "                    print(step_size)\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'index': index,\n",
    "                    'min_lr': min_lr,\n",
    "                    'max_lr': max_lr,\n",
    "                    'steps': steps,\n",
    "                    'step_size': step_size,\n",
    "                    'falling': falling,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'threshold': threshold\n",
    "                }\n",
    "                save_ckp(checkpoint, True)\n",
    "            elif falling:\n",
    "                optimizer.param_groups[-1]['lr'] = optimizer.param_groups[-1]['lr'] - step_size\n",
    "                if optimizer.param_groups[-1]['lr'] < min_lr:\n",
    "                    falling = False\n",
    "                    max_lr *= decay\n",
    "                    min_lr *= decay\n",
    "                    steps /= decay\n",
    "                    step_size = (max_lr-min_lr)/steps\n",
    "\n",
    "                    if printing:\n",
    "                        print(min_lr)\n",
    "                        print(max_lr)\n",
    "                        print(steps)\n",
    "                        print(step_size)\n",
    "                    \n",
    "                    \n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch,\n",
    "                        'index': index,\n",
    "                        'min_lr': min_lr,\n",
    "                        'max_lr': max_lr,\n",
    "                        'steps': steps,\n",
    "                        'step_size': step_size,\n",
    "                        'falling': falling,\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'threshold': threshold\n",
    "                    }\n",
    "                    save_ckp(checkpoint, False)\n",
    "\n",
    "            else: \n",
    "                optimizer.param_groups[-1]['lr'] += step_size\n",
    "                if optimizer.param_groups[-1]['lr'] > max_lr:\n",
    "                    falling = True\n",
    "\n",
    "\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if printing:\n",
    "                print(optimizer.param_groups[-1]['lr'])\n",
    "                print('  batch {} loss: {}'.format(index + 1, last_loss))\n",
    "                print(lis)\n",
    "                lis = []\n",
    "            running_loss = 0\n",
    "\n",
    "            if last_loss < record:\n",
    "                record = last_loss\n",
    "                if last_loss < 0.08:\n",
    "                    checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'index': index,\n",
    "                    'min_lr': min_lr,\n",
    "                    'max_lr': max_lr,\n",
    "                    'steps': steps,\n",
    "                    'step_size': step_size,\n",
    "                    'falling': falling,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'threshold': threshold\n",
    "                }\n",
    "                    save_ckp(checkpoint, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Rani/Desktop/ai_training_immages/1/_DSC0001.NEF\n",
      "[1.5390501022338867, 0.0010004043579101562, 0.0, 1.6169846057891846, 0.030069828033447266, 2.6113336086273193, 0.696631669998169, 0.0]\n",
      "[3.4108407497406006, 0.0030012130737304688, 0.0, 3.223478078842163, 0.05709671974182129, 5.20122218132019, 1.3942623138427734, 0.015013456344604492]\n",
      "[4.917867660522461, 0.0040018558502197266, 0.0, 4.832986354827881, 0.08512330055236816, 7.818122386932373, 2.069880723953247, 0.03403067588806152]\n",
      "[6.808576583862305, 0.0050013065338134766, 0.0, 6.424399137496948, 0.11214613914489746, 10.428500413894653, 2.747067451477051, 0.0470428466796875]\n",
      "[8.32053518295288, 0.006002187728881836, 0.0, 8.016862392425537, 0.14112520217895508, 13.03839659690857, 3.4226791858673096, 0.05805325508117676]\n",
      "[10.238825559616089, 0.006002187728881836, 0.0, 9.61528491973877, 0.16180038452148438, 15.61980652809143, 4.115321397781372, 0.07706999778747559]\n",
      "[11.76326322555542, 0.006002187728881836, 0.0, 11.211738586425781, 0.1878221035003662, 18.2191641330719, 4.786930799484253, 0.09108257293701172]\n",
      "[13.65001368522644, 0.006002187728881836, 0.0, 12.823691844940186, 0.2098841667175293, 20.79753351211548, 5.462549448013306, 0.11009979248046875]\n",
      "[15.154994010925293, 0.007002353668212891, 0.0, 14.444666624069214, 0.23790621757507324, 23.407458066940308, 6.134217023849487, 0.44140148162841797]\n",
      "[17.06335210800171, 0.010004758834838867, 0.0, 16.056931972503662, 0.26688432693481445, 26.08551573753357, 6.810828685760498, 0.45641493797302246]\n",
      "[18.61379337310791, 0.010004758834838867, 0.0, 17.667364597320557, 0.294910192489624, 28.677922248840332, 7.49345064163208, 0.46942591667175293]\n",
      "[20.534149169921875, 0.010004758834838867, 0.0, 19.244303226470947, 0.32393431663513184, 31.307833433151245, 8.180072784423828, 0.48143649101257324]\n",
      "[22.11561417579651, 0.010004758834838867, 0.0010006427764892578, 20.879818439483643, 0.3549056053161621, 33.956774950027466, 8.86969542503357, 0.4944484233856201]\n",
      "[24.09299874305725, 0.01100611686706543, 0.0010006427764892578, 22.49924063682556, 0.374922513961792, 36.61926627159119, 9.573317766189575, 0.5104629993438721]\n",
      "[25.65946936607361, 0.01100611686706543, 0.0010006427764892578, 24.139692306518555, 0.40795350074768066, 39.265888929367065, 10.254932165145874, 0.5254771709442139]\n",
      "[27.551702737808228, 0.01100611686706543, 0.0010006427764892578, 25.742204427719116, 0.43248748779296875, 41.87683153152466, 10.941550493240356, 0.5404913425445557]\n",
      "[29.066654682159424, 0.01400899887084961, 0.0010006427764892578, 27.34306025505066, 0.46300363540649414, 44.49314045906067, 11.621263980865479, 0.5555047988891602]\n",
      "[31.007527351379395, 0.01501011848449707, 0.0010006427764892578, 28.98952603340149, 0.48702239990234375, 47.146605014801025, 12.32689380645752, 0.5665144920349121]\n"
     ]
    }
   ],
   "source": [
    "printing = False\n",
    "\n",
    "\n",
    "running_loss = 0.\n",
    "last_loss = 0.\n",
    "lis = []\n",
    " # might have to delete when loading model\n",
    "threshold_decay = 0.2\n",
    "flags = [True for _ in threshold]\n",
    "record = 1\n",
    "epochs = 100\n",
    "\n",
    "times = [0]*8\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    training = generateLossImages.MakeIter(generateLossImages.get_image_pairs_transforms_with_loss(cupy=True, start=start_index if epoch == start_epoch else 0)) # start=2*71*50*4))#start_index if epoch == start_epoch else 0)) \n",
    "    val = generateLossImages.get_image_pairs_transforms_with_loss(\"C:/Users/Rani/Desktop/ai_val/16\")\n",
    "    training_loader = torch.utils.data.DataLoader(training)\n",
    "    end = 0\n",
    "    for index, data in enumerate(training_loader):#[90.06174230575562, 0.03202486038208008, 0.016014575958251953, 84.36967897415161, 1.3647308349609375, 137.4005196094513, 34.81299662590027, 1.9427943229675293, 0, 0]\n",
    "        start = time.time()\n",
    "        if end != 0:\n",
    "            times[0] += (start-end)\n",
    "        inputs, labels = data  \n",
    "\n",
    "        load = time.time()\n",
    "        times[1] += load-start\n",
    "\n",
    "        labels = labels.to(\"cuda\")\n",
    "\n",
    "        lab = time.time()\n",
    "        times[2] += (lab-load)\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        out = time.time()\n",
    "        times[3] += (out-lab)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        los = time.time()\n",
    "        times[4] += (los-out)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        back = time.time()\n",
    "        times[5] += (back-los)\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        runn = time.time()\n",
    "        times[6] += (runn-back)\n",
    "\n",
    "        if printing:\n",
    "            lis.append((f'{outputs.item():.3}',f'{labels.item():.3}'))\n",
    "        if index % 71 == 70:\n",
    "            # Zero your gradients for every batch!\n",
    "            # Adjust learning weights\n",
    "            last_loss = running_loss / 71 # loss per batch\n",
    "            if last_loss < threshold[0] and flags[0]:\n",
    "                threshold = threshold[1:]\n",
    "                flags = flags[1:]\n",
    "                flag1 = False\n",
    "                min_lr *= threshold_decay\n",
    "                max_lr *= threshold_decay\n",
    "                step_size = (max_lr-min_lr)/steps\n",
    "                falling = True\n",
    "                optimizer.param_groups[-1]['lr'] = max_lr\n",
    "                if printing:\n",
    "                    print(min_lr)\n",
    "                    print(max_lr)\n",
    "                    print(steps)\n",
    "                    print(step_size)\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'index': index,\n",
    "                    'min_lr': min_lr,\n",
    "                    'max_lr': max_lr,\n",
    "                    'steps': steps,\n",
    "                    'step_size': step_size,\n",
    "                    'falling': falling,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'threshold': threshold\n",
    "                }\n",
    "                save_ckp(checkpoint, True)\n",
    "            elif falling:\n",
    "                optimizer.param_groups[-1]['lr'] = optimizer.param_groups[-1]['lr'] - step_size\n",
    "                if optimizer.param_groups[-1]['lr'] < min_lr:\n",
    "                    falling = False\n",
    "                    max_lr *= decay\n",
    "                    min_lr *= decay\n",
    "                    steps /= decay\n",
    "                    step_size = (max_lr-min_lr)/steps\n",
    "\n",
    "                    if printing:\n",
    "                        print(min_lr)\n",
    "                        print(max_lr)\n",
    "                        print(steps)\n",
    "                        print(step_size)\n",
    "\n",
    "            else: \n",
    "                optimizer.param_groups[-1]['lr'] += step_size\n",
    "                if optimizer.param_groups[-1]['lr'] > max_lr:\n",
    "                    falling = True\n",
    "\n",
    "\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if printing:\n",
    "                print(optimizer.param_groups[-1]['lr'])\n",
    "                print('  batch {} loss: {}'.format(index + 1, last_loss))\n",
    "                print(lis)\n",
    "                lis = []\n",
    "            running_loss = 0\n",
    "\n",
    "            if last_loss < record:\n",
    "                record = last_loss\n",
    "                if last_loss < 0.08:\n",
    "                    checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'index': index,\n",
    "                    'min_lr': min_lr,\n",
    "                    'max_lr': max_lr,\n",
    "                    'steps': steps,\n",
    "                    'step_size': step_size,\n",
    "                    'falling': falling,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'threshold': threshold\n",
    "                }\n",
    "                    save_ckp(checkpoint, True)\n",
    "            print(times)\n",
    "        end = time.time()\n",
    "        times[7] += (end-runn)\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
