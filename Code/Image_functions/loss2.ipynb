{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (2048x6x4). Calculated output size: (2048x1x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mLossv2\u001b[39;00m\n\u001b[0;32m      7\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m summary(Lossv2\u001b[39m.\u001b[39;49mLoss()\u001b[39m.\u001b[39;49mto(device), (\u001b[39m6\u001b[39;49m, \u001b[39m768\u001b[39;49m, \u001b[39m512\u001b[39;49m))  \u001b[39m###  IDK why, but I have to switch the dims in AvgPool on Loss() to get this to work :/ But that breaks the stuff bellow\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rani\\anaconda3\\envs\\torch\\lib\\site-packages\\torchsummary\\torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m model\u001b[39m.\u001b[39mapply(register_hook)\n\u001b[0;32m     70\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m model(\u001b[39m*\u001b[39;49mx)\n\u001b[0;32m     74\u001b[0m \u001b[39m# remove these hooks\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks:\n",
      "File \u001b[1;32mc:\\Users\\Rani\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Rani\\Documents\\GitHub\\DeepLearningBachelorProject\\Code\\Image_functions\\Lossv2.py:575\u001b[0m, in \u001b[0;36mLoss.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    573\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_18(x)\n\u001b[0;32m    574\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_19(x) \n\u001b[1;32m--> 575\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool(x)\n\u001b[0;32m    579\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    580\u001b[0m \u001b[39m#x = self.dropout(x)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rani\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1210\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1212\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1214\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[1;32mc:\\Users\\Rani\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:627\u001b[0m, in \u001b[0;36mAvgPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 627\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mavg_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    628\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcount_include_pad, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdivisor_override)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (2048x6x4). Calculated output size: (2048x1x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import Lossv2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "summary(Lossv2.Loss().to(device), (6, 768, 512))  ###  IDK why, but I have to switch the dims in AvgPool on Loss() to get this to work :/ But that breaks the stuff bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.manual_seed(100)\n",
    "np.random.seed(100)\n",
    "import Lossv2\n",
    "import generateLossImages\n",
    "import time\n",
    "\n",
    "global counter \n",
    "counter = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def save_ckp(state, is_best, checkpoint_dir=\"./models/rest/\", best_model_dir=\"./models/best/\"):\n",
    "    global counter \n",
    "    f_path = checkpoint_dir + str(counter) + '_checkpoint.pt'\n",
    "    counter = counter + 1\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_dir + 'best_model.pt'\n",
    "        shutil.copyfile(f_path, best_fpath)\n",
    "\n",
    "def load_ckp(model, optimizer, checkpoint_fpath=\"./models/best/best_model.pt\"):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch'], checkpoint['index'], checkpoint['min_lr'], checkpoint['max_lr'], checkpoint['steps'], checkpoint['step_size'], checkpoint['falling'], checkpoint['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in PyTorch 1.12 and later.\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "min_lr = 0.001\n",
    "max_lr = 0.003\n",
    "decay = 0.8\n",
    "steps = 300\n",
    "falling = True\n",
    "start_epoch = 0\n",
    "start_index = 0\n",
    "momentum = 0.94\n",
    "threshold = [0.16, 0.12, 0.09, 0.06, 0.04, 0.03, 0.02, 0.015, 0.01 -1]\n",
    "step_size = (max_lr-min_lr)/steps\n",
    "model = Lossv2.Loss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=max_lr, momentum=momentum)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "#torch.autograd.set_detect_anomaly(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "model = Lossv2.Loss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.96)\n",
    "model, optimizer, start_epoch, start_index, min_lr, max_lr, steps, step_size, falling, threshold = load_ckp(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.72382749606882, 0.012452385971162576, 0.0008301326924880367, 24.049694721718666, 0.40403351288996003, 39.11279737602433, 10.22638426619226, 0.4699801084423085]\n"
     ]
    }
   ],
   "source": [
    "li = [31.007527351379395, 0.01501011848449707, 0.0010006427764892578, 28.98952603340149, 0.48702239990234375, 47.146605014801025, 12.32689380645752, 0.5665144920349121]\n",
    "su = sum(li)\n",
    "print([100*l/su for l in li])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3280, 4948, 3])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m val \u001b[39m=\u001b[39m generateLossImages\u001b[39m.\u001b[39mget_image_pairs_transforms_with_loss(\u001b[39m\"\u001b[39m\u001b[39mC:/Users/Rani/Desktop/ai_val/16\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m training_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(training)\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfor\u001b[39;00m index, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(training_loader): \u001b[39m# loading data takes 25.72% of the time\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     inputs, labels \u001b[39m=\u001b[39m data  \u001b[39m#0.01%\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# 0.00%\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rani\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Rani\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Rani\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Rani\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Rani\\Documents\\GitHub\\DeepLearningBachelorProject\\Code\\Image_functions\\generateLossImages.py:158\u001b[0m, in \u001b[0;36mMakeIter.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerator_func\u001b[39m.\u001b[39;49m\u001b[39m__next__\u001b[39;49m()\n",
      "File \u001b[1;32mc:\\Users\\Rani\\Documents\\GitHub\\DeepLearningBachelorProject\\Code\\Image_functions\\generateLossImages.py:170\u001b[0m, in \u001b[0;36mget_image_pairs_transforms_with_loss\u001b[1;34m(path, start)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m imgs:  \u001b[39m# total is 117\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mfor\u001b[39;00m aug_0 \u001b[39min\u001b[39;00m get_images_with_loss_of_0(img):\n\u001b[1;32m--> 170\u001b[0m         aug_0 \u001b[39m=\u001b[39m aug_0\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m    171\u001b[0m         im \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m    172\u001b[0m         \u001b[39myield\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39mconcatenate(((im \u001b[39m-\u001b[39m \u001b[39m128\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m, im\u001b[39m-\u001b[39maug_0), axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m), torch\u001b[39m.\u001b[39mtensor(\u001b[39m0.001\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "printing = True\n",
    "\n",
    "\n",
    "running_loss = 0.\n",
    "last_loss = 0.\n",
    "lis = []\n",
    "# might have to delete when loading model\n",
    "threshold_decay = 0.2\n",
    "flags = [True for _ in threshold]\n",
    "record = 1\n",
    "epochs = 100\n",
    "\n",
    "times = [0]*10\n",
    "transforms = 117\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    training = generateLossImages.MakeIter(generateLossImages.get_image_pairs_transforms_with_loss(start=start_index if epoch == start_epoch else 0)) # start=2*71*50*4))#start_index if epoch == start_epoch else 0)) \n",
    "    val = generateLossImages.get_image_pairs_transforms_with_loss(\"C:/Users/Rani/Desktop/ai_val/16\")\n",
    "    training_loader = torch.utils.data.DataLoader(training)\n",
    "    for index, data in enumerate(training_loader): # loading data takes 25.72% of the time\n",
    "\n",
    "        inputs, labels = data  #0.01%\n",
    "\n",
    "        labels = labels.to(\"cuda\") # 0.00%\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs) # 24.05%\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels) # 0.40%\n",
    "\n",
    "        loss.backward() # 39.11%\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item() # 10.23%\n",
    "\n",
    "        if printing: # From here down only takes 0.47% of the time\n",
    "            lis.append((f'{outputs.item():.3}',f'{labels.item():.3}'))\n",
    "        if index % transforms == transforms-1:\n",
    "            # Zero your gradients for every batch!\n",
    "            # Adjust learning weights\n",
    "            last_loss = running_loss / transforms # loss per batch\n",
    "            if last_loss < threshold[0] and flags[0]:\n",
    "                threshold = threshold[1:]\n",
    "                flags = flags[1:]\n",
    "                flag1 = False\n",
    "                min_lr *= threshold_decay\n",
    "                max_lr *= threshold_decay\n",
    "                step_size = (max_lr-min_lr)/steps\n",
    "                falling = True\n",
    "                optimizer.param_groups[-1]['lr'] = max_lr\n",
    "                if printing:\n",
    "                    print(min_lr)\n",
    "                    print(max_lr)\n",
    "                    print(steps)\n",
    "                    print(step_size)\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'index': index,\n",
    "                    'min_lr': min_lr,\n",
    "                    'max_lr': max_lr,\n",
    "                    'steps': steps,\n",
    "                    'step_size': step_size,\n",
    "                    'falling': falling,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'threshold': threshold\n",
    "                }\n",
    "                save_ckp(checkpoint, True)\n",
    "            elif falling:\n",
    "                optimizer.param_groups[-1]['lr'] = optimizer.param_groups[-1]['lr'] - step_size\n",
    "                if optimizer.param_groups[-1]['lr'] < min_lr:\n",
    "                    falling = False\n",
    "                    max_lr *= decay\n",
    "                    min_lr *= decay\n",
    "                    steps /= decay\n",
    "                    step_size = (max_lr-min_lr)/steps\n",
    "\n",
    "                    if printing:\n",
    "                        print(min_lr)\n",
    "                        print(max_lr)\n",
    "                        print(steps)\n",
    "                        print(step_size)\n",
    "                    \n",
    "                    \n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch,\n",
    "                        'index': index,\n",
    "                        'min_lr': min_lr,\n",
    "                        'max_lr': max_lr,\n",
    "                        'steps': steps,\n",
    "                        'step_size': step_size,\n",
    "                        'falling': falling,\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'threshold': threshold\n",
    "                    }\n",
    "                    save_ckp(checkpoint, False)\n",
    "\n",
    "            else: \n",
    "                optimizer.param_groups[-1]['lr'] += step_size\n",
    "                if optimizer.param_groups[-1]['lr'] > max_lr:\n",
    "                    falling = True\n",
    "\n",
    "\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if printing:\n",
    "                print(optimizer.param_groups[-1]['lr'])\n",
    "                print('  batch {} loss: {}'.format(index + 1, last_loss))\n",
    "                print(lis)\n",
    "                lis = []\n",
    "            running_loss = 0\n",
    "\n",
    "            if last_loss < record:\n",
    "                record = last_loss\n",
    "                if last_loss < 0.08:\n",
    "                    checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'index': index,\n",
    "                    'min_lr': min_lr,\n",
    "                    'max_lr': max_lr,\n",
    "                    'steps': steps,\n",
    "                    'step_size': step_size,\n",
    "                    'falling': falling,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'threshold': threshold\n",
    "                }\n",
    "                    save_ckp(checkpoint, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.29034188034187\n"
     ]
    }
   ],
   "source": [
    "print(index/4/50/117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rani\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "from torch import autocast\n",
    "printing = False\n",
    "running_loss = 0.\n",
    "last_loss = 0.\n",
    "lis = []\n",
    " # might have to delete when loading model\n",
    "threshold_decay = 0.2\n",
    "flags = [True for _ in threshold]\n",
    "record = 1\n",
    "epochs = 100\n",
    "times = [0]*8\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    training = generateLossImages.MakeIter(generateLossImages.get_image_pairs_transforms_with_loss(start=start_index if epoch == start_epoch else 0)) # start=2*71*50*4))#start_index if epoch == start_epoch else 0)) \n",
    "    #val = generateLossImages.get_image_pairs_transforms_with_loss(\"C:/Users/Rani/Desktop/ai_val/16\")\n",
    "    training_loader = torch.utils.data.DataLoader(training) # num_workers\n",
    "    end = 0\n",
    "    before_start = 0\n",
    "    in_upstart = True\n",
    "    for index, data in enumerate(training_loader):#[90.06174230575562, 0.03202486038208008, 0.016014575958251953, 84.36967897415161, 1.3647308349609375, 137.4005196094513, 34.81299662590027, 1.9427943229675293, 0, 0]\n",
    "        before_start += 1\n",
    "        if before_start > 117 and in_upstart:\n",
    "            in_upstart = False\n",
    "            times = [0]*8\n",
    "        start = time.time()\n",
    "        if end != 0:\n",
    "            times[0] += (start-end)\n",
    "        inputs, labels = data  \n",
    "\n",
    "        load = time.time()\n",
    "        times[1] += load-start\n",
    "\n",
    "        lab = time.time()\n",
    "        times[2] += (lab-load)\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        out = time.time()\n",
    "        times[3] += (out-lab)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        los = time.time()\n",
    "        times[4] += (los-out)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        back = time.time()\n",
    "        times[5] += (back-los)\n",
    "        # Gather data and report\n",
    "        #running_loss += loss.item()\n",
    "        \n",
    "        runn = time.time()\n",
    "        times[6] += (runn-back)\n",
    "\n",
    "        if printing:\n",
    "            lis.append((f'{outputs.item():.3}',f'{labels.item():.3}'))\n",
    "        if index % 117 == 116:\n",
    "            # Zero your gradients for every batch!\n",
    "            # Adjust learning weights\n",
    "            #last_loss = running_loss / 117 # loss per batch\n",
    "            #if last_loss < threshold[0] and flags[0]:\n",
    "            #    threshold = threshold[1:]\n",
    "            #    flags = flags[1:]\n",
    "            #    flag1 = False\n",
    "            #    min_lr *= threshold_decay\n",
    "            #    max_lr *= threshold_decay\n",
    "            #    step_size = (max_lr-min_lr)/steps\n",
    "            #    falling = True\n",
    "            #    optimizer.param_groups[-1]['lr'] = max_lr\n",
    "            #    if printing:\n",
    "            #        print(min_lr)\n",
    "            #        print(max_lr)\n",
    "            #        print(steps)\n",
    "            #        print(step_size)\n",
    "            #    checkpoint = {\n",
    "            #        'epoch': epoch,\n",
    "            #        'index': index,\n",
    "            #        'min_lr': min_lr,\n",
    "            #        'max_lr': max_lr,\n",
    "            #        'steps': steps,\n",
    "            #        'step_size': step_size,\n",
    "            #        'falling': falling,\n",
    "            #        'state_dict': model.state_dict(),\n",
    "            #        'optimizer': optimizer.state_dict(),\n",
    "            #        'threshold': threshold\n",
    "            #    }\n",
    "            #    save_ckp(checkpoint, True)\n",
    "            #elif falling:\n",
    "            if falling:\n",
    "                optimizer.param_groups[-1]['lr'] = optimizer.param_groups[-1]['lr'] - step_size\n",
    "                if optimizer.param_groups[-1]['lr'] < min_lr:\n",
    "                    falling = False\n",
    "                    max_lr *= decay\n",
    "                    min_lr *= decay\n",
    "                    steps /= decay\n",
    "                    step_size = (max_lr-min_lr)/steps\n",
    "\n",
    "                    if printing:\n",
    "                        print(min_lr)\n",
    "                        print(max_lr)\n",
    "                        print(steps)\n",
    "                        print(step_size)\n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch,\n",
    "                        'index': index,\n",
    "                        'min_lr': min_lr,\n",
    "                        'max_lr': max_lr,\n",
    "                        'steps': steps,\n",
    "                        'step_size': step_size,\n",
    "                        'falling': falling,\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'threshold': threshold\n",
    "                    }\n",
    "                    save_ckp(checkpoint, True)\n",
    "\n",
    "            else: \n",
    "                optimizer.param_groups[-1]['lr'] += step_size\n",
    "                if optimizer.param_groups[-1]['lr'] > max_lr:\n",
    "                    falling = True\n",
    "\n",
    "\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        #    if printing:\n",
    "        #        print(optimizer.param_groups[-1]['lr'])\n",
    "        #        print('  batch {} loss: {}'.format(index + 1, last_loss))\n",
    "        #        print(lis)\n",
    "        #        lis = []\n",
    "        #    running_loss = 0\n",
    "\n",
    "        #    if last_loss < record:\n",
    "        #        record = last_loss\n",
    "        #        if last_loss < 0.08:\n",
    "        #            checkpoint = {\n",
    "        #            'epoch': epoch,\n",
    "        #            'index': index,\n",
    "        #            'min_lr': min_lr,\n",
    "        #            'max_lr': max_lr,\n",
    "        #            'steps': steps,\n",
    "        #            'step_size': step_size,\n",
    "        #            'falling': falling,\n",
    "        #            'state_dict': model.state_dict(),\n",
    "        #            'optimizer': optimizer.state_dict(),\n",
    "        #            'threshold': threshold\n",
    "        #        }\n",
    "        #            save_ckp(checkpoint, True)\n",
    "            #print(times)\n",
    "        end = time.time()\n",
    "        times[7] += (end-runn)\n",
    "        if before_start > 117*4:\n",
    "            break\n",
    "    \n",
    "    break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6015474796295166, 0.002002239227294922, 0.0, 7.0254199504852295, 0.07607626914978027, 10.602812767028809, 0.0010006427764892578, 0.01801609992980957]\n",
      "[3.282324263777951, 0.010925153242576506, 0.0, 38.3339755340833, 0.4151076890585865, 57.85390312157438, 0.005459974774838484, 0.09830426348836553]\n"
     ]
    }
   ],
   "source": [
    "print(times)\n",
    "su = sum(times)\n",
    "print([100*l/su for l in times])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
