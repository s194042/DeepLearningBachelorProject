{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 384, 256]           2,304\n",
      "               ELU-2         [-1, 32, 384, 256]               0\n",
      "            Conv2d-3         [-1, 32, 384, 256]           9,216\n",
      "               ELU-4         [-1, 32, 384, 256]               0\n",
      "            Conv2d-5         [-1, 32, 192, 128]           9,216\n",
      "               ELU-6         [-1, 32, 192, 128]               0\n",
      "            Conv2d-7         [-1, 32, 384, 256]           1,024\n",
      "         MaxPool2d-8         [-1, 32, 192, 128]               0\n",
      "               ELU-9         [-1, 32, 192, 128]               0\n",
      "           Conv2d-10         [-1, 64, 192, 128]          25,088\n",
      "           Conv2d-11         [-1, 64, 192, 128]          36,864\n",
      "              ELU-12         [-1, 64, 192, 128]               0\n",
      "           Conv2d-13           [-1, 64, 96, 64]          36,864\n",
      "              ELU-14           [-1, 64, 96, 64]               0\n",
      "           Conv2d-15         [-1, 64, 192, 128]           4,096\n",
      "        MaxPool2d-16           [-1, 64, 96, 64]               0\n",
      "              ELU-17           [-1, 64, 96, 64]               0\n",
      "           Conv2d-18          [-1, 128, 96, 64]          73,728\n",
      "             Stem-19          [-1, 128, 96, 64]               0\n",
      "           Conv2d-20           [-1, 32, 96, 64]           4,096\n",
      "        MaxPool2d-21           [-1, 32, 96, 64]               0\n",
      "              ELU-22           [-1, 32, 96, 64]               0\n",
      "           Conv2d-23           [-1, 32, 96, 64]           4,096\n",
      "              ELU-24           [-1, 32, 96, 64]               0\n",
      "           Conv2d-25           [-1, 32, 96, 64]           4,096\n",
      "              ELU-26           [-1, 32, 96, 64]               0\n",
      "           Conv2d-27           [-1, 32, 96, 64]           9,216\n",
      "              ELU-28           [-1, 32, 96, 64]               0\n",
      "           Conv2d-29           [-1, 32, 96, 64]           4,096\n",
      "              ELU-30           [-1, 32, 96, 64]               0\n",
      "           Conv2d-31           [-1, 32, 96, 64]          25,600\n",
      "              ELU-32           [-1, 32, 96, 64]               0\n",
      "       InceptionA-33          [-1, 128, 96, 64]               0\n",
      "           Conv2d-34           [-1, 32, 96, 64]           4,096\n",
      "        MaxPool2d-35           [-1, 32, 96, 64]               0\n",
      "              ELU-36           [-1, 32, 96, 64]               0\n",
      "           Conv2d-37           [-1, 32, 96, 64]           4,096\n",
      "              ELU-38           [-1, 32, 96, 64]               0\n",
      "           Conv2d-39           [-1, 32, 96, 64]           4,096\n",
      "              ELU-40           [-1, 32, 96, 64]               0\n",
      "           Conv2d-41           [-1, 32, 96, 64]           9,216\n",
      "              ELU-42           [-1, 32, 96, 64]               0\n",
      "           Conv2d-43           [-1, 32, 96, 64]           4,096\n",
      "              ELU-44           [-1, 32, 96, 64]               0\n",
      "           Conv2d-45           [-1, 32, 96, 64]          25,600\n",
      "              ELU-46           [-1, 32, 96, 64]               0\n",
      "       InceptionA-47          [-1, 128, 96, 64]               0\n",
      "           Conv2d-48           [-1, 32, 96, 64]           4,096\n",
      "        MaxPool2d-49           [-1, 32, 96, 64]               0\n",
      "              ELU-50           [-1, 32, 96, 64]               0\n",
      "           Conv2d-51           [-1, 32, 96, 64]           4,096\n",
      "              ELU-52           [-1, 32, 96, 64]               0\n",
      "           Conv2d-53           [-1, 32, 96, 64]           4,096\n",
      "              ELU-54           [-1, 32, 96, 64]               0\n",
      "           Conv2d-55           [-1, 32, 96, 64]           9,216\n",
      "              ELU-56           [-1, 32, 96, 64]               0\n",
      "           Conv2d-57           [-1, 32, 96, 64]           4,096\n",
      "              ELU-58           [-1, 32, 96, 64]               0\n",
      "           Conv2d-59           [-1, 32, 96, 64]          25,600\n",
      "              ELU-60           [-1, 32, 96, 64]               0\n",
      "       InceptionA-61          [-1, 128, 96, 64]               0\n",
      "           Conv2d-62           [-1, 32, 96, 64]           4,096\n",
      "        MaxPool2d-63           [-1, 32, 96, 64]               0\n",
      "              ELU-64           [-1, 32, 96, 64]               0\n",
      "           Conv2d-65           [-1, 32, 96, 64]           4,096\n",
      "              ELU-66           [-1, 32, 96, 64]               0\n",
      "           Conv2d-67           [-1, 32, 96, 64]           4,096\n",
      "              ELU-68           [-1, 32, 96, 64]               0\n",
      "           Conv2d-69           [-1, 32, 96, 64]           9,216\n",
      "              ELU-70           [-1, 32, 96, 64]               0\n",
      "           Conv2d-71           [-1, 32, 96, 64]           4,096\n",
      "              ELU-72           [-1, 32, 96, 64]               0\n",
      "           Conv2d-73           [-1, 32, 96, 64]          25,600\n",
      "              ELU-74           [-1, 32, 96, 64]               0\n",
      "       InceptionA-75          [-1, 128, 96, 64]               0\n",
      "           Conv2d-76           [-1, 32, 96, 64]           4,096\n",
      "        MaxPool2d-77           [-1, 32, 96, 64]               0\n",
      "              ELU-78           [-1, 32, 96, 64]               0\n",
      "           Conv2d-79           [-1, 32, 96, 64]           4,096\n",
      "              ELU-80           [-1, 32, 96, 64]               0\n",
      "           Conv2d-81           [-1, 32, 96, 64]           4,096\n",
      "              ELU-82           [-1, 32, 96, 64]               0\n",
      "           Conv2d-83           [-1, 32, 96, 64]           9,216\n",
      "              ELU-84           [-1, 32, 96, 64]               0\n",
      "           Conv2d-85           [-1, 32, 96, 64]           4,096\n",
      "              ELU-86           [-1, 32, 96, 64]               0\n",
      "           Conv2d-87           [-1, 32, 96, 64]          25,600\n",
      "              ELU-88           [-1, 32, 96, 64]               0\n",
      "       InceptionA-89          [-1, 128, 96, 64]               0\n",
      "           Conv2d-90           [-1, 32, 96, 64]           4,096\n",
      "        MaxPool2d-91           [-1, 32, 96, 64]               0\n",
      "              ELU-92           [-1, 32, 96, 64]               0\n",
      "           Conv2d-93           [-1, 32, 96, 64]           4,096\n",
      "              ELU-94           [-1, 32, 96, 64]               0\n",
      "           Conv2d-95           [-1, 32, 96, 64]           4,096\n",
      "              ELU-96           [-1, 32, 96, 64]               0\n",
      "           Conv2d-97           [-1, 32, 96, 64]           9,216\n",
      "              ELU-98           [-1, 32, 96, 64]               0\n",
      "           Conv2d-99           [-1, 32, 96, 64]           4,096\n",
      "             ELU-100           [-1, 32, 96, 64]               0\n",
      "          Conv2d-101           [-1, 32, 96, 64]          25,600\n",
      "             ELU-102           [-1, 32, 96, 64]               0\n",
      "      InceptionA-103          [-1, 128, 96, 64]               0\n",
      "          Conv2d-104           [-1, 64, 96, 64]           8,192\n",
      "       MaxPool2d-105           [-1, 64, 48, 32]               0\n",
      "             ELU-106           [-1, 64, 48, 32]               0\n",
      "          Conv2d-107          [-1, 128, 48, 32]         147,456\n",
      "             ELU-108          [-1, 128, 48, 32]               0\n",
      "          Conv2d-109           [-1, 64, 96, 64]           8,192\n",
      "             ELU-110           [-1, 64, 96, 64]               0\n",
      "          Conv2d-111           [-1, 64, 48, 32]         102,400\n",
      "             ELU-112           [-1, 64, 48, 32]               0\n",
      "          Conv2d-113          [-1, 256, 48, 32]         294,912\n",
      "      ReductionA-114          [-1, 256, 48, 32]               0\n",
      "          Conv2d-115           [-1, 64, 48, 32]          16,384\n",
      "       MaxPool2d-116           [-1, 64, 48, 32]               0\n",
      "             ELU-117           [-1, 64, 48, 32]               0\n",
      "          Conv2d-118           [-1, 64, 48, 32]          16,384\n",
      "             ELU-119           [-1, 64, 48, 32]               0\n",
      "          Conv2d-120           [-1, 64, 48, 32]          16,384\n",
      "             ELU-121           [-1, 64, 48, 32]               0\n",
      "          Conv2d-122           [-1, 64, 48, 32]          36,864\n",
      "             ELU-123           [-1, 64, 48, 32]               0\n",
      "          Conv2d-124           [-1, 64, 48, 32]          16,384\n",
      "             ELU-125           [-1, 64, 48, 32]               0\n",
      "          Conv2d-126           [-1, 64, 48, 32]         102,400\n",
      "             ELU-127           [-1, 64, 48, 32]               0\n",
      "      InceptionA-128          [-1, 256, 48, 32]               0\n",
      "          Conv2d-129           [-1, 64, 48, 32]          16,384\n",
      "       MaxPool2d-130           [-1, 64, 48, 32]               0\n",
      "             ELU-131           [-1, 64, 48, 32]               0\n",
      "          Conv2d-132           [-1, 64, 48, 32]          16,384\n",
      "             ELU-133           [-1, 64, 48, 32]               0\n",
      "          Conv2d-134           [-1, 64, 48, 32]          16,384\n",
      "             ELU-135           [-1, 64, 48, 32]               0\n",
      "          Conv2d-136           [-1, 64, 48, 32]          36,864\n",
      "             ELU-137           [-1, 64, 48, 32]               0\n",
      "          Conv2d-138           [-1, 64, 48, 32]          16,384\n",
      "             ELU-139           [-1, 64, 48, 32]               0\n",
      "          Conv2d-140           [-1, 64, 48, 32]         102,400\n",
      "             ELU-141           [-1, 64, 48, 32]               0\n",
      "      InceptionA-142          [-1, 256, 48, 32]               0\n",
      "          Conv2d-143          [-1, 128, 48, 32]          32,768\n",
      "       MaxPool2d-144          [-1, 128, 24, 16]               0\n",
      "             ELU-145          [-1, 128, 24, 16]               0\n",
      "          Conv2d-146          [-1, 256, 24, 16]         589,824\n",
      "             ELU-147          [-1, 256, 24, 16]               0\n",
      "          Conv2d-148          [-1, 128, 48, 32]          32,768\n",
      "             ELU-149          [-1, 128, 48, 32]               0\n",
      "          Conv2d-150          [-1, 128, 24, 16]         409,600\n",
      "             ELU-151          [-1, 128, 24, 16]               0\n",
      "          Conv2d-152          [-1, 512, 24, 16]       1,179,648\n",
      "      ReductionA-153          [-1, 512, 24, 16]               0\n",
      "          Conv2d-154          [-1, 128, 24, 16]          65,536\n",
      "       MaxPool2d-155          [-1, 128, 24, 16]               0\n",
      "             ELU-156          [-1, 128, 24, 16]               0\n",
      "          Conv2d-157          [-1, 128, 24, 16]          65,536\n",
      "             ELU-158          [-1, 128, 24, 16]               0\n",
      "          Conv2d-159          [-1, 128, 24, 16]          65,536\n",
      "             ELU-160          [-1, 128, 24, 16]               0\n",
      "          Conv2d-161          [-1, 128, 24, 16]         802,816\n",
      "             ELU-162          [-1, 128, 24, 16]               0\n",
      "          Conv2d-163          [-1, 128, 24, 16]          65,536\n",
      "             ELU-164          [-1, 128, 24, 16]               0\n",
      "          Conv2d-165          [-1, 128, 24, 16]         802,816\n",
      "             ELU-166          [-1, 128, 24, 16]               0\n",
      "          Conv2d-167          [-1, 128, 24, 16]         802,816\n",
      "             ELU-168          [-1, 128, 24, 16]               0\n",
      "      InceptionB-169          [-1, 512, 24, 16]               0\n",
      "          Conv2d-170          [-1, 128, 24, 16]          65,536\n",
      "       MaxPool2d-171          [-1, 128, 24, 16]               0\n",
      "             ELU-172          [-1, 128, 24, 16]               0\n",
      "          Conv2d-173          [-1, 128, 24, 16]          65,536\n",
      "             ELU-174          [-1, 128, 24, 16]               0\n",
      "          Conv2d-175          [-1, 128, 24, 16]          65,536\n",
      "             ELU-176          [-1, 128, 24, 16]               0\n",
      "          Conv2d-177          [-1, 128, 24, 16]         802,816\n",
      "             ELU-178          [-1, 128, 24, 16]               0\n",
      "          Conv2d-179          [-1, 128, 24, 16]          65,536\n",
      "             ELU-180          [-1, 128, 24, 16]               0\n",
      "          Conv2d-181          [-1, 128, 24, 16]         802,816\n",
      "             ELU-182          [-1, 128, 24, 16]               0\n",
      "          Conv2d-183          [-1, 128, 24, 16]         802,816\n",
      "             ELU-184          [-1, 128, 24, 16]               0\n",
      "      InceptionB-185          [-1, 512, 24, 16]               0\n",
      "          Conv2d-186          [-1, 128, 24, 16]          65,536\n",
      "       MaxPool2d-187          [-1, 128, 24, 16]               0\n",
      "             ELU-188          [-1, 128, 24, 16]               0\n",
      "          Conv2d-189          [-1, 128, 24, 16]          65,536\n",
      "             ELU-190          [-1, 128, 24, 16]               0\n",
      "          Conv2d-191          [-1, 128, 24, 16]          65,536\n",
      "             ELU-192          [-1, 128, 24, 16]               0\n",
      "          Conv2d-193          [-1, 128, 24, 16]         802,816\n",
      "             ELU-194          [-1, 128, 24, 16]               0\n",
      "          Conv2d-195          [-1, 128, 24, 16]          65,536\n",
      "             ELU-196          [-1, 128, 24, 16]               0\n",
      "          Conv2d-197          [-1, 128, 24, 16]         802,816\n",
      "             ELU-198          [-1, 128, 24, 16]               0\n",
      "          Conv2d-199          [-1, 128, 24, 16]         802,816\n",
      "             ELU-200          [-1, 128, 24, 16]               0\n",
      "      InceptionB-201          [-1, 512, 24, 16]               0\n",
      "          Conv2d-202          [-1, 128, 24, 16]          65,536\n",
      "       MaxPool2d-203          [-1, 128, 24, 16]               0\n",
      "             ELU-204          [-1, 128, 24, 16]               0\n",
      "          Conv2d-205          [-1, 128, 24, 16]          65,536\n",
      "             ELU-206          [-1, 128, 24, 16]               0\n",
      "          Conv2d-207          [-1, 128, 24, 16]          65,536\n",
      "             ELU-208          [-1, 128, 24, 16]               0\n",
      "          Conv2d-209          [-1, 128, 24, 16]         802,816\n",
      "             ELU-210          [-1, 128, 24, 16]               0\n",
      "          Conv2d-211          [-1, 128, 24, 16]          65,536\n",
      "             ELU-212          [-1, 128, 24, 16]               0\n",
      "          Conv2d-213          [-1, 128, 24, 16]         802,816\n",
      "             ELU-214          [-1, 128, 24, 16]               0\n",
      "          Conv2d-215          [-1, 128, 24, 16]         802,816\n",
      "             ELU-216          [-1, 128, 24, 16]               0\n",
      "      InceptionB-217          [-1, 512, 24, 16]               0\n",
      "       MaxPool2d-218           [-1, 512, 12, 8]               0\n",
      "             ELU-219           [-1, 512, 12, 8]               0\n",
      "          Conv2d-220          [-1, 256, 24, 16]         131,072\n",
      "             ELU-221          [-1, 256, 24, 16]               0\n",
      "          Conv2d-222           [-1, 256, 12, 8]         589,824\n",
      "             ELU-223           [-1, 256, 12, 8]               0\n",
      "          Conv2d-224          [-1, 256, 24, 16]         131,072\n",
      "             ELU-225          [-1, 256, 24, 16]               0\n",
      "          Conv2d-226          [-1, 256, 24, 16]       3,211,264\n",
      "             ELU-227          [-1, 256, 24, 16]               0\n",
      "          Conv2d-228           [-1, 256, 12, 8]         589,824\n",
      "             ELU-229           [-1, 256, 12, 8]               0\n",
      "          Conv2d-230          [-1, 1024, 12, 8]       4,718,592\n",
      "      ReductionB-231          [-1, 1024, 12, 8]               0\n",
      "          Conv2d-232           [-1, 256, 12, 8]         262,144\n",
      "       MaxPool2d-233           [-1, 256, 12, 8]               0\n",
      "             ELU-234           [-1, 256, 12, 8]               0\n",
      "          Conv2d-235           [-1, 256, 12, 8]         262,144\n",
      "             ELU-236           [-1, 256, 12, 8]               0\n",
      "          Conv2d-237           [-1, 256, 12, 8]         262,144\n",
      "             ELU-238           [-1, 256, 12, 8]               0\n",
      "          Conv2d-239           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-240           [-1, 256, 12, 8]               0\n",
      "          Conv2d-241           [-1, 256, 12, 8]         262,144\n",
      "             ELU-242           [-1, 256, 12, 8]               0\n",
      "          Conv2d-243           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-244           [-1, 256, 12, 8]               0\n",
      "          Conv2d-245           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-246           [-1, 256, 12, 8]               0\n",
      "      InceptionB-247          [-1, 1024, 12, 8]               0\n",
      "          Conv2d-248           [-1, 256, 12, 8]         262,144\n",
      "       MaxPool2d-249           [-1, 256, 12, 8]               0\n",
      "             ELU-250           [-1, 256, 12, 8]               0\n",
      "          Conv2d-251           [-1, 256, 12, 8]         262,144\n",
      "             ELU-252           [-1, 256, 12, 8]               0\n",
      "          Conv2d-253           [-1, 256, 12, 8]         262,144\n",
      "             ELU-254           [-1, 256, 12, 8]               0\n",
      "          Conv2d-255           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-256           [-1, 256, 12, 8]               0\n",
      "          Conv2d-257           [-1, 256, 12, 8]         262,144\n",
      "             ELU-258           [-1, 256, 12, 8]               0\n",
      "          Conv2d-259           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-260           [-1, 256, 12, 8]               0\n",
      "          Conv2d-261           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-262           [-1, 256, 12, 8]               0\n",
      "      InceptionB-263          [-1, 1024, 12, 8]               0\n",
      "          Conv2d-264           [-1, 256, 12, 8]         262,144\n",
      "       MaxPool2d-265           [-1, 256, 12, 8]               0\n",
      "             ELU-266           [-1, 256, 12, 8]               0\n",
      "          Conv2d-267           [-1, 256, 12, 8]         262,144\n",
      "             ELU-268           [-1, 256, 12, 8]               0\n",
      "          Conv2d-269           [-1, 256, 12, 8]         262,144\n",
      "             ELU-270           [-1, 256, 12, 8]               0\n",
      "          Conv2d-271           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-272           [-1, 256, 12, 8]               0\n",
      "          Conv2d-273           [-1, 256, 12, 8]         262,144\n",
      "             ELU-274           [-1, 256, 12, 8]               0\n",
      "          Conv2d-275           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-276           [-1, 256, 12, 8]               0\n",
      "          Conv2d-277           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-278           [-1, 256, 12, 8]               0\n",
      "      InceptionB-279          [-1, 1024, 12, 8]               0\n",
      "          Conv2d-280           [-1, 256, 12, 8]         262,144\n",
      "       MaxPool2d-281           [-1, 256, 12, 8]               0\n",
      "             ELU-282           [-1, 256, 12, 8]               0\n",
      "          Conv2d-283           [-1, 256, 12, 8]         262,144\n",
      "             ELU-284           [-1, 256, 12, 8]               0\n",
      "          Conv2d-285           [-1, 256, 12, 8]         262,144\n",
      "             ELU-286           [-1, 256, 12, 8]               0\n",
      "          Conv2d-287           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-288           [-1, 256, 12, 8]               0\n",
      "          Conv2d-289           [-1, 256, 12, 8]         262,144\n",
      "             ELU-290           [-1, 256, 12, 8]               0\n",
      "          Conv2d-291           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-292           [-1, 256, 12, 8]               0\n",
      "          Conv2d-293           [-1, 256, 12, 8]       3,211,264\n",
      "             ELU-294           [-1, 256, 12, 8]               0\n",
      "      InceptionB-295          [-1, 1024, 12, 8]               0\n",
      "       MaxPool2d-296           [-1, 1024, 6, 4]               0\n",
      "             ELU-297           [-1, 1024, 6, 4]               0\n",
      "          Conv2d-298           [-1, 512, 12, 8]         524,288\n",
      "             ELU-299           [-1, 512, 12, 8]               0\n",
      "          Conv2d-300            [-1, 512, 6, 4]       2,359,296\n",
      "             ELU-301            [-1, 512, 6, 4]               0\n",
      "          Conv2d-302           [-1, 512, 12, 8]         524,288\n",
      "             ELU-303           [-1, 512, 12, 8]               0\n",
      "          Conv2d-304           [-1, 512, 12, 8]      12,845,056\n",
      "             ELU-305           [-1, 512, 12, 8]               0\n",
      "          Conv2d-306            [-1, 512, 6, 4]       2,359,296\n",
      "             ELU-307            [-1, 512, 6, 4]               0\n",
      "          Conv2d-308           [-1, 2048, 6, 4]      18,874,368\n",
      "      ReductionB-309           [-1, 2048, 6, 4]               0\n",
      "          Conv2d-310            [-1, 512, 6, 4]       1,048,576\n",
      "       MaxPool2d-311            [-1, 512, 6, 4]               0\n",
      "             ELU-312            [-1, 512, 6, 4]               0\n",
      "          Conv2d-313            [-1, 512, 6, 4]       1,048,576\n",
      "             ELU-314            [-1, 512, 6, 4]               0\n",
      "          Conv2d-315            [-1, 512, 6, 4]       1,048,576\n",
      "             ELU-316            [-1, 512, 6, 4]               0\n",
      "          Conv2d-317            [-1, 512, 6, 4]      12,845,056\n",
      "             ELU-318            [-1, 512, 6, 4]               0\n",
      "          Conv2d-319            [-1, 512, 6, 4]       1,048,576\n",
      "             ELU-320            [-1, 512, 6, 4]               0\n",
      "          Conv2d-321            [-1, 512, 6, 4]      12,845,056\n",
      "             ELU-322            [-1, 512, 6, 4]               0\n",
      "          Conv2d-323            [-1, 512, 6, 4]      12,845,056\n",
      "             ELU-324            [-1, 512, 6, 4]               0\n",
      "      InceptionB-325           [-1, 2048, 6, 4]               0\n",
      "       AvgPool2d-326           [-1, 2048, 1, 1]               0\n",
      "          Linear-327                  [-1, 256]         524,544\n",
      "             ELU-328                  [-1, 256]               0\n",
      "          Linear-329                   [-1, 64]          16,448\n",
      "             ELU-330                   [-1, 64]               0\n",
      "          Linear-331                   [-1, 16]           1,040\n",
      "             ELU-332                   [-1, 16]               0\n",
      "          Linear-333                   [-1, 16]           1,040\n",
      "            Tanh-334                   [-1, 16]               0\n",
      "          Linear-335                    [-1, 1]              33\n",
      "         Sigmoid-336                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 147,263,617\n",
      "Trainable params: 147,263,617\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12.00\n",
      "Forward/backward pass size (MB): 481.80\n",
      "Params size (MB): 561.77\n",
      "Estimated Total Size (MB): 1055.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import Lossv2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "summary(Lossv2.Loss(seperable=False,slim=False).to(device), (8, 768, 512))  ###  IDK why, but I have to switch the dims in AvgPool on Loss() to get this to work :/ But that breaks the stuff bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.manual_seed(100)\n",
    "np.random.seed(100)\n",
    "import Lossv2\n",
    "import generateLossImages\n",
    "import time\n",
    "\n",
    "global counter \n",
    "counter = 40\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def save_ckp(state, is_best, checkpoint_dir=\"./models/rest/\", best_model_dir=\"./models/best/\"):\n",
    "    global counter \n",
    "    f_path = checkpoint_dir + str(counter) + '_checkpoint.pt'\n",
    "    counter = counter + 1\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_dir + 'best_model.pt'\n",
    "        shutil.copyfile(f_path, best_fpath)\n",
    "\n",
    "def load_ckp(model, optimizer, checkpoint_fpath=\"./models/rest/15_checkpoint.pt\"):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch'], checkpoint['index'], checkpoint['min_lr'], checkpoint['max_lr'], checkpoint['steps'], checkpoint['step_size'], checkpoint['falling'], checkpoint['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in PyTorch 1.12 and later.\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "loss_fn = nn.L1Loss(reduction='sum')\n",
    "min_lr = 0.001\n",
    "max_lr = 0.004\n",
    "decay = 0.9\n",
    "steps = 500\n",
    "falling = True\n",
    "start_epoch = 0\n",
    "start_index = 0\n",
    "momentum = 0.94\n",
    "threshold = [0.16, 0.12, 0.09, 0.06, 0.04, 0.03, 0.02, 0.015, 0.01 -1]\n",
    "step_size = (max_lr-min_lr)/steps\n",
    "model = Lossv2.Loss(seperable=True, slim=True).to(device).to(memory_format=torch.channels_last)\n",
    "#x = torch.rand(22, 8, 512, 768).to(device).to(memory_format=torch.channels_last)\n",
    "model = torch.jit.script(model)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=max_lr, momentum=momentum)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "#\n",
    "#torch.autograd.set_detect_anomaly(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "model = Lossv2.Loss(seperable=True, slim=True).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=max_lr, momentum=momentum)\n",
    "model, optimizer, start_epoch, start_index, min_lr, max_lr, steps, step_size, falling, threshold = load_ckp(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#li = [31.007527351379395, 0.01501011848449707, 0.0010006427764892578, 28.98952603340149, 0.48702239990234375, 47.146605014801025, 12.32689380645752, 0.5665144920349121]\n",
    "#su = sum(li)\n",
    "#print([100*l/su for l in li])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rani\\AppData\\Local\\Temp\\ipykernel_4464\\744408567.py:17: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  torch.autograd.detect_anomaly(check_nan=False)\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "printing = True\n",
    "running_loss = 0.\n",
    "last_loss = 0.\n",
    "lis = []\n",
    " # might have to delete when loading model\n",
    "threshold_decay = 0.2\n",
    "flags = [True for _ in threshold]\n",
    "record = 1\n",
    "epochs = 100\n",
    "times = [0]*8\n",
    "batch_size= 12\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.detect_anomaly(check_nan=False)\n",
    "torch.autograd.set_detect_anomaly(False, check_nan=False)\n",
    "torch.autograd.profiler.profile(enabled=False)\n",
    "torch.autograd.profiler.emit_nvtx(enabled=False)\n",
    "#torch.autograd.gradgradcheck(check_undefined_grad= False)\n",
    "#torch.autograd.gradcheck(check_undefined_grad= False)\n",
    "#torch.no_grad()\n",
    "\n",
    "scaler = GradScaler()\n",
    "#import warnings \n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 53\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39m#load = time.time()\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39m#times[1] += load-start\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m \u001b[39m# Make predictions for this batch\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39mwith\u001b[39;00m autocast():\n\u001b[1;32m---> 53\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     55\u001b[0m     \u001b[39m#out = time.time()\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[39m#times[3] += (out-lab)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m     \u001b[39m# Compute the loss and its gradients\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\Rani\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "startup = False\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    if startup:\n",
    "        training = generateLossImages.MakeIter(start_index=start_index if epoch == start_epoch else 0, startup = True)#, epoch=epoch) # start=2*71*50*4))#start_index if epoch == start_epoch else 0)) \n",
    "        #val = generateLossImages.get_image_pairs_transforms_with_loss(\"C:/Users/Rani/Desktop/ai_val/16\")\n",
    "        training_loader = torch.utils.data.DataLoader(training, batch_size=batch_size, num_workers=2)#), worker_init_fn=worker_init_fn) # num_workers\n",
    "        startup = True\n",
    "        min_lr *= batch_size**0.5\n",
    "        max_lr *= batch_size**0.5\n",
    "        step_size = (max_lr-min_lr)/steps\n",
    "        optimizer.param_groups[-1]['lr'] = max_lr\n",
    "        los = [0]*(112//batch_size)\n",
    "        pred = [0]*(112//batch_size)\n",
    "        \n",
    "    else:\n",
    "        training = generateLossImages.MakeIter(start_index=start_index if epoch == start_epoch else 0, epoch=epoch, startup = False) # start=2*71*50*4))#start_index if epoch == start_epoch else 0)) \n",
    "        #val = generateLossImages.get_image_pairs_transforms_with_loss(\"C:/Users/Rani/Desktop/ai_val/16\")\n",
    "        training_loader = torch.utils.data.DataLoader(training, batch_size=batch_size, num_workers=2)#2)#), worker_init_fn=worker_init_fn) # num_workers\n",
    "        #max_lr /= 10\n",
    "        #min_lr /= 10\n",
    "        #steps *= 2\n",
    "        #step_size = (max_lr-min_lr)/steps\n",
    "        #falling = True\n",
    "        #optimizer.param_groups[-1]['lr'] = max_lr\n",
    "\n",
    "    #end = 0\n",
    "    #before_start = 0\n",
    "    #in_upstart = True\n",
    "    \n",
    "    \n",
    "    \n",
    "    for index, data in enumerate(training_loader):#[90.06174230575562, 0.03202486038208008, 0.016014575958251953, 84.36967897415161, 1.3647308349609375, 137.4005196094513, 34.81299662590027, 1.9427943229675293, 0, 0]\n",
    "        #print(len(inputs))\n",
    "        #before_start += 1\n",
    "        #if before_start > 55*11/batch_size and in_upstart:\n",
    "        #    in_upstart = False\n",
    "        #    times = [0]*8\n",
    "        #start = time.time()\n",
    "        #if end != 0:\n",
    "        #    times[0] += (start-end)\n",
    "        inputs, labels = data\n",
    "        labels = torch.unsqueeze(labels, dim=-1)\n",
    "        inputs.to(memory_format=torch.channels_last)\n",
    "        #load = time.time()\n",
    "        #times[1] += load-start\n",
    "\n",
    "        #lab = time.time()\n",
    "        #times[2] += (lab-load)\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            #out = time.time()\n",
    "            #times[3] += (out-lab)\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            #los = time.time()\n",
    "            #times[4] += (los-out)\n",
    "\n",
    "        loss.backward()#scaler.scale(loss).backward()#loss.backward()\n",
    "        \n",
    "        #back = time.time()\n",
    "        #times[5] += (back-los)\n",
    "        # Gather data and report\n",
    "        if startup:\n",
    "            los[index%(112//batch_size)] = loss.item()\n",
    "            pred[index%(112//batch_size)] = (list(zip(labels.detach().cpu().numpy().tolist(),outputs.detach().cpu().numpy().tolist())))\n",
    "            \n",
    "        #runn = time.time()\n",
    "        #times[6] += (runn-back)\n",
    "        if startup:\n",
    "            if index % (112//batch_size) == (112//batch_size)-1:\n",
    "                optimizer.step()#scaler.step(optimizer)#optimizer.step()\n",
    "                #scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "        else:\n",
    "            optimizer.step()#scaler.step(optimizer)#optimizer.step()\n",
    "                #scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        if falling:\n",
    "            optimizer.param_groups[-1]['lr'] = optimizer.param_groups[-1]['lr'] - step_size\n",
    "            if optimizer.param_groups[-1]['lr'] < min_lr:\n",
    "                falling = False\n",
    "                max_lr *= decay\n",
    "                min_lr *= decay\n",
    "                steps /= decay\n",
    "                step_size = (max_lr-min_lr)/steps\n",
    "\n",
    "                if printing:\n",
    "                    print(\"!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                    print(min_lr)\n",
    "                    print(max_lr)\n",
    "                    print(steps)\n",
    "                    print(step_size)\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'index': index,\n",
    "                    'min_lr': min_lr,\n",
    "                    'max_lr': max_lr,\n",
    "                    'steps': steps,\n",
    "                    'step_size': step_size,\n",
    "                    'falling': falling,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'threshold': threshold\n",
    "                }\n",
    "                save_ckp(checkpoint, True)\n",
    "                \n",
    "                if startup and sum(los)/10 < 0.05 and max(los) < 0.1:\n",
    "                    #max_lr *= 0.4\n",
    "                    #min_lr *= 0.4\n",
    "                    #steps /= 0.4\n",
    "                    #step_size = (max_lr-min_lr)/steps\n",
    "                    #print(\"loss\")\n",
    "                    print(loss.item())\n",
    "                    print(\"lr\")\n",
    "                    print(optimizer.param_groups[-1]['lr'])\n",
    "                    print(\"pred\")\n",
    "                    print(labels)\n",
    "                    print(outputs.T)\n",
    "                    startup = False\n",
    "                    max_lr /= 4\n",
    "                    min_lr /= 4\n",
    "                    steps *= 2\n",
    "                    step_size = (max_lr-min_lr)/steps\n",
    "                    falling = True\n",
    "                    optimizer.param_groups[-1]['lr'] = max_lr\n",
    "                    print(\"startup done !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                    break\n",
    "\n",
    "\n",
    "        else: \n",
    "            optimizer.param_groups[-1]['lr'] += step_size\n",
    "            if optimizer.param_groups[-1]['lr'] > max_lr:\n",
    "                falling = True\n",
    "\n",
    "        if startup:\n",
    "            if printing and index % (112//batch_size) == (112//batch_size)-1:\n",
    "                print(\"loss\")\n",
    "                print(loss.item())\n",
    "                print(\"lr\")\n",
    "                print(optimizer.param_groups[-1]['lr'])\n",
    "                print(\"pred\")\n",
    "                print(pred)\n",
    "                \n",
    "        elif index % (20*(112//batch_size)-1) == 0:\n",
    "        #    print(\"loss\")\n",
    "            print(\"loss\")\n",
    "            print(loss.item())\n",
    "            print(\"lr\")\n",
    "            print(optimizer.param_groups[-1]['lr'])\n",
    "            print(\"pred\")\n",
    "            print(labels.T)\n",
    "            print(outputs.T)\n",
    "        #        print('  batch {} loss: {}'.format(index + 1, last_loss))\n",
    "        #        print(lis)\n",
    "        #        lis = []\n",
    "        #    running_loss = 0\n",
    "\n",
    "        #    if last_loss < record:\n",
    "        #        record = last_loss\n",
    "        #        if last_loss < 0.08:\n",
    "        #            checkpoint = {\n",
    "        #            'epoch': epoch,\n",
    "        #            'index': index,\n",
    "        #            'min_lr': min_lr,\n",
    "        #            'max_lr': max_lr,\n",
    "        #            'steps': steps,\n",
    "        #            'step_size': step_size,\n",
    "        #            'falling': falling,\n",
    "        #            'state_dict': model.state_dict(),\n",
    "        #            'optimizer': optimizer.state_dict(),\n",
    "        #            'threshold': threshold\n",
    "        #        }\n",
    "        #            save_ckp(checkpoint, True)\n",
    "        \n",
    "            \n",
    "    #    end = time.time()\n",
    "    #    times[7] += (end-runn)\n",
    "        \n",
    "    #    if before_start > 70*11/batch_size:\n",
    "    #        break\n",
    "    #break\n",
    "    \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "2.045703172683716\n",
      "lr\n",
      "0.0011391120811111322\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.4924, 0.5010, 0.5098, 0.5142, 0.5103, 0.5044, 0.4973, 0.5435, 0.5381,\n",
      "         0.5479, 0.5337, 0.5205]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2075682878494263\n",
      "lr\n",
      "0.0011235236238430128\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.4927, 0.4951, 0.4946, 0.4824, 0.4941, 0.5049, 0.5059, 0.5000, 0.5151,\n",
      "         0.5063, 0.5117, 0.4954]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.2891602516174316\n",
      "lr\n",
      "0.0011079351665748934\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.5820, 0.6016, 0.6055, 0.5796, 0.5640, 0.5923, 0.6309, 0.6270, 0.6611,\n",
      "         0.6299, 0.5991, 0.7837]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "3.256640672683716\n",
      "lr\n",
      "0.001092346709306774\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.8926, 0.8818, 0.6191, 0.5820, 0.6138, 0.6313, 0.5752, 0.5469, 0.6255,\n",
      "         0.6704, 0.7266, 0.6914]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.9447264671325684\n",
      "lr\n",
      "0.0010767582520386546\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.8276, 0.8052, 0.8867, 0.6445, 0.6118, 0.6562, 0.6460, 0.6143, 0.5815,\n",
      "         0.6602, 0.6777, 0.7329]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.7276854515075684\n",
      "lr\n",
      "0.0010611697947705352\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.5996, 0.5967, 0.6616, 0.6387, 0.7676, 0.8149, 0.5205, 0.5020, 0.5122,\n",
      "         0.5259, 0.4919, 0.4893]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.3327146768569946\n",
      "lr\n",
      "0.0010455813375024158\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.6118, 0.6294, 0.6821, 0.6729, 0.7510, 0.6875, 0.7627, 0.5400, 0.5244,\n",
      "         0.5635, 0.5513, 0.5562]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.2122557163238525\n",
      "lr\n",
      "0.0010299928802342964\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.5054, 0.4980, 0.5205, 0.4856, 0.4758, 0.4734, 0.4998, 0.4871, 0.5845,\n",
      "         0.5405, 0.4421, 0.4407]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.443603754043579\n",
      "lr\n",
      "0.001014404422966177\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.4788, 0.4651, 0.4822, 0.4622, 0.4543, 0.4536, 0.4514, 0.4707, 0.4919,\n",
      "         0.4966, 0.7139, 0.4365]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.5291013717651367\n",
      "lr\n",
      "0.0009988159656980577\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.6548, 0.6460, 0.8848, 0.8193, 0.6021, 0.5825, 0.6587, 0.5635, 0.5259,\n",
      "         0.5400, 0.6079, 0.5854]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.4825193881988525\n",
      "lr\n",
      "0.0009832275084299383\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.4956, 0.8350, 0.6436, 0.5938, 0.6729, 0.6387, 0.7725, 0.6528, 0.6279,\n",
      "         0.6670, 0.7261, 0.7568]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2980468273162842\n",
      "lr\n",
      "0.0009676390511618182\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.8296, 0.8271, 0.7100, 0.7573, 0.8145, 0.7534, 0.9111, 0.9902, 0.8828,\n",
      "         0.8657, 0.7788, 0.7612]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.429931640625\n",
      "lr\n",
      "0.0009520505938936979\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.4121, 0.4006, 0.4036, 0.4226, 0.4709, 0.7446, 0.4441, 0.4243, 0.7393,\n",
      "         0.7026, 0.6279, 0.6372]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.7955565452575684\n",
      "lr\n",
      "0.0009364621366255775\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.3638, 0.3811, 0.9194, 0.9053, 0.8223, 0.7764, 0.6084, 0.6235, 0.6968,\n",
      "         0.7271, 0.9258, 0.9546]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.2467775344848633\n",
      "lr\n",
      "0.0009208736793574571\n",
      "pred\n",
      "tensor([[1.0000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9609, 0.3093, 0.3110, 0.3154, 0.3149, 0.3486, 0.3411, 0.3643, 0.3892,\n",
      "         0.7100, 0.5327, 0.4712]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.432079792022705\n",
      "lr\n",
      "0.0009052852220893368\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.3132, 0.3101, 0.3284, 0.3347, 0.3477, 0.3555, 0.8403, 0.8125, 0.8286,\n",
      "         0.7207, 0.5742, 0.5811]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.470605492591858\n",
      "lr\n",
      "0.0008896967648212164\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.6836, 0.7251, 0.9673, 0.8623, 0.9741, 0.2820, 0.2852, 0.2871, 0.2837,\n",
      "         0.3071, 0.3174, 0.3206]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m scaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward()\u001b[39m#loss.backward()\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39mif\u001b[39;00m startup:\n\u001b[1;32m---> 29\u001b[0m     los[index\u001b[39m%\u001b[39m(\u001b[39m112\u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mbatch_size)] \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\u001b[39m/\u001b[39mbatch_size\n\u001b[0;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39m%\u001b[39m (\u001b[39m112\u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mbatch_size) \u001b[39m==\u001b[39m (\u001b[39m112\u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mbatch_size)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:         \n\u001b[0;32m     31\u001b[0m         scaler\u001b[39m.\u001b[39mstep(optimizer)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "startup = True\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    if startup:\n",
    "        training = generateLossImages.MakeIter(start_index=start_index if epoch == start_epoch else 0, startup = True)\n",
    "        training_loader = torch.utils.data.DataLoader(training, batch_size=batch_size, num_workers=2)\n",
    "        min_lr /= batch_size**0.5  # normally one puts the learning rate up by sqrt(batchsize), since that keeps the variance constant, however since we use sum in L1Loss, the oposit is true\n",
    "        max_lr /= batch_size**0.5\n",
    "        step_size = (max_lr-min_lr)/steps\n",
    "        optimizer.param_groups[-1]['lr'] = max_lr\n",
    "        los = [0]*(112//batch_size)\n",
    "    else:\n",
    "        training = generateLossImages.MakeIter(start_index=start_index if epoch == start_epoch else 0, epoch=epoch, startup = False)\n",
    "        training_loader = torch.utils.data.DataLoader(training, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "\n",
    "    for index, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        labels = torch.unsqueeze(labels, dim=-1)\n",
    "        inputs.to(memory_format=torch.channels_last)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(inputs)            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()#loss.backward()\n",
    "        if startup:\n",
    "            los[index%(112//batch_size)] = loss.item()/batch_size\n",
    "            if index % (112//batch_size) == (112//batch_size)-1:         \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "        else:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if falling:\n",
    "            optimizer.param_groups[-1]['lr'] = optimizer.param_groups[-1]['lr'] - step_size\n",
    "            if optimizer.param_groups[-1]['lr'] < min_lr:\n",
    "                falling = False\n",
    "                max_lr *= decay\n",
    "                min_lr *= decay\n",
    "                steps /= decay\n",
    "                step_size = (max_lr-min_lr)/steps\n",
    "                if printing:\n",
    "                    print(\"Saving model !!\")\n",
    "                    print(\"Min lr\")\n",
    "                    print(min_lr)\n",
    "                    print(\"Max lr\")\n",
    "                    print(max_lr)\n",
    "                checkpoint = {'epoch': epoch, 'index': index, 'min_lr': min_lr, 'max_lr': max_lr, 'steps': steps, 'step_size': step_size, 'falling': falling, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'threshold': threshold\n",
    "                }\n",
    "                save_ckp(checkpoint, True)\n",
    "                \n",
    "                if startup and sum(los)/10 < 0.05 and max(los) < 0.1:\n",
    "                    startup = False\n",
    "                    max_lr /= 4\n",
    "                    min_lr /= 4\n",
    "                    steps *= 2\n",
    "                    step_size = (max_lr-min_lr)/steps\n",
    "                    falling = True\n",
    "                    optimizer.param_groups[-1]['lr'] = max_lr\n",
    "                    print(\"startup done ! !\")\n",
    "                    break\n",
    "        else: \n",
    "            optimizer.param_groups[-1]['lr'] += step_size\n",
    "            if optimizer.param_groups[-1]['lr'] > max_lr:\n",
    "                falling = True\n",
    "\n",
    "        if (startup and printing and index % (112//batch_size) == (112//batch_size)-1) or (not startup and printing and index % (20*(112//batch_size) == (112//batch_size))-1):\n",
    "            print(\"loss\")\n",
    "            print(loss.item())\n",
    "            print(\"lr\")\n",
    "            print(optimizer.param_groups[-1]['lr'])\n",
    "            print(\"pred\")\n",
    "            print(labels.T)\n",
    "            print(outputs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0040051937103271484, 0.8806514739990234, 0.0, 0.1621570587158203, 0.001001119613647461, 0.31227612495422363, 0.0, 0.024025678634643555]\n",
      "[0.2893682198971097, 63.62552420967629, 0.0, 11.715563045892052, 0.07232913598118719, 22.561402251625466, 0.0, 1.735813136927891]\n"
     ]
    }
   ],
   "source": [
    "print(times)\n",
    "su = sum(times)\n",
    "print([100*l/su for l in times])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4193603606135756\n"
     ]
    }
   ],
   "source": [
    "print(su/15*6645*50*4/86400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f33075560525c4759195768b52de2817c211ae9aef6733cbe5230884af85532a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
