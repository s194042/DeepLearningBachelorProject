{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#from torch import nn\n",
    "#import numpy as np\n",
    "#from torchsummary import summary\n",
    "#import Lossv2\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#summary(Lossv2.Loss().to(device), (6, 768, 512))  ###  IDK why, but I have to switch the dims in AvgPool on Loss() to get this to work :/ But that breaks the stuff bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.manual_seed(100)\n",
    "np.random.seed(100)\n",
    "import Lossv2\n",
    "import generateLossImages\n",
    "import time\n",
    "\n",
    "global counter \n",
    "counter = 16\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def save_ckp(state, is_best, checkpoint_dir=\"./models/rest/\", best_model_dir=\"./models/best/\"):\n",
    "    global counter \n",
    "    f_path = checkpoint_dir + str(counter) + '_checkpoint.pt'\n",
    "    counter = counter + 1\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_dir + 'best_model.pt'\n",
    "        shutil.copyfile(f_path, best_fpath)\n",
    "\n",
    "def load_ckp(model, optimizer, checkpoint_fpath=\"./models/rest/15_checkpoint.pt\"):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch'], checkpoint['index'], checkpoint['min_lr'], checkpoint['max_lr'], checkpoint['steps'], checkpoint['step_size'], checkpoint['falling'], checkpoint['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in PyTorch 1.12 and later.\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "loss_fn = nn.L1Loss(reduction='sum')\n",
    "min_lr = 0.001\n",
    "max_lr = 0.004\n",
    "decay = 0.9\n",
    "steps = 500\n",
    "falling = True\n",
    "start_epoch = 0\n",
    "start_index = 0\n",
    "momentum = 0.94\n",
    "threshold = [0.16, 0.12, 0.09, 0.06, 0.04, 0.03, 0.02, 0.015, 0.01 -1]\n",
    "step_size = (max_lr-min_lr)/steps\n",
    "model = Lossv2.Loss(seperable=True, slim=True).to(device).to(memory_format=torch.channels_last)\n",
    "#x = torch.rand(22, 8, 512, 768).to(device).to(memory_format=torch.channels_last)\n",
    "model = torch.jit.script(model)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=max_lr, momentum=momentum)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "#\n",
    "#torch.autograd.set_detect_anomaly(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "model = Lossv2.Loss(seperable=True, slim=True).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=max_lr, momentum=momentum)\n",
    "model, optimizer, start_epoch, start_index, min_lr, max_lr, steps, step_size, falling, threshold = load_ckp(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#li = [31.007527351379395, 0.01501011848449707, 0.0010006427764892578, 28.98952603340149, 0.48702239990234375, 47.146605014801025, 12.32689380645752, 0.5665144920349121]\n",
    "#su = sum(li)\n",
    "#print([100*l/su for l in li])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rani\\AppData\\Local\\Temp\\ipykernel_7000\\744408567.py:17: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  torch.autograd.detect_anomaly(check_nan=False)\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "printing = True\n",
    "running_loss = 0.\n",
    "last_loss = 0.\n",
    "lis = []\n",
    " # might have to delete when loading model\n",
    "threshold_decay = 0.2\n",
    "flags = [True for _ in threshold]\n",
    "record = 1\n",
    "epochs = 100\n",
    "times = [0]*8\n",
    "batch_size= 12\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.detect_anomaly(check_nan=False)\n",
    "torch.autograd.set_detect_anomaly(False, check_nan=False)\n",
    "torch.autograd.profiler.profile(enabled=False)\n",
    "torch.autograd.profiler.emit_nvtx(enabled=False)\n",
    "#torch.autograd.gradgradcheck(check_undefined_grad= False)\n",
    "#torch.autograd.gradcheck(check_undefined_grad= False)\n",
    "#torch.no_grad()\n",
    "\n",
    "#scaler = GradScaler()\n",
    "#import warnings \n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "0.0026531219482421875\n",
      "lr\n",
      "7.13500763380393e-05\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0027,\n",
      "         0.0027, 0.0027, 0.0027]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "startup = False\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    if startup:\n",
    "        training = generateLossImages.MakeIter(start_index=start_index if epoch == start_epoch else 0, startup = True)#, epoch=epoch) # start=2*71*50*4))#start_index if epoch == start_epoch else 0)) \n",
    "        #val = generateLossImages.get_image_pairs_transforms_with_loss(\"C:/Users/Rani/Desktop/ai_val/16\")\n",
    "        training_loader = torch.utils.data.DataLoader(training, batch_size=batch_size, num_workers=2)#), worker_init_fn=worker_init_fn) # num_workers\n",
    "        startup = True\n",
    "        min_lr *= batch_size**0.5\n",
    "        max_lr *= batch_size**0.5\n",
    "        step_size = (max_lr-min_lr)/steps\n",
    "        optimizer.param_groups[-1]['lr'] = max_lr\n",
    "        los = [0]*(112//batch_size)\n",
    "        pred = [0]*(112//batch_size)\n",
    "        \n",
    "    else:\n",
    "        training = generateLossImages.MakeIter(start_index=start_index if epoch == start_epoch else 0, epoch=epoch, startup = False) # start=2*71*50*4))#start_index if epoch == start_epoch else 0)) \n",
    "        #val = generateLossImages.get_image_pairs_transforms_with_loss(\"C:/Users/Rani/Desktop/ai_val/16\")\n",
    "        training_loader = torch.utils.data.DataLoader(training, batch_size=batch_size, num_workers=2)#2)#), worker_init_fn=worker_init_fn) # num_workers\n",
    "        #max_lr /= 10\n",
    "        #min_lr /= 10\n",
    "        #steps *= 2\n",
    "        #step_size = (max_lr-min_lr)/steps\n",
    "        #falling = True\n",
    "        #optimizer.param_groups[-1]['lr'] = max_lr\n",
    "\n",
    "    #end = 0\n",
    "    #before_start = 0\n",
    "    #in_upstart = True\n",
    "    \n",
    "    \n",
    "    \n",
    "    for index, data in enumerate(training_loader):#[90.06174230575562, 0.03202486038208008, 0.016014575958251953, 84.36967897415161, 1.3647308349609375, 137.4005196094513, 34.81299662590027, 1.9427943229675293, 0, 0]\n",
    "        #print(len(inputs))\n",
    "        #before_start += 1\n",
    "        #if before_start > 55*11/batch_size and in_upstart:\n",
    "        #    in_upstart = False\n",
    "        #    times = [0]*8\n",
    "        #start = time.time()\n",
    "        #if end != 0:\n",
    "        #    times[0] += (start-end)\n",
    "        inputs, labels = data\n",
    "        labels = torch.unsqueeze(labels, dim=-1)\n",
    "        inputs.to(memory_format=torch.channels_last)\n",
    "        #load = time.time()\n",
    "        #times[1] += load-start\n",
    "\n",
    "        #lab = time.time()\n",
    "        #times[2] += (lab-load)\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            #out = time.time()\n",
    "            #times[3] += (out-lab)\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            #los = time.time()\n",
    "            #times[4] += (los-out)\n",
    "\n",
    "        loss.backward()#scaler.scale(loss).backward()#loss.backward()\n",
    "        \n",
    "        #back = time.time()\n",
    "        #times[5] += (back-los)\n",
    "        # Gather data and report\n",
    "        if startup:\n",
    "            los[index%(112//batch_size)] = loss.item()\n",
    "            pred[index%(112//batch_size)] = (list(zip(labels.detach().cpu().numpy().tolist(),outputs.detach().cpu().numpy().tolist())))\n",
    "            \n",
    "        #runn = time.time()\n",
    "        #times[6] += (runn-back)\n",
    "        if startup:\n",
    "            if index % (112//batch_size) == (112//batch_size)-1:\n",
    "                optimizer.step()#scaler.step(optimizer)#optimizer.step()\n",
    "                #scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "        else:\n",
    "            optimizer.step()#scaler.step(optimizer)#optimizer.step()\n",
    "                #scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        if falling:\n",
    "            optimizer.param_groups[-1]['lr'] = optimizer.param_groups[-1]['lr'] - step_size\n",
    "            if optimizer.param_groups[-1]['lr'] < min_lr:\n",
    "                falling = False\n",
    "                max_lr *= decay\n",
    "                min_lr *= decay\n",
    "                steps /= decay\n",
    "                step_size = (max_lr-min_lr)/steps\n",
    "\n",
    "                if printing:\n",
    "                    print(\"!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                    print(min_lr)\n",
    "                    print(max_lr)\n",
    "                    print(steps)\n",
    "                    print(step_size)\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'index': index,\n",
    "                    'min_lr': min_lr,\n",
    "                    'max_lr': max_lr,\n",
    "                    'steps': steps,\n",
    "                    'step_size': step_size,\n",
    "                    'falling': falling,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'threshold': threshold\n",
    "                }\n",
    "                save_ckp(checkpoint, True)\n",
    "                \n",
    "                if startup and sum(los)/10 < 0.05 and max(los) < 0.1:\n",
    "                    #max_lr *= 0.4\n",
    "                    #min_lr *= 0.4\n",
    "                    #steps /= 0.4\n",
    "                    #step_size = (max_lr-min_lr)/steps\n",
    "                    #print(\"loss\")\n",
    "                    print(loss.item())\n",
    "                    print(\"lr\")\n",
    "                    print(optimizer.param_groups[-1]['lr'])\n",
    "                    print(\"pred\")\n",
    "                    print(labels)\n",
    "                    print(outputs.T)\n",
    "                    startup = False\n",
    "                    max_lr /= 4\n",
    "                    min_lr /= 4\n",
    "                    steps *= 2\n",
    "                    step_size = (max_lr-min_lr)/steps\n",
    "                    falling = True\n",
    "                    optimizer.param_groups[-1]['lr'] = max_lr\n",
    "                    print(\"startup done !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                    break\n",
    "\n",
    "\n",
    "        else: \n",
    "            optimizer.param_groups[-1]['lr'] += step_size\n",
    "            if optimizer.param_groups[-1]['lr'] > max_lr:\n",
    "                falling = True\n",
    "\n",
    "        if startup:\n",
    "            if printing and index % (112//batch_size) == (112//batch_size)-1:\n",
    "                print(\"loss\")\n",
    "                print(loss.item())\n",
    "                print(\"lr\")\n",
    "                print(optimizer.param_groups[-1]['lr'])\n",
    "                print(\"pred\")\n",
    "                print(pred)\n",
    "                \n",
    "        elif index % (20*(112//batch_size)-1) == 0:\n",
    "        #    print(\"loss\")\n",
    "            print(\"loss\")\n",
    "            print(loss.item())\n",
    "            print(\"lr\")\n",
    "            print(optimizer.param_groups[-1]['lr'])\n",
    "            print(\"pred\")\n",
    "            print(labels.T)\n",
    "            print(outputs.T)\n",
    "        #        print('  batch {} loss: {}'.format(index + 1, last_loss))\n",
    "        #        print(lis)\n",
    "        #        lis = []\n",
    "        #    running_loss = 0\n",
    "\n",
    "        #    if last_loss < record:\n",
    "        #        record = last_loss\n",
    "        #        if last_loss < 0.08:\n",
    "        #            checkpoint = {\n",
    "        #            'epoch': epoch,\n",
    "        #            'index': index,\n",
    "        #            'min_lr': min_lr,\n",
    "        #            'max_lr': max_lr,\n",
    "        #            'steps': steps,\n",
    "        #            'step_size': step_size,\n",
    "        #            'falling': falling,\n",
    "        #            'state_dict': model.state_dict(),\n",
    "        #            'optimizer': optimizer.state_dict(),\n",
    "        #            'threshold': threshold\n",
    "        #        }\n",
    "        #            save_ckp(checkpoint, True)\n",
    "        \n",
    "            \n",
    "    #    end = time.time()\n",
    "    #    times[7] += (end-runn)\n",
    "        \n",
    "    #    if before_start > 70*11/batch_size:\n",
    "    #        break\n",
    "    #break\n",
    "    \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "2.045703172683716\n",
      "lr\n",
      "0.0011391120811111322\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.4924, 0.5010, 0.5098, 0.5142, 0.5103, 0.5044, 0.4973, 0.5435, 0.5381,\n",
      "         0.5479, 0.5337, 0.5205]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.5825682878494263\n",
      "lr\n",
      "0.0011235236238430128\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.5122, 0.5190, 0.5127, 0.4924, 0.5225, 0.5425, 0.5479, 0.5337, 0.5698,\n",
      "         0.5479, 0.5542, 0.5278]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.617382764816284\n",
      "lr\n",
      "0.0011079351665748934\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.6030, 0.6274, 0.6328, 0.6011, 0.5825, 0.6177, 0.6646, 0.6602, 0.7012,\n",
      "         0.6646, 0.6260, 0.8364]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "3.460742235183716\n",
      "lr\n",
      "0.001092346709306774\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.9277, 0.9175, 0.6294, 0.5859, 0.6240, 0.6445, 0.5820, 0.5474, 0.6396,\n",
      "         0.6929, 0.7554, 0.7144]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.9095702171325684\n",
      "lr\n",
      "0.0010767582520386546\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.8438, 0.8184, 0.9082, 0.6309, 0.5952, 0.6445, 0.6333, 0.6050, 0.5679,\n",
      "         0.6553, 0.6738, 0.7334]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.6332030296325684\n",
      "lr\n",
      "0.0010611697947705352\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.5493, 0.5439, 0.6079, 0.5835, 0.7207, 0.7812, 0.4739, 0.4629, 0.4702,\n",
      "         0.4788, 0.4680, 0.4622]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6190918684005737\n",
      "lr\n",
      "0.0010455813375024158\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.5054, 0.5151, 0.5684, 0.5557, 0.6313, 0.5635, 0.6479, 0.4407, 0.4353,\n",
      "         0.4531, 0.4478, 0.4709]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.4824217557907104\n",
      "lr\n",
      "0.0010299928802342964\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.5933, 0.5732, 0.6333, 0.5449, 0.5039, 0.4958, 0.5586, 0.5356, 0.7544,\n",
      "         0.6636, 0.4180, 0.4124]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.0272459983825684\n",
      "lr\n",
      "0.001014404422966177\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.6758, 0.6294, 0.6890, 0.6230, 0.5845, 0.5659, 0.5688, 0.6528, 0.7129,\n",
      "         0.7261, 0.9355, 0.5020]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.0362305641174316\n",
      "lr\n",
      "0.0009988159656980577\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.8862, 0.8833, 0.9834, 0.9619, 0.8315, 0.8081, 0.8833, 0.7891, 0.7290,\n",
      "         0.7529, 0.8447, 0.8218]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.1376953125\n",
      "lr\n",
      "0.0009832275084299383\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.4248, 0.8257, 0.5786, 0.5151, 0.5972, 0.5503, 0.7407, 0.5850, 0.6084,\n",
      "         0.6689, 0.7510, 0.7568]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "3.0488767623901367\n",
      "lr\n",
      "0.0009676390511618182\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.5254, 0.5278, 0.4705, 0.6328, 0.6958, 0.5215, 0.6802, 0.9492, 0.6069,\n",
      "         0.5659, 0.4407, 0.4329]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.7445802688598633\n",
      "lr\n",
      "0.0009520505938936979\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2761, 0.3069, 0.3428, 0.3484, 0.3340, 0.4941, 0.2839, 0.2810, 0.4846,\n",
      "         0.4351, 0.3870, 0.4160]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9668946862220764\n",
      "lr\n",
      "0.0009364621366255775\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.3149, 0.3442, 0.9746, 0.9678, 0.9473, 0.9292, 0.8799, 0.8667, 0.9229,\n",
      "         0.9399, 0.9824, 0.9902]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.5695314407348633\n",
      "lr\n",
      "0.0009208736793574571\n",
      "pred\n",
      "tensor([[1.0000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9976, 0.2355, 0.2394, 0.2502, 0.2659, 0.3347, 0.2876, 0.3430, 0.4929,\n",
      "         0.9224, 0.7568, 0.6387]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2867677211761475\n",
      "lr\n",
      "0.0009052852220893368\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.2163, 0.2203, 0.2656, 0.2395, 0.2482, 0.2961, 0.9316, 0.9131, 0.9531,\n",
      "         0.9102, 0.8647, 0.6426]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.280419945716858\n",
      "lr\n",
      "0.0008896967648212164\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.4583, 0.7471, 0.9385, 0.7148, 0.9385, 0.1859, 0.1946, 0.1887, 0.1934,\n",
      "         0.2372, 0.1984, 0.2013]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.147436499595642\n",
      "lr\n",
      "0.000874108307553096\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.8022, 0.9565, 0.1866, 0.1947, 0.1899, 0.1943, 0.2261, 0.1998, 0.1993,\n",
      "         0.2218, 0.8311, 0.7930]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1187012195587158\n",
      "lr\n",
      "0.0008585198502849756\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9727, 0.9541, 0.9072, 0.6094, 0.6914, 0.8667, 0.9946, 0.9165, 0.9932,\n",
      "         0.1912, 0.1904, 0.2061]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.5201659202575684\n",
      "lr\n",
      "0.0008429313930168553\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.8438, 0.9009, 0.9482, 0.9810, 0.9780, 0.9966, 0.2023, 0.1971, 0.2203,\n",
      "         0.2109, 0.2278, 0.2133]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.49560546875\n",
      "lr\n",
      "0.0008273429357487349\n",
      "pred\n",
      "tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.2368, 0.3652, 0.9346, 0.9219, 0.9141, 0.8940, 0.8403, 0.8530, 0.9199,\n",
      "         0.8818, 0.9668, 0.9800]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.3079102039337158\n",
      "lr\n",
      "0.0008117544784806145\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.6768, 0.7026, 0.6748, 0.6421, 0.6084, 0.6338, 0.6738, 0.7866, 0.7178,\n",
      "         0.8511, 0.1887, 0.1848]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.937255859375\n",
      "lr\n",
      "0.0007961660212124942\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.1743, 0.1765, 0.1896, 0.1921, 0.1846, 0.1891, 0.7456, 0.7075, 0.7793,\n",
      "         0.7305, 0.6411, 0.5649]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.5020508766174316\n",
      "lr\n",
      "0.0007805775639443738\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.6543, 0.3887, 0.2852, 0.7295, 0.6650, 0.3528, 0.3887, 0.4807, 0.8008,\n",
      "         0.9316, 0.5635, 0.4307]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.8099365234375\n",
      "lr\n",
      "0.0007649891066762534\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.1611, 0.1659, 0.1603, 0.1794, 0.1578, 0.1547, 0.1907, 0.2004, 0.1676,\n",
      "         0.2559, 0.9937, 0.9902]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "3.2815427780151367\n",
      "lr\n",
      "0.0007494006494081331\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.7852, 0.9302, 0.8608, 0.6670, 0.7915, 0.7031, 0.5298, 0.9829, 0.9736,\n",
      "         0.9609, 0.9551, 0.9414]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.4710693359375\n",
      "lr\n",
      "0.0007338121921400127\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.8369, 0.8003, 0.8271, 0.7778, 0.1445, 0.1506, 0.1444, 0.1636, 0.1431,\n",
      "         0.1400, 0.1631, 0.1796]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.756591796875\n",
      "lr\n",
      "0.0007182237348718923\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.2673, 0.3293, 0.3469, 0.3638, 0.5283, 0.8418, 0.5381, 0.5718, 0.6558,\n",
      "         0.6016, 0.4458, 0.8809]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.895263671875\n",
      "lr\n",
      "0.000702635277603772\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.3513, 0.2881, 0.2903, 0.3154, 0.3416, 0.2900, 0.4111, 0.3604, 0.1376,\n",
      "         0.1344, 0.1339, 0.1376]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.3904297351837158\n",
      "lr\n",
      "0.0006870468203356516\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.5615, 0.6001, 0.7021, 0.2094, 0.1803, 0.2024, 0.2125, 0.2269, 0.2795,\n",
      "         0.4514, 0.3730, 0.3176]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.119238257408142\n",
      "lr\n",
      "0.0006714583630675312\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.3086, 0.3142, 0.3235, 0.2693, 0.4407, 0.3535, 0.3882, 0.4014, 0.5776,\n",
      "         0.5728, 0.4944, 0.3831]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2694334983825684\n",
      "lr\n",
      "0.0006558699057994109\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.7075, 0.4734, 0.4795, 0.6924, 0.8179, 0.6348, 0.9229, 0.3210, 0.2556,\n",
      "         0.3879, 0.4058, 0.4058]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.696044921875\n",
      "lr\n",
      "0.0006402814485312905\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.2485, 0.4087, 0.2773, 0.2205, 0.5010, 0.7100, 0.6074, 0.5078, 0.6714,\n",
      "         0.6733, 0.7295, 0.6333]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "3.031249761581421\n",
      "lr\n",
      "0.0006246929912631701\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.7681, 0.7251, 0.8906, 0.8330, 0.8857, 0.7935, 0.8755, 0.9604, 0.9277,\n",
      "         0.8853, 0.9829, 0.5034]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.562353491783142\n",
      "lr\n",
      "0.0006091045339950497\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.9741, 0.8813, 0.3123, 0.2212, 0.3403, 0.4734, 0.3291, 0.2537, 0.5151,\n",
      "         0.6846, 0.6099, 0.5171]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.9098143577575684\n",
      "lr\n",
      "0.0005935160767269294\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.3904, 0.7847, 0.4270, 0.3484, 0.6216, 0.5806, 0.7432, 0.6787, 0.7329,\n",
      "         0.6450, 0.6870, 0.8315]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.295678734779358\n",
      "lr\n",
      "0.000577927619458809\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.6353, 0.4275, 0.4800, 0.6709, 0.7495, 0.6436, 0.2068, 0.1606, 0.2006,\n",
      "         0.2854, 0.1841, 0.1592]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9824097752571106\n",
      "lr\n",
      "0.0005623391621906886\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.1501, 0.1272, 0.1210, 0.1421, 0.2319, 0.3521, 0.1493, 0.1355, 0.4790,\n",
      "         0.4358, 0.5571, 0.5044]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1251463890075684\n",
      "lr\n",
      "0.0005467507049225683\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.5952, 0.5703, 0.6484, 0.6108, 0.6040, 0.5161, 0.5752, 0.6743, 0.6934,\n",
      "         0.6406, 0.1956, 0.1509]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9447388052940369\n",
      "lr\n",
      "0.0005311622476544479\n",
      "pred\n",
      "tensor([[1.0000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.8862, 0.1350, 0.1176, 0.1389, 0.1608, 0.1237, 0.1267, 0.1572, 0.2639,\n",
      "         0.3728, 0.1266, 0.1193]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.650390625\n",
      "lr\n",
      "0.0005155737903863275\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.7949, 0.7632, 0.9458, 0.8652, 0.7183, 0.6992, 0.7944, 0.7500, 0.7588,\n",
      "         0.6763, 0.7617, 0.7202]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.79803466796875\n",
      "lr\n",
      "0.0004999853331182072\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.8516, 0.8525, 0.9824, 0.8823, 0.9678, 0.1360, 0.1155, 0.1615, 0.1814,\n",
      "         0.1271, 0.1538, 0.2100]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7744140625\n",
      "lr\n",
      "0.00048439687585008696\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.9204, 0.8779, 0.8584, 0.8101, 0.8486, 0.8872, 0.9751, 0.9214, 0.7974,\n",
      "         0.7803, 0.8521, 0.8101]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9502197504043579\n",
      "lr\n",
      "0.0004688084185819671\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9204, 0.9082, 0.8657, 0.8550, 0.8979, 0.9077, 0.9673, 0.9404, 0.9751,\n",
      "         0.1479, 0.1182, 0.1459]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.4958251118659973\n",
      "lr\n",
      "0.0004532199613138472\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1593, 0.1401, 0.8848, 0.8647, 0.9028, 0.8604, 0.8301, 0.8008, 0.8672,\n",
      "         0.8804, 0.9663, 0.9155]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.69647216796875\n",
      "lr\n",
      "0.0004376315040457273\n",
      "pred\n",
      "tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.1086, 0.3008, 0.8760, 0.8560, 0.8921, 0.8613, 0.8115, 0.7998, 0.8750,\n",
      "         0.8516, 0.9521, 0.9375]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9517088532447815\n",
      "lr\n",
      "0.00042204304677760743\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1036, 0.0975, 0.0854, 0.1144, 0.1307, 0.1313, 0.7920, 0.7666, 0.8364,\n",
      "         0.7476, 0.6787, 0.7241]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.057861328125\n",
      "lr\n",
      "0.00040645458950948755\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0890, 0.0848, 0.0995, 0.1038, 0.0927, 0.1448, 0.8228, 0.7979, 0.8130,\n",
      "         0.7798, 0.6582, 0.6851]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.5102050304412842\n",
      "lr\n",
      "0.00039086613224136767\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.8481, 0.8960, 0.1103, 0.0984, 0.1080, 0.1041, 0.0880, 0.1045, 0.1378,\n",
      "         0.1249, 0.7812, 0.7559]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.356201171875\n",
      "lr\n",
      "0.0003752776749732478\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0869, 0.1025, 0.0932, 0.1067, 0.0953, 0.0873, 0.0927, 0.1088, 0.0989,\n",
      "         0.1831, 0.8584, 0.8408]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7339844107627869\n",
      "lr\n",
      "0.0003596892177051279\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.6460, 0.6733, 0.7612, 0.8975, 0.8120, 0.9424, 0.1428, 0.1176, 0.1471,\n",
      "         0.1394, 0.1013, 0.1146]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.53497314453125\n",
      "lr\n",
      "0.00034410076043700803\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.6855, 0.7207, 0.6553, 0.6060, 0.0842, 0.1251, 0.1034, 0.1350, 0.1122,\n",
      "         0.0972, 0.0922, 0.1182]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8533690571784973\n",
      "lr\n",
      "0.00032851230316888815\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.8081, 0.8843, 0.8496, 0.8257, 0.7715, 0.8511, 0.8481, 0.9634, 0.8926,\n",
      "         0.9795, 0.1816, 0.1409]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.748046875\n",
      "lr\n",
      "0.00031292384590076827\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.6841, 0.6362, 0.6392, 0.5952, 0.6821, 0.7544, 0.6738, 0.6035, 0.0866,\n",
      "         0.1315, 0.1082, 0.1532]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.031469702720642\n",
      "lr\n",
      "0.0002973353886326484\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.4331, 0.1427, 0.1340, 0.8091, 0.7793, 0.8828, 0.8413, 0.8037, 0.7129,\n",
      "         0.8091, 0.8589, 0.9624]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "Saving model !!\n",
      "Min lr\n",
      "0.0002598076211353316\n",
      "Max lr\n",
      "0.0010392304845413265\n",
      "loss\n",
      "1.273535132408142\n",
      "lr\n",
      "0.0002942869792113272\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.4104, 0.4775, 0.4790, 0.4187, 0.5801, 0.5317, 0.6094, 0.5283, 0.7388,\n",
      "         0.7368, 0.6113, 0.5469]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2654297351837158\n",
      "lr\n",
      "0.0003069136295985044\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.2913, 0.4841, 0.5386, 0.3860, 0.3599, 0.1578, 0.1276, 0.7319, 0.6924,\n",
      "         0.7637, 0.7383, 0.7085]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2207764387130737\n",
      "lr\n",
      "0.00031954027998568155\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.1849, 0.2374, 0.1433, 0.2229, 0.2239, 0.2474, 0.3550, 0.3032, 0.4468,\n",
      "         0.3787, 0.4075, 0.4282]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.424462914466858\n",
      "lr\n",
      "0.00033216693037285873\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.2252, 0.2793, 0.2957, 0.2761, 0.2793, 0.4180, 0.4512, 0.3403, 0.2727,\n",
      "         0.2043, 0.1671, 0.7046]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.3622803688049316\n",
      "lr\n",
      "0.0003447935807600359\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.8594, 0.8062, 0.2063, 0.1558, 0.1699, 0.2379, 0.1473, 0.1615, 0.2812,\n",
      "         0.3608, 0.3823, 0.3218]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.296728491783142\n",
      "lr\n",
      "0.0003574202311472131\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.7217, 0.6567, 0.9116, 0.3191, 0.2561, 0.3225, 0.3542, 0.3508, 0.3772,\n",
      "         0.5601, 0.6064, 0.4202]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.6700440645217896\n",
      "lr\n",
      "0.00037004688153439026\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.8535, 0.8345, 0.9502, 0.9082, 0.9395, 0.9258, 0.2290, 0.1698, 0.2012,\n",
      "         0.3044, 0.2163, 0.2297]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1931638717651367\n",
      "lr\n",
      "0.00038267353192156743\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.7534, 0.6597, 0.6665, 0.7495, 0.7939, 0.6274, 0.9683, 0.3801, 0.3093,\n",
      "         0.3916, 0.4277, 0.4277]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2912843227386475\n",
      "lr\n",
      "0.0003953001823087446\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.7671, 0.7334, 0.8394, 0.7900, 0.8105, 0.7622, 0.8442, 0.9077, 0.8955,\n",
      "         0.8540, 0.2966, 0.2162]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.4444823265075684\n",
      "lr\n",
      "0.0004079268326959218\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.5288, 0.4907, 0.7007, 0.5874, 0.6763, 0.7212, 0.8159, 0.8228, 0.8081,\n",
      "         0.5576, 0.8154, 0.3513]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9067381620407104\n",
      "lr\n",
      "0.00042055348308309896\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.6953, 0.8384, 0.9678, 0.8306, 0.6509, 0.6323, 0.7456, 0.6577, 0.6455,\n",
      "         0.5645, 0.6079, 0.6836]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8510986566543579\n",
      "lr\n",
      "0.00043318013347027614\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.1937, 0.5112, 0.2346, 0.2004, 0.5615, 0.5332, 0.6260, 0.5259, 0.5498,\n",
      "         0.6074, 0.7109, 0.7246]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "2.3010740280151367\n",
      "lr\n",
      "0.0004458067838574533\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.5703, 0.5601, 0.5142, 0.7397, 0.8525, 0.6030, 0.6899, 0.9629, 0.6611,\n",
      "         0.6479, 0.5098, 0.5132]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1321533918380737\n",
      "lr\n",
      "0.0004584334342446305\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2903, 0.1490, 0.2539, 0.2617, 0.2563, 0.6064, 0.3894, 0.3313, 0.6230,\n",
      "         0.5977, 0.6494, 0.5830]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7427001595497131\n",
      "lr\n",
      "0.00047106008463180767\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1570, 0.2001, 0.8340, 0.7900, 0.9175, 0.8398, 0.8086, 0.7959, 0.9019,\n",
      "         0.8857, 0.9834, 0.9370]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6865723133087158\n",
      "lr\n",
      "0.00048368673501898485\n",
      "pred\n",
      "tensor([[1.0000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9810, 0.2456, 0.1882, 0.2240, 0.2781, 0.1501, 0.2124, 0.1545, 0.1190,\n",
      "         0.4202, 0.1586, 0.1422]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8261107206344604\n",
      "lr\n",
      "0.0004963133854061617\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1519, 0.1494, 0.0986, 0.1422, 0.1379, 0.1118, 0.8496, 0.8169, 0.8745,\n",
      "         0.8096, 0.7754, 0.6426]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.60546875\n",
      "lr\n",
      "0.0005089400357933384\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.8721, 0.9102, 0.9673, 0.9517, 0.9771, 0.1765, 0.1360, 0.1615, 0.2103,\n",
      "         0.1371, 0.1508, 0.1648]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.527294933795929\n",
      "lr\n",
      "0.0005215666861805151\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.9512, 0.9800, 0.1265, 0.1016, 0.1255, 0.1268, 0.0995, 0.1038, 0.1368,\n",
      "         0.1527, 0.9058, 0.8838]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7186523675918579\n",
      "lr\n",
      "0.0005341933365676918\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9487, 0.9380, 0.8945, 0.8472, 0.9380, 0.9526, 0.9849, 0.9868, 0.9917,\n",
      "         0.1492, 0.1154, 0.1344]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.877087414264679\n",
      "lr\n",
      "0.0005468199869548685\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.6401, 0.6138, 0.9038, 0.9580, 0.7432, 0.9746, 0.1069, 0.0893, 0.1021,\n",
      "         0.1028, 0.0857, 0.1009]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.077392578125\n",
      "lr\n",
      "0.0005594466373420451\n",
      "pred\n",
      "tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0725, 0.1323, 0.9287, 0.9097, 0.9312, 0.9141, 0.8521, 0.8242, 0.9023,\n",
      "         0.9238, 0.9785, 0.9629]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.68804931640625\n",
      "lr\n",
      "0.0005720732877292218\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.7622, 0.7920, 0.7988, 0.7729, 0.7500, 0.8389, 0.9150, 0.8877, 0.9204,\n",
      "         0.9800, 0.1155, 0.0935]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.25506591796875\n",
      "lr\n",
      "0.0005846999381163985\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0842, 0.0724, 0.0847, 0.0801, 0.0720, 0.1943, 0.9238, 0.8833, 0.9614,\n",
      "         0.9316, 0.8599, 0.7725]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9953857660293579\n",
      "lr\n",
      "0.0005973265885035752\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3274, 0.3213, 0.2328, 0.7163, 0.6772, 0.8438, 0.7700, 0.7368, 0.7354,\n",
      "         0.8491, 0.7456, 0.9653]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.23651123046875\n",
      "lr\n",
      "0.0006099532388907519\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0684, 0.1160, 0.0916, 0.1188, 0.0974, 0.0772, 0.0824, 0.1000, 0.0799,\n",
      "         0.2340, 0.9243, 0.9048]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1824463605880737\n",
      "lr\n",
      "0.0006225798892779286\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.4907, 0.6118, 0.5132, 0.4614, 0.5449, 0.2976, 0.2384, 0.7949, 0.7612,\n",
      "         0.7271, 0.7095, 0.7109]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.13482666015625\n",
      "lr\n",
      "0.0006352065396651053\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.6353, 0.6245, 0.5859, 0.4797, 0.0666, 0.1210, 0.0935, 0.1268, 0.1021,\n",
      "         0.0806, 0.0785, 0.0997]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.6927733421325684\n",
      "lr\n",
      "0.000647833190052282\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3521, 0.2515, 0.2871, 0.2751, 0.3804, 0.5874, 0.2888, 0.1648, 0.5317,\n",
      "         0.1843, 0.1460, 0.6963]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.85400390625\n",
      "lr\n",
      "0.0006604598404394587\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.4832, 0.4431, 0.4651, 0.4448, 0.5537, 0.6890, 0.4771, 0.4287, 0.0652,\n",
      "         0.1000, 0.0821, 0.1060]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.090087890625\n",
      "lr\n",
      "0.0006730864908266353\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.7275, 0.6802, 0.9849, 0.4067, 0.3506, 0.3916, 0.4160, 0.4233, 0.3831,\n",
      "         0.5356, 0.6006, 0.4404]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.374121069908142\n",
      "lr\n",
      "0.000685713141213812\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.3743, 0.5059, 0.5127, 0.4514, 0.5771, 0.5483, 0.6548, 0.5723, 0.7368,\n",
      "         0.8691, 0.5205, 0.5537]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.6858885288238525\n",
      "lr\n",
      "0.0006983397916009887\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.8379, 0.6099, 0.8154, 0.8994, 0.8818, 0.5708, 0.9526, 0.3403, 0.2898,\n",
      "         0.3875, 0.4109, 0.4663]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9554932117462158\n",
      "lr\n",
      "0.0007109664419881654\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.2109, 0.2952, 0.2466, 0.1654, 0.2629, 0.4504, 0.4207, 0.3728, 0.4617,\n",
      "         0.4412, 0.5723, 0.3899]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2850587368011475\n",
      "lr\n",
      "0.0007235930923753421\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.4602, 0.4307, 0.5391, 0.4536, 0.5625, 0.4666, 0.5527, 0.4648, 0.6104,\n",
      "         0.5439, 0.8809, 0.3320]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.0267335176467896\n",
      "lr\n",
      "0.0007362197427625188\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.9067, 0.7974, 0.2778, 0.2137, 0.2264, 0.2930, 0.2140, 0.2401, 0.2766,\n",
      "         0.1488, 0.4126, 0.3743]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8986449241638184\n",
      "lr\n",
      "0.0007488463931496955\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2230, 0.4343, 0.1359, 0.1174, 0.6206, 0.5850, 0.6592, 0.5732, 0.6587,\n",
      "         0.6348, 0.7007, 0.7788]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.410888671875\n",
      "lr\n",
      "0.0007614730435368722\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.8213, 0.7866, 0.8682, 0.9287, 0.9199, 0.8857, 0.4299, 0.3394, 0.3474,\n",
      "         0.4255, 0.3005, 0.3577]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7690674066543579\n",
      "lr\n",
      "0.0007740996939240489\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2588, 0.1597, 0.2124, 0.2808, 0.3257, 0.4614, 0.1664, 0.1377, 0.6304,\n",
      "         0.5981, 0.6216, 0.5601]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1416503190994263\n",
      "lr\n",
      "0.0007867263443112255\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.6377, 0.6138, 0.5386, 0.5479, 0.5791, 0.5972, 0.7534, 0.6812, 0.5566,\n",
      "         0.8647, 0.3445, 0.2690]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6105713248252869\n",
      "lr\n",
      "0.0007993529946984022\n",
      "pred\n",
      "tensor([[1.0000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9595, 0.1763, 0.1248, 0.1437, 0.1989, 0.1340, 0.1464, 0.1941, 0.2268,\n",
      "         0.2289, 0.0877, 0.0799]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7525390386581421\n",
      "lr\n",
      "0.0008119796450855789\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.7910, 0.8975, 0.9663, 0.9053, 0.6133, 0.5830, 0.7163, 0.6387, 0.6807,\n",
      "         0.5894, 0.7173, 0.8408]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.54034423828125\n",
      "lr\n",
      "0.0008246062954727556\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.8779, 0.9497, 0.9888, 0.9341, 0.9849, 0.1780, 0.1207, 0.1534, 0.2158,\n",
      "         0.1548, 0.1454, 0.1879]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7541017532348633\n",
      "lr\n",
      "0.0008372329458599323\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.9629, 0.9253, 0.9175, 0.8262, 0.9131, 0.9731, 0.9941, 0.9688, 0.7515,\n",
      "         0.7144, 0.8608, 0.7988]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1142210960388184\n",
      "lr\n",
      "0.000849859596247109\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9077, 0.9048, 0.8604, 0.7729, 0.8481, 0.9136, 0.9551, 0.9399, 0.9829,\n",
      "         0.1587, 0.1089, 0.1327]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9164304733276367\n",
      "lr\n",
      "0.0008624862466342857\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1182, 0.0824, 0.8311, 0.7939, 0.8975, 0.8311, 0.8003, 0.6631, 0.7568,\n",
      "         0.8818, 0.9741, 0.8379]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.79791259765625\n",
      "lr\n",
      "0.0008751128970214624\n",
      "pred\n",
      "tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0632, 0.0814, 0.8809, 0.8574, 0.8813, 0.8682, 0.7808, 0.6509, 0.7476,\n",
      "         0.8477, 0.9448, 0.8872]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.5083494782447815\n",
      "lr\n",
      "0.000887739547408639\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1034, 0.1021, 0.0806, 0.0850, 0.1440, 0.1459, 0.8809, 0.8618, 0.8862,\n",
      "         0.8535, 0.8052, 0.7339]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2940673828125\n",
      "lr\n",
      "0.0009003661977958157\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0660, 0.0592, 0.0646, 0.1076, 0.0731, 0.2742, 0.9385, 0.9258, 0.9097,\n",
      "         0.9038, 0.8564, 0.8164]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.4713134169578552\n",
      "lr\n",
      "0.0009129928481829924\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.9209, 0.9624, 0.1241, 0.0863, 0.1067, 0.1045, 0.0734, 0.0997, 0.1569,\n",
      "         0.1136, 0.8877, 0.8706]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.976715087890625\n",
      "lr\n",
      "0.0009256194985701691\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0509, 0.0748, 0.0610, 0.0726, 0.0610, 0.0509, 0.0651, 0.0898, 0.0532,\n",
      "         0.2100, 0.9160, 0.8965]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6270018815994263\n",
      "lr\n",
      "0.0009382461489573458\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.6587, 0.8013, 0.8242, 0.9360, 0.8872, 0.9517, 0.1101, 0.0799, 0.0964,\n",
      "         0.0923, 0.0627, 0.0935]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.873077392578125\n",
      "lr\n",
      "0.0009508727993445225\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.6548, 0.5908, 0.5376, 0.4692, 0.0473, 0.0765, 0.0600, 0.0739, 0.0613,\n",
      "         0.0504, 0.0615, 0.1282]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.848437488079071\n",
      "lr\n",
      "0.0009634994497316992\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.7827, 0.8091, 0.7905, 0.7114, 0.7383, 0.8506, 0.8647, 0.9390, 0.9707,\n",
      "         0.9849, 0.1517, 0.1007]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.849822998046875\n",
      "lr\n",
      "0.0009761261001188759\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.5581, 0.5195, 0.5264, 0.5396, 0.7095, 0.5605, 0.5449, 0.5923, 0.0471,\n",
      "         0.0919, 0.0663, 0.0937]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.5343750715255737\n",
      "lr\n",
      "0.0009887527505060534\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.5259, 0.2013, 0.1327, 0.6943, 0.6406, 0.6895, 0.6499, 0.7026, 0.6313,\n",
      "         0.8931, 0.8066, 0.8511]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8353027105331421\n",
      "lr\n",
      "0.001001379400893231\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.3025, 0.3875, 0.4636, 0.4231, 0.4531, 0.4351, 0.4512, 0.3767, 0.5156,\n",
      "         0.7236, 0.4087, 0.4824]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9858886003494263\n",
      "lr\n",
      "0.0010140060512804088\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3303, 0.5317, 0.6016, 0.4482, 0.4568, 0.3831, 0.3232, 0.8398, 0.7856,\n",
      "         0.9102, 0.9072, 0.9126]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.5674072504043579\n",
      "lr\n",
      "0.0010266327016675864\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.2747, 0.3542, 0.2681, 0.2238, 0.2869, 0.4111, 0.4695, 0.4297, 0.4966,\n",
      "         0.4583, 0.4797, 0.4109]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.5895508527755737\n",
      "lr\n",
      "0.001039259352054764\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3606, 0.3730, 0.3750, 0.3459, 0.3701, 0.4241, 0.4873, 0.4194, 0.3674,\n",
      "         0.3154, 0.2510, 0.7827]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8332763910293579\n",
      "lr\n",
      "0.0010266327016675864\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.5552, 0.9287, 0.3525, 0.2815, 0.2153, 0.3147, 0.2157, 0.2847, 0.4001,\n",
      "         0.2947, 0.4736, 0.4421]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1346678733825684\n",
      "lr\n",
      "0.0010140060512804088\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.8438, 0.5576, 0.7739, 0.4390, 0.3850, 0.4629, 0.4546, 0.4175, 0.4407,\n",
      "         0.5303, 0.5400, 0.5747]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2890625\n",
      "lr\n",
      "0.001001379400893231\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.7837, 0.7334, 0.8237, 0.8965, 0.9556, 0.8091, 0.4314, 0.3469, 0.3511,\n",
      "         0.4463, 0.3250, 0.3865]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2990721464157104\n",
      "lr\n",
      "0.0009887527505060534\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.5991, 0.6694, 0.7729, 0.8223, 0.7246, 0.6655, 0.8730, 0.5093, 0.4592,\n",
      "         0.4736, 0.4810, 0.4473]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7404296398162842\n",
      "lr\n",
      "0.0009761261001188759\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.6470, 0.6201, 0.6416, 0.5869, 0.5479, 0.6113, 0.7080, 0.6670, 0.7104,\n",
      "         0.7437, 0.3528, 0.2527]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.0313966274261475\n",
      "lr\n",
      "0.0009634994497316992\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.5161, 0.4897, 0.5449, 0.4644, 0.4888, 0.5029, 0.5405, 0.5020, 0.6055,\n",
      "         0.5054, 0.7686, 0.3879]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8640624284744263\n",
      "lr\n",
      "0.0009508727993445225\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.8418, 0.8477, 0.9966, 0.8740, 0.5835, 0.5566, 0.8198, 0.6880, 0.6948,\n",
      "         0.6001, 0.7534, 0.7808]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.5426511764526367\n",
      "lr\n",
      "0.0009382461489573458\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.4761, 0.4375, 0.1097, 0.0877, 0.6348, 0.6074, 0.6011, 0.6147, 0.7178,\n",
      "         0.7217, 0.8848, 0.8442]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9401369094848633\n",
      "lr\n",
      "0.0009256194985701691\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.9912, 0.9683, 0.9565, 0.7876, 0.9077, 0.9771, 0.9995, 0.9004, 0.7310,\n",
      "         0.7085, 0.9248, 0.8628]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.835693359375\n",
      "lr\n",
      "0.0009129928481829924\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2493, 0.2220, 0.1497, 0.1752, 0.3535, 0.3643, 0.0871, 0.0718, 0.5981,\n",
      "         0.5684, 0.6743, 0.6226]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6581054329872131\n",
      "lr\n",
      "0.0009003661977958157\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1594, 0.2444, 0.8618, 0.8403, 0.8940, 0.8682, 0.8652, 0.8511, 0.9595,\n",
      "         0.9355, 0.9512, 0.9888]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.0287597179412842\n",
      "lr\n",
      "0.000887739547408639\n",
      "pred\n",
      "tensor([[1.0000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9678, 0.1531, 0.1016, 0.1132, 0.1705, 0.1078, 0.1375, 0.0790, 0.0914,\n",
      "         0.2998, 0.0804, 0.0689]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1894407272338867\n",
      "lr\n",
      "0.0008751128970214624\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1036, 0.1039, 0.0571, 0.0895, 0.1337, 0.1259, 0.7666, 0.7349, 0.7998,\n",
      "         0.7319, 0.6255, 0.6724]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.797106921672821\n",
      "lr\n",
      "0.0008624862466342857\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9004, 0.8037, 0.9009, 0.9629, 0.9458, 0.2568, 0.1865, 0.1910, 0.2549,\n",
      "         0.1076, 0.1873, 0.2715]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.0240111351013184\n",
      "lr\n",
      "0.000849859596247109\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.9429, 0.9663, 0.2444, 0.1599, 0.2034, 0.1991, 0.0685, 0.1499, 0.2039,\n",
      "         0.1704, 0.8848, 0.8628]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6795409917831421\n",
      "lr\n",
      "0.0008372329458599323\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9741, 0.9673, 0.9185, 0.8843, 0.9380, 0.9648, 0.9946, 0.9644, 0.9927,\n",
      "         0.3406, 0.2561, 0.2815]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1807982921600342\n",
      "lr\n",
      "0.0008246062954727556\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.8545, 0.9009, 0.9419, 0.9590, 0.9175, 0.9854, 0.2283, 0.1479, 0.1940,\n",
      "         0.1815, 0.0629, 0.1329]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.386138916015625\n",
      "lr\n",
      "0.0008119796450855789\n",
      "pred\n",
      "tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0485, 0.1960, 0.9092, 0.8726, 0.9595, 0.9341, 0.8481, 0.7578, 0.8467,\n",
      "         0.8433, 0.9927, 0.8945]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.3313477039337158\n",
      "lr\n",
      "0.0007993529946984022\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.5781, 0.8276, 0.7500, 0.6587, 0.5430, 0.6357, 0.7524, 0.9497, 0.6812,\n",
      "         0.9199, 0.1150, 0.0818]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.439239501953125\n",
      "lr\n",
      "0.0007867263443112255\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0583, 0.0460, 0.0605, 0.0725, 0.0449, 0.0993, 0.8667, 0.8369, 0.8945,\n",
      "         0.8667, 0.7612, 0.7163]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7269042730331421\n",
      "lr\n",
      "0.0007740996939240489\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3413, 0.3027, 0.2708, 0.7441, 0.6973, 0.8418, 0.8179, 0.7783, 0.7656,\n",
      "         0.8174, 0.8154, 0.9346]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.78839111328125\n",
      "lr\n",
      "0.0007614730435368722\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0417, 0.0712, 0.0547, 0.0782, 0.0589, 0.0496, 0.0525, 0.0689, 0.0526,\n",
      "         0.1238, 0.9438, 0.9199]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.4218261241912842\n",
      "lr\n",
      "0.0007488463931496955\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.4834, 0.7295, 0.7314, 0.4460, 0.5044, 0.3242, 0.2295, 0.8345, 0.8037,\n",
      "         0.8853, 0.8828, 0.8745]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.011871337890625\n",
      "lr\n",
      "0.0007362197427625188\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.7427, 0.6465, 0.5688, 0.5210, 0.0443, 0.0790, 0.0592, 0.0863, 0.0666,\n",
      "         0.0576, 0.0602, 0.0797]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2218139171600342\n",
      "lr\n",
      "0.0007235930923753421\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3684, 0.4077, 0.4368, 0.4385, 0.4038, 0.6230, 0.6504, 0.4216, 0.4827,\n",
      "         0.1801, 0.1227, 0.7715]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.577728271484375\n",
      "lr\n",
      "0.0007109664419881654\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.5200, 0.4751, 0.4746, 0.5083, 0.5898, 0.4893, 0.5342, 0.4438, 0.0500,\n",
      "         0.0906, 0.0670, 0.1007]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.5352050065994263\n",
      "lr\n",
      "0.0006983397916009887\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.6108, 0.5322, 0.7295, 0.4026, 0.3616, 0.4028, 0.4111, 0.3865, 0.3354,\n",
      "         0.4719, 0.4836, 0.4385]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7364257574081421\n",
      "lr\n",
      "0.000685713141213812\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.3735, 0.4575, 0.4626, 0.4270, 0.4641, 0.4504, 0.4558, 0.4412, 0.6172,\n",
      "         0.5195, 0.4751, 0.5449]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.727294921875\n",
      "lr\n",
      "0.0006730864908266353\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.5947, 0.5718, 0.7065, 0.7573, 0.5391, 0.6519, 0.8428, 0.4216, 0.3811,\n",
      "         0.4006, 0.4275, 0.3943]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8439697027206421\n",
      "lr\n",
      "0.0006604598404394587\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.3076, 0.3809, 0.2700, 0.2042, 0.4314, 0.4988, 0.5078, 0.4597, 0.6006,\n",
      "         0.5239, 0.5581, 0.5688]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2359373569488525\n",
      "lr\n",
      "0.000647833190052282\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.5024, 0.4700, 0.7402, 0.6084, 0.6694, 0.6084, 0.7349, 0.7661, 0.8423,\n",
      "         0.5781, 0.7930, 0.3762]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.133081078529358\n",
      "lr\n",
      "0.0006352065396651053\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.8843, 0.9199, 0.3330, 0.2588, 0.2629, 0.3394, 0.2330, 0.1855, 0.4180,\n",
      "         0.4888, 0.4792, 0.4307]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8885254859924316\n",
      "lr\n",
      "0.0006225798892779286\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2018, 0.5103, 0.2520, 0.2140, 0.5293, 0.4932, 0.6138, 0.5044, 0.5298,\n",
      "         0.5991, 0.6943, 0.6582]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.0493897199630737\n",
      "lr\n",
      "0.0006099532388907519\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.6855, 0.5996, 0.8633, 0.7969, 0.7485, 0.9453, 0.2847, 0.2101, 0.2039,\n",
      "         0.3079, 0.2588, 0.1699]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.0606201887130737\n",
      "lr\n",
      "0.0005973265885035752\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2024, 0.1199, 0.1180, 0.1455, 0.2290, 0.5767, 0.2974, 0.2615, 0.5347,\n",
      "         0.4958, 0.6050, 0.4973]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9116699695587158\n",
      "lr\n",
      "0.0005846999381163985\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.7285, 0.6880, 0.7988, 0.7041, 0.6460, 0.6587, 0.7920, 0.8579, 0.8955,\n",
      "         0.8521, 0.3357, 0.2603]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.976147472858429\n",
      "lr\n",
      "0.0005720732877292218\n",
      "pred\n",
      "tensor([[1.0000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9951, 0.1968, 0.1307, 0.1727, 0.2278, 0.1342, 0.1288, 0.2233, 0.2861,\n",
      "         0.6089, 0.3184, 0.2700]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7756836414337158\n",
      "lr\n",
      "0.0005594466373420451\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.8296, 0.9336, 0.9985, 0.9238, 0.6436, 0.6162, 0.8472, 0.7173, 0.6870,\n",
      "         0.6035, 0.7388, 0.7964]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.559374988079071\n",
      "lr\n",
      "0.0005468199869548685\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9038, 0.8481, 0.9604, 0.9824, 0.9893, 0.2084, 0.1376, 0.1632, 0.2222,\n",
      "         0.1510, 0.1525, 0.2172]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.55419921875\n",
      "lr\n",
      "0.0005341933365676918\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.9365, 0.8882, 0.8325, 0.7827, 0.8789, 0.9419, 0.9888, 0.9458, 0.7153,\n",
      "         0.6821, 0.7754, 0.6851]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9050537347793579\n",
      "lr\n",
      "0.0005215666861805151\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9619, 0.9385, 0.8271, 0.7998, 0.8716, 0.8794, 0.9946, 0.9561, 0.9922,\n",
      "         0.1981, 0.1251, 0.1505]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "5.100530624389648\n",
      "lr\n",
      "0.0005089400357933384\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.2781, 0.0378, 0.8018, 0.7217, 0.0377, 0.0378, 0.0378, 0.7617, 0.9404,\n",
      "         0.0378, 0.0402, 0.9961]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.777587890625\n",
      "lr\n",
      "0.0004963133854061617\n",
      "pred\n",
      "tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0988, 0.1759, 0.9111, 0.8594, 0.7734, 0.7822, 0.7681, 0.7900, 0.9263,\n",
      "         0.8374, 0.8569, 0.9922]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.5115599632263184\n",
      "lr\n",
      "0.0004836867350189848\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1082, 0.0962, 0.0885, 0.0967, 0.1923, 0.2123, 0.9004, 0.8804, 0.8535,\n",
      "         0.8525, 0.8550, 0.7788]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.293792724609375\n",
      "lr\n",
      "0.0004710600846318076\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0523, 0.0577, 0.0579, 0.1017, 0.0612, 0.4580, 0.9424, 0.9229, 0.9590,\n",
      "         0.9521, 0.9185, 0.8003]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9150756597518921\n",
      "lr\n",
      "0.00045843343424463044\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.9736, 0.9707, 0.1249, 0.0771, 0.0922, 0.0986, 0.0942, 0.0937, 0.2407,\n",
      "         0.3210, 0.8560, 0.8042]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.850860595703125\n",
      "lr\n",
      "0.00044580678385745326\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0368, 0.0565, 0.0446, 0.0729, 0.0506, 0.0541, 0.0453, 0.0643, 0.0608,\n",
      "         0.1913, 0.9414, 0.8848]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7672485113143921\n",
      "lr\n",
      "0.0004331801334702761\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.6865, 0.8594, 0.7769, 0.6226, 0.9492, 0.9697, 0.1186, 0.0737, 0.0975,\n",
      "         0.0989, 0.0923, 0.0812]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8328857421875\n",
      "lr\n",
      "0.0004205534830830989\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.5137, 0.6543, 0.6162, 0.4214, 0.0376, 0.0619, 0.0470, 0.0699, 0.0550,\n",
      "         0.0667, 0.0447, 0.0873]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8498046398162842\n",
      "lr\n",
      "0.00040792683269592173\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.7793, 0.7808, 0.8350, 0.8608, 0.6880, 0.8130, 0.9561, 0.8774, 0.9360,\n",
      "         0.9736, 0.1205, 0.0746]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.21844482421875\n",
      "lr\n",
      "0.00039530018230874456\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.5503, 0.5298, 0.6885, 0.4729, 0.7056, 0.8818, 0.5312, 0.5928, 0.0349,\n",
      "         0.0637, 0.0465, 0.0662]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.3207764625549316\n",
      "lr\n",
      "0.0003826735319215674\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3789, 0.2664, 0.1962, 0.7935, 0.7554, 0.9214, 0.8999, 0.9009, 0.5850,\n",
      "         0.7803, 0.9688, 0.9854]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.3609374761581421\n",
      "lr\n",
      "0.0003700468815343902\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.3635, 0.3079, 0.5029, 0.4565, 0.5098, 0.4597, 0.4924, 0.4778, 0.5767,\n",
      "         0.4885, 0.5410, 0.5342]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.46391597390174866\n",
      "lr\n",
      "0.000357420231147213\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3799, 0.4333, 0.4316, 0.4519, 0.4243, 0.3494, 0.2681, 0.8105, 0.7710,\n",
      "         0.8267, 0.8350, 0.8188]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6694091558456421\n",
      "lr\n",
      "0.00034479358076003585\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.2773, 0.3381, 0.2360, 0.3694, 0.4077, 0.4463, 0.4976, 0.4573, 0.5142,\n",
      "         0.4456, 0.4512, 0.5586]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8272950053215027\n",
      "lr\n",
      "0.0003321669303728587\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3787, 0.4121, 0.3882, 0.3621, 0.3733, 0.3792, 0.2375, 0.5122, 0.3323,\n",
      "         0.2869, 0.2168, 0.7422]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7306396961212158\n",
      "lr\n",
      "0.0003195402799856815\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.8779, 0.6309, 0.3694, 0.2915, 0.2903, 0.3408, 0.2114, 0.2646, 0.2356,\n",
      "         0.1744, 0.5137, 0.4724]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.035498023033142\n",
      "lr\n",
      "0.0003069136295985043\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.7935, 0.5894, 0.9331, 0.4531, 0.4055, 0.4377, 0.4133, 0.3647, 0.4409,\n",
      "         0.4778, 0.3118, 0.5464]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.10888671875\n",
      "lr\n",
      "0.00029428697921132714\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.6533, 0.7729, 0.9062, 0.8306, 0.8613, 0.9272, 0.4111, 0.3276, 0.3137,\n",
      "         0.3782, 0.2817, 0.3149]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2004393339157104\n",
      "lr\n",
      "0.00028166032882414997\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.6406, 0.7251, 0.7554, 0.5859, 0.7725, 0.6587, 0.9561, 0.4995, 0.4480,\n",
      "         0.4604, 0.4453, 0.4248]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.4424805641174316\n",
      "lr\n",
      "0.0002690336784369728\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.7812, 0.7573, 0.7930, 0.7114, 0.7593, 0.8296, 0.9448, 0.8965, 0.8940,\n",
      "         0.9395, 0.4099, 0.3259]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "Saving model !!\n",
      "Min lr\n",
      "0.00023382685902179846\n",
      "Max lr\n",
      "0.0009353074360871938\n",
      "loss\n",
      "1.2394042015075684\n",
      "lr\n",
      "0.00026148574742774914\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.6235, 0.5850, 0.5562, 0.5278, 0.6343, 0.7354, 0.8828, 0.7852, 0.6045,\n",
      "         0.7632, 0.8140, 0.4656]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6390626430511475\n",
      "lr\n",
      "0.0002717133342413628\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.9038, 0.9692, 0.9829, 0.9580, 0.7168, 0.6836, 0.7383, 0.6729, 0.7114,\n",
      "         0.7207, 0.8159, 0.8784]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2021362781524658\n",
      "lr\n",
      "0.0002819409210549765\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2028, 0.4087, 0.1542, 0.1168, 0.5273, 0.5034, 0.5503, 0.4683, 0.5820,\n",
      "         0.6401, 0.8481, 0.8047]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.83154296875\n",
      "lr\n",
      "0.00029216850786859016\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.9189, 0.8652, 0.8535, 0.8086, 0.9683, 0.9292, 0.9805, 0.9946, 0.5581,\n",
      "         0.5386, 0.6973, 0.6387]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1151611804962158\n",
      "lr\n",
      "0.00030239609468220383\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.1923, 0.1801, 0.1144, 0.1197, 0.2467, 0.3716, 0.1065, 0.0850, 0.4932,\n",
      "         0.4680, 0.4985, 0.4456]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9589477181434631\n",
      "lr\n",
      "0.0003126236814958175\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1061, 0.2123, 0.7881, 0.7510, 0.8516, 0.7832, 0.7974, 0.7646, 0.9233,\n",
      "         0.9170, 0.9570, 0.9790]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7597900629043579\n",
      "lr\n",
      "0.0003228512683094312\n",
      "pred\n",
      "tensor([[1.0000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9604, 0.1807, 0.1124, 0.1490, 0.2106, 0.2069, 0.1190, 0.1276, 0.2610,\n",
      "         0.3574, 0.1295, 0.0974]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6012938618659973\n",
      "lr\n",
      "0.00033307885512304485\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1099, 0.1124, 0.1126, 0.0644, 0.0898, 0.1660, 0.8330, 0.7949, 0.9077,\n",
      "         0.8501, 0.8232, 0.7520]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.4401367902755737\n",
      "lr\n",
      "0.00034330644193665853\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9492, 0.4460, 0.4963, 0.9927, 0.9736, 0.2233, 0.1470, 0.1492, 0.2366,\n",
      "         0.2184, 0.1611, 0.2771]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.0351684093475342\n",
      "lr\n",
      "0.0003535340287502722\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.9756, 0.9668, 0.1616, 0.0967, 0.1322, 0.1451, 0.1320, 0.0927, 0.2399,\n",
      "         0.3291, 0.8501, 0.8076]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.637890636920929\n",
      "lr\n",
      "0.0003637616155638859\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9746, 0.9692, 0.9316, 0.8354, 0.8735, 0.9624, 0.9941, 0.9351, 0.9893,\n",
      "         0.2649, 0.1730, 0.2113]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9934203624725342\n",
      "lr\n",
      "0.00037398920237749955\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.8394, 0.9170, 0.9663, 0.9370, 0.9326, 0.9858, 0.1899, 0.1095, 0.1520,\n",
      "         0.1476, 0.0995, 0.1158]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.068145751953125\n",
      "lr\n",
      "0.0003842167891911132\n",
      "pred\n",
      "tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0457, 0.4360, 0.9551, 0.9390, 0.9810, 0.9766, 0.9414, 0.8164, 0.8799,\n",
      "         0.9795, 0.9961, 0.9487]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.224218726158142\n",
      "lr\n",
      "0.0003944443760047269\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.7388, 0.8989, 0.8721, 0.8379, 0.5532, 0.6338, 0.8472, 0.9731, 0.7285,\n",
      "         0.9863, 0.1493, 0.0863]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.096160888671875\n",
      "lr\n",
      "0.0004046719628183406\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0467, 0.0349, 0.0478, 0.0594, 0.0391, 0.1270, 0.9121, 0.8926, 0.9575,\n",
      "         0.9351, 0.8296, 0.7319]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9209961891174316\n",
      "lr\n",
      "0.00041489954963195425\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.4651, 0.3259, 0.2729, 0.7314, 0.6919, 0.7954, 0.7939, 0.7666, 0.5923,\n",
      "         0.7441, 0.8706, 0.8999]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7586669921875\n",
      "lr\n",
      "0.0004251271364455679\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0333, 0.0610, 0.0438, 0.0594, 0.0434, 0.0333, 0.0480, 0.0578, 0.0343,\n",
      "         0.1198, 0.9043, 0.8711]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.3239257335662842\n",
      "lr\n",
      "0.0004353547232591816\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3560, 0.3228, 0.2418, 0.5181, 0.3169, 0.2114, 0.1688, 0.7002, 0.6494,\n",
      "         0.8809, 0.8193, 0.7271]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8023681640625\n",
      "lr\n",
      "0.00044558231007279527\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.5454, 0.6782, 0.5986, 0.4773, 0.0346, 0.0716, 0.0488, 0.0654, 0.0479,\n",
      "         0.0330, 0.0552, 0.1009]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.122534155845642\n",
      "lr\n",
      "0.00045580989688640894\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.4424, 0.4580, 0.4565, 0.4001, 0.4651, 0.5820, 0.5054, 0.5132, 0.4929,\n",
      "         0.2739, 0.1698, 0.8506]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.25091552734375\n",
      "lr\n",
      "0.0004660374837000226\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.5537, 0.5288, 0.4944, 0.6475, 0.8125, 0.7354, 0.5586, 0.6641, 0.0333,\n",
      "         0.0844, 0.0537, 0.0734]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.7520995140075684\n",
      "lr\n",
      "0.0004762650705136363\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.7285, 0.7461, 0.9150, 0.5054, 0.4529, 0.4612, 0.4758, 0.4380, 0.5078,\n",
      "         0.7407, 0.6655, 0.5151]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.339208960533142\n",
      "lr\n",
      "0.00048649265732724997\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.5303, 0.4441, 0.5420, 0.5020, 0.4739, 0.4714, 0.4895, 0.6245, 0.8550,\n",
      "         0.6157, 0.3943, 0.6548]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1156249046325684\n",
      "lr\n",
      "0.0004967202441408636\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.6338, 0.7593, 0.8838, 0.7344, 0.5693, 0.7007, 0.8647, 0.4429, 0.3945,\n",
      "         0.3962, 0.4265, 0.4297]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.68701171875\n",
      "lr\n",
      "0.0005069478309544773\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.2463, 0.3196, 0.1863, 0.2261, 0.3762, 0.3840, 0.4836, 0.4375, 0.4731,\n",
      "         0.4502, 0.4312, 0.5415]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8210937976837158\n",
      "lr\n",
      "0.000517175417768091\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.5327, 0.5015, 0.5869, 0.5293, 0.5801, 0.6328, 0.7681, 0.7319, 0.5913,\n",
      "         0.5708, 0.7725, 0.3916]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6444824934005737\n",
      "lr\n",
      "0.0005274030045817047\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.7715, 0.6890, 0.2998, 0.2205, 0.2372, 0.3210, 0.1924, 0.1617, 0.2861,\n",
      "         0.2986, 0.4539, 0.4089]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.90850830078125\n",
      "lr\n",
      "0.0005376305913953183\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2273, 0.3530, 0.1072, 0.0836, 0.5498, 0.5127, 0.6396, 0.5752, 0.6260,\n",
      "         0.5396, 0.6797, 0.7510]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.0233887434005737\n",
      "lr\n",
      "0.000547858178208932\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.7583, 0.6860, 0.8242, 0.8535, 0.8301, 0.8242, 0.3298, 0.2456, 0.2664,\n",
      "         0.3679, 0.2303, 0.1364]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.867919921875\n",
      "lr\n",
      "0.0005580857650225457\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2386, 0.1743, 0.0944, 0.1942, 0.3098, 0.4749, 0.2510, 0.1940, 0.5684,\n",
      "         0.5332, 0.7090, 0.6431]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9770020246505737\n",
      "lr\n",
      "0.0005683133518361594\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.7129, 0.6846, 0.8325, 0.7822, 0.7622, 0.6943, 0.8184, 0.8613, 0.8984,\n",
      "         0.8076, 0.3411, 0.2607]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8995239734649658\n",
      "lr\n",
      "0.000578540938649773\n",
      "pred\n",
      "tensor([[1.0000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9683, 0.1893, 0.1207, 0.1586, 0.2289, 0.1432, 0.0928, 0.1406, 0.2771,\n",
      "         0.5161, 0.2715, 0.2195]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6161131858825684\n",
      "lr\n",
      "0.0005887685254633867\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.8652, 0.8232, 0.8999, 0.9575, 0.6533, 0.6211, 0.6787, 0.6733, 0.6772,\n",
      "         0.6265, 0.7998, 0.7773]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.785888671875\n",
      "lr\n",
      "0.0005989961122770004\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.8677, 0.7808, 0.9780, 0.9146, 0.9648, 0.1812, 0.1184, 0.1632, 0.2124,\n",
      "         0.1356, 0.1512, 0.1710]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6960936784744263\n",
      "lr\n",
      "0.0006092236990906141\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.8867, 0.8486, 0.7793, 0.7524, 0.9238, 0.8320, 0.9575, 0.9731, 0.6719,\n",
      "         0.6421, 0.7476, 0.6929]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2177977561950684\n",
      "lr\n",
      "0.0006194512859042277\n",
      "pred\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.8838, 0.8770, 0.7529, 0.8115, 0.8838, 0.7939, 0.9526, 0.9565, 0.9775,\n",
      "         0.1998, 0.1310, 0.1617]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.5647948384284973\n",
      "lr\n",
      "0.0006296788727178414\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1411, 0.1438, 0.9121, 0.8955, 0.8926, 0.8506, 0.7617, 0.7856, 0.8735,\n",
      "         0.8818, 0.9673, 0.9419]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.1226806640625\n",
      "lr\n",
      "0.0006399064595314551\n",
      "pred\n",
      "tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0513, 0.1359, 0.9512, 0.9360, 0.9580, 0.9414, 0.8281, 0.7461, 0.8540,\n",
      "         0.9023, 0.9922, 0.9551]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6698974370956421\n",
      "lr\n",
      "0.0006501340463450688\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1506, 0.1120, 0.0604, 0.1142, 0.1846, 0.1879, 0.8755, 0.8228, 0.9702,\n",
      "         0.9097, 0.8257, 0.7749]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.883941650390625\n",
      "lr\n",
      "0.0006603616331586824\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0524, 0.0403, 0.0571, 0.0935, 0.0384, 0.1443, 0.9668, 0.9497, 0.9663,\n",
      "         0.9497, 0.8579, 0.8516]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.57916259765625\n",
      "lr\n",
      "0.0006705892199722961\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.9351, 0.9888, 0.1375, 0.0869, 0.1379, 0.1130, 0.0763, 0.1049, 0.1670,\n",
      "         0.1300, 0.9160, 0.8877]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.81890869140625\n",
      "lr\n",
      "0.0006808168067859098\n",
      "pred\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.0330, 0.0743, 0.0492, 0.0823, 0.0519, 0.0439, 0.0589, 0.1082, 0.0500,\n",
      "         0.1538, 0.9565, 0.9302]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.694445788860321\n",
      "lr\n",
      "0.0006910443935995234\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.6909, 0.7817, 0.8628, 0.9600, 0.8335, 0.9795, 0.1407, 0.0868, 0.1238,\n",
      "         0.1021, 0.0632, 0.1147]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.748748779296875\n",
      "lr\n",
      "0.0007012719804131371\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.6245, 0.4158, 0.5225, 0.4639, 0.0328, 0.0811, 0.0512, 0.0842, 0.0548,\n",
      "         0.0419, 0.0491, 0.0863]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9341186285018921\n",
      "lr\n",
      "0.0007114995672267508\n",
      "pred\n",
      "tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.1000, 0.1000]], device='cuda:0')\n",
      "tensor([[0.7231, 0.8711, 0.8364, 0.8315, 0.7085, 0.7876, 0.6333, 0.9683, 0.8364,\n",
      "         0.9834, 0.1461, 0.0866]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.800384521484375\n",
      "lr\n",
      "0.0007217271540403645\n",
      "pred\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]], device='cuda:0')\n",
      "tensor([[0.4985, 0.4937, 0.5386, 0.5254, 0.5928, 0.7783, 0.4351, 0.5420, 0.0330,\n",
      "         0.0811, 0.0505, 0.0860]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9651855230331421\n",
      "lr\n",
      "0.0007319547408539781\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.5063, 0.3572, 0.2798, 0.8130, 0.7847, 0.8516, 0.8774, 0.8950, 0.7852,\n",
      "         0.9282, 0.9707, 0.9297]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.9705566167831421\n",
      "lr\n",
      "0.0007421823276675918\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.3933, 0.4995, 0.4978, 0.4458, 0.5171, 0.5015, 0.5981, 0.5107, 0.6519,\n",
      "         0.7900, 0.4539, 0.5059]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.8147950172424316\n",
      "lr\n",
      "0.0007524099144812055\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.8000, 0.8000,\n",
      "         0.8000, 0.8000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3665, 0.5137, 0.5142, 0.2247, 0.4504, 0.2874, 0.2218, 0.7271, 0.6904,\n",
      "         0.4797, 0.5312, 0.5347]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6938720941543579\n",
      "lr\n",
      "0.0007626375012948192\n",
      "pred\n",
      "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.2332, 0.3069, 0.2751, 0.2103, 0.2917, 0.3486, 0.4287, 0.3823, 0.4529,\n",
      "         0.4148, 0.4507, 0.4219]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7562012672424316\n",
      "lr\n",
      "0.0007728650881084328\n",
      "pred\n",
      "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.8000]], device='cuda:0')\n",
      "tensor([[0.3162, 0.3892, 0.3945, 0.3892, 0.3210, 0.3833, 0.3115, 0.5024, 0.2859,\n",
      "         0.3684, 0.3020, 0.6851]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.72119140625\n",
      "lr\n",
      "0.0007830926749220465\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0.7285, 0.8589, 0.3718, 0.2886, 0.2913, 0.3823, 0.3169, 0.2700, 0.3914,\n",
      "         0.4602, 0.5522, 0.4912]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.4925780296325684\n",
      "lr\n",
      "0.0007933202617356602\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.6587, 0.7407, 0.9424, 0.5088, 0.4478, 0.4712, 0.4971, 0.4900, 0.4868,\n",
      "         0.5767, 0.6167, 0.4558]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.8810058832168579\n",
      "lr\n",
      "0.0008035478485492739\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.3000, 0.3000, 0.3000,\n",
      "         0.3000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.7070, 0.7456, 0.8535, 0.7407, 0.8726, 0.8892, 0.4082, 0.3223, 0.3142,\n",
      "         0.3997, 0.2991, 0.3271]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7781250476837158\n",
      "lr\n",
      "0.0008137754353628875\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.5610, 0.5854, 0.6523, 0.4629, 0.7373, 0.5728, 0.8721, 0.4399, 0.3872,\n",
      "         0.4192, 0.4094, 0.3828]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.7725096940994263\n",
      "lr\n",
      "0.0008240030221765012\n",
      "pred\n",
      "tensor([[0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.3000, 0.3000]], device='cuda:0')\n",
      "tensor([[0.6514, 0.6357, 0.4128, 0.4321, 0.4504, 0.6279, 0.7954, 0.5249, 0.4336,\n",
      "         0.8740, 0.3337, 0.2617]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.7786133289337158\n",
      "lr\n",
      "0.0008342306089901149\n",
      "pred\n",
      "tensor([[0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.4000]], device='cuda:0')\n",
      "tensor([[0.5547, 0.5225, 0.5859, 0.4954, 0.5391, 0.5952, 0.7578, 0.6445, 0.6675,\n",
      "         0.6035, 0.7847, 0.4133]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.5683594942092896\n",
      "lr\n",
      "0.0008444581958037286\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.9038, 0.9355, 0.9541, 0.9624, 0.7280, 0.7075, 0.6943, 0.6758, 0.6885,\n",
      "         0.7495, 0.8335, 0.8525]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.2756590843200684\n",
      "lr\n",
      "0.0008546857826173422\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.6000, 0.6000, 0.6000, 0.6000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2306, 0.5991, 0.3123, 0.2646, 0.6279, 0.5903, 0.6489, 0.6040, 0.7197,\n",
      "         0.7031, 0.7466, 0.8091]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "1.048828125\n",
      "lr\n",
      "0.0008649133694309559\n",
      "pred\n",
      "tensor([[0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.7000,\n",
      "         0.7000, 0.7000, 0.7000]], device='cuda:0')\n",
      "tensor([[0.9761, 0.9341, 0.9224, 0.6860, 0.8184, 0.8291, 0.9976, 0.8345, 0.6372,\n",
      "         0.5977, 0.8467, 0.7749]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6405762434005737\n",
      "lr\n",
      "0.0008751409562445696\n",
      "pred\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.6000,\n",
      "         0.6000, 0.6000, 0.6000]], device='cuda:0')\n",
      "tensor([[0.2015, 0.1506, 0.1678, 0.2255, 0.2671, 0.3806, 0.2075, 0.1573, 0.5337,\n",
      "         0.5029, 0.6191, 0.5483]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.5346923470497131\n",
      "lr\n",
      "0.0008853685430581833\n",
      "pred\n",
      "tensor([[0.1000, 0.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "         0.9000, 0.9000, 0.9000]], device='cuda:0')\n",
      "tensor([[0.1475, 0.1354, 0.8555, 0.8325, 0.9243, 0.8867, 0.8809, 0.7930, 0.8760,\n",
      "         0.9629, 0.9795, 0.9097]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "loss\n",
      "0.6718384027481079\n",
      "lr\n",
      "0.0008955961298717969\n",
      "pred\n",
      "tensor([[1.0000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000]], device='cuda:0')\n",
      "tensor([[0.9502, 0.2017, 0.1276, 0.1537, 0.1846, 0.0998, 0.1725, 0.1880, 0.1844,\n",
      "         0.4487, 0.2637, 0.2185]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "startup = True\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    if startup:\n",
    "        training = generateLossImages.MakeIter(start_index=start_index if epoch == start_epoch else 0, startup = True)\n",
    "        training_loader = torch.utils.data.DataLoader(training, batch_size=batch_size, num_workers=2)\n",
    "        min_lr /= batch_size**0.5  # normally one puts the learning rate up by sqrt(batchsize), since that keeps the variance constant, however since we use sum in L1Loss, the oposit is true\n",
    "        max_lr /= batch_size**0.5\n",
    "        step_size = (max_lr-min_lr)/steps\n",
    "        optimizer.param_groups[-1]['lr'] = max_lr\n",
    "        los = [0]*(112//batch_size)\n",
    "    else:\n",
    "        training = generateLossImages.MakeIter(start_index=start_index if epoch == start_epoch else 0, epoch=epoch, startup = False)\n",
    "        training_loader = torch.utils.data.DataLoader(training, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "\n",
    "    for index, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        labels = torch.unsqueeze(labels, dim=-1)\n",
    "        inputs.to(memory_format=torch.channels_last)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(inputs)            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        if startup:\n",
    "            los[index%(112//batch_size)] = loss.item()/batch_size\n",
    "            if index % (112//batch_size) == (112//batch_size)-1:         \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "        else:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if falling:\n",
    "            optimizer.param_groups[-1]['lr'] = optimizer.param_groups[-1]['lr'] - step_size\n",
    "            if optimizer.param_groups[-1]['lr'] < min_lr:\n",
    "                falling = False\n",
    "                max_lr *= decay\n",
    "                min_lr *= decay\n",
    "                steps /= decay\n",
    "                step_size = (max_lr-min_lr)/steps\n",
    "                if printing:\n",
    "                    print(\"Saving model !!\")\n",
    "                    print(\"Min lr\")\n",
    "                    print(min_lr)\n",
    "                    print(\"Max lr\")\n",
    "                    print(max_lr)\n",
    "                checkpoint = {'epoch': epoch, 'index': index, 'min_lr': min_lr, 'max_lr': max_lr, 'steps': steps, 'step_size': step_size, 'falling': falling, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'threshold': threshold\n",
    "                }\n",
    "                save_ckp(checkpoint, True)\n",
    "                \n",
    "                if startup and sum(los)/10 < 0.05 and max(los) < 0.1:\n",
    "                    startup = False\n",
    "                    max_lr /= 4\n",
    "                    min_lr /= 4\n",
    "                    steps *= 2\n",
    "                    step_size = (max_lr-min_lr)/steps\n",
    "                    falling = True\n",
    "                    optimizer.param_groups[-1]['lr'] = max_lr\n",
    "                    print(\"startup done ! !\")\n",
    "                    break\n",
    "        else: \n",
    "            optimizer.param_groups[-1]['lr'] += step_size\n",
    "            if optimizer.param_groups[-1]['lr'] > max_lr:\n",
    "                falling = True\n",
    "\n",
    "        if (startup and printing and index % (112//batch_size) == (112//batch_size)-1) or (not startup and printing and index % (20*(112//batch_size) == (112//batch_size))-1):\n",
    "            print(\"loss\")\n",
    "            print(loss.item())\n",
    "            print(\"lr\")\n",
    "            print(optimizer.param_groups[-1]['lr'])\n",
    "            print(\"pred\")\n",
    "            print(labels.T)\n",
    "            print(outputs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0040051937103271484, 0.8806514739990234, 0.0, 0.1621570587158203, 0.001001119613647461, 0.31227612495422363, 0.0, 0.024025678634643555]\n",
      "[0.2893682198971097, 63.62552420967629, 0.0, 11.715563045892052, 0.07232913598118719, 22.561402251625466, 0.0, 1.735813136927891]\n"
     ]
    }
   ],
   "source": [
    "print(times)\n",
    "su = sum(times)\n",
    "print([100*l/su for l in times])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4193603606135756\n"
     ]
    }
   ],
   "source": [
    "print(su/15*6645*50*4/86400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f33075560525c4759195768b52de2817c211ae9aef6733cbe5230884af85532a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
